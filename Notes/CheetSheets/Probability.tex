\documentclass{article}
\usepackage{amsmath}
\usepackage{geometry}

\title{Probability Cheet Sheet}
\author{Peitian Zhang}
\geometry{left=2cm,right=2cm,bottom=2cm}

\begin{document}
\maketitle
\tableofcontents
\clearpage
\section{Distribution}
A distribution $P: \Omega\rightarrow\Gamma$ is a mapping from the probabilities of events to the probabilities of outcomes. \textbf{A distribution is defined by a \emph{probability mass function} (discrete random variable) or a \emph{probability density function} (continuous random variable)}.

\subsection{Joint Distribution}
Say a distribution is defined over multiple \textbf{discrete} random variables, formally $$p(X_1=x_1,X_2=x_2,\cdots,X_n=x_n)$$then $p(X_1,X_2,\cdots,X_n)$ is called \textbf{joint distribution}.

\section{Bayesian Theorem}
\textbf{Bayesian Theorem} is used to infer the \emph{unobserved variable} from the \emph{observed data}, formally
\begin{equation}
    p(x|y) = \frac{p(y|x)p(x)}{p(y)},
\end{equation}
where $y\in \mathcal{Y}$ is the observed data and $x\in \mathcal{X}$ is the latent variable, $\mathcal{Y}$ denotes the data(event) space and $\mathcal{X}$ denotes the latent space, \begin{itemize}
    \item $p(x|y)$ describes the probability of $x$ given $y$ observed, namely the \textbf{posterior}.
    \item $p(y|x)$ describes the probability of $y$ given a determined $x$, which is the principle that we assume the data is generated, namely the \textbf{likelihood}.
    \item $p(x)$ describes the probability of $x$ regardless of any observed data $y$, namely the \textbf{prior}.
    \item $p(y)$ describes the probability of $y$ independent of any latent variable, namely the \textbf{evidence}.
\end{itemize}
Furthermore, \begin{equation}
    p(y) = \begin{cases}
        \int_{x\in \mathcal{X}} p(y|x)p(x) \,dx&X \text{ is continuous,}\\
        \sum_{x\in\mathcal{X}} p(y|x)p(x) &X \text{ is discrete.}\\
    \end{cases}
\end{equation}
Notice that we assume the data is generated by two steps:
\begin{itemize}
    \item draw a latent variable $x$ from the prior $p(x)$,
    \item draw data $y$ from the likelihood $p(y|x)$.
\end{itemize}
\section{Variational Inference}
The \textbf{evidence} is the distribution over the whole data space, and is usually intractable to directly compute, \textbf{Variational Inference} is the technique to avoid calculating $p(y)$, instead, it assumes a model $f(\cdot)$ to simulate $p(x|y)$.
\end{document}