{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import logging\n",
    "import math,random\n",
    "import time\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from models.Attention import Attention\n",
    "from models.Interactors.FIM import FIM_Interactor\n",
    "from models.Interactors.KNRM import KNRM_Interactor\n",
    "from models.Encoders.CNN import CNN_Encoder\n",
    "from data.configs.demo import config\n",
    "from utils.utils import prepare\n",
    "\n",
    "from models.base_model import BaseModel"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "config.device = 'cuda:0'\n",
    "config.k = 3\n",
    "config.spadam = False\n",
    "\n",
    "vocab, loaders = prepare(config)\n",
    "record = next(iter(loaders[0]))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[2021-07-21 08:27:22,252] INFO (root) Hyper Parameters are\n",
      "<class 'data.configs.demo.config'>\n",
      "[2021-07-21 08:27:22,254] INFO (root) preparing dataset...\n",
      "[2021-07-21 08:27:24,532] INFO (torchtext.vocab) Loading vectors from /home/peitian_zhang/Data/.vector_cache/glove.840B.300d.txt.pt\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "class DRM(nn.Module):\n",
    "    def __init__(self, k, threshold = -float('inf')):\n",
    "        super().__init__()\n",
    "\n",
    "        self.name = \"matching-based\"\n",
    "\n",
    "        self.k = k\n",
    "        self.threshold = threshold\n",
    "    \n",
    "    def forward(self, news_embedding, user_repr):\n",
    "        \"\"\"\n",
    "        Extract words from news text according to the overall user interest\n",
    "\n",
    "        Args:\n",
    "            news_embedding: word-level news embedding, [batch_size, his_size, signal_length, hidden_dim]\n",
    "            user_repr: user representation, [batch_size, 1, hidden_dim]\n",
    "        \n",
    "        Returns:\n",
    "            weighted_pt: weighted embedding for personalized terms, [batch_size, his_size, k, hidden_dim]\n",
    "        \"\"\"\n",
    "        # [bs, *, sl, 1]\n",
    "        scores = F.normalize(news_embedding, dim=-1).matmul(F.normalize(user_repr, dim=-1).transpose(-2,-1).unsqueeze(1)).squeeze(-1)\n",
    "\n",
    "        score_k, score_kid = scores.topk(dim=-1, k=self.k)\n",
    "        personalized_terms = news_embedding.gather(dim=-2,index=score_kid.unsqueeze(-1).expand(score_kid.size() + (news_embedding.size(-1),)))\n",
    "\n",
    "        weighted_ps_terms = personalized_terms * (score_k.masked_fill(score_k < self.threshold, 0).unsqueeze(-1))\n",
    "\n",
    "        return weighted_ps_terms\n",
    "\n",
    "class CNN_Interactor(nn.Module):\n",
    "    def __init__(self, signal_length, term_num, hidden_dim):\n",
    "        super().__init__()\n",
    "        self.name = '2dcnn'\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.signal_length = signal_length\n",
    "        self.term_num = term_num\n",
    "\n",
    "        self.SeqCNN2D = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels=32, kernel_size=[3, 3], padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=[3, 3], stride=[3, 3]),\n",
    "            nn.Conv2d(in_channels=32, out_channels=16, kernel_size=[3, 3], padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=[3, 3], stride=[3, 3])\n",
    "        )\n",
    "\n",
    "        self.final_dim = int(int(signal_length/3)/3) * int(int(term_num/3)/3) * 16\n",
    "\n",
    "        # nn.init.xavier_normal_(self.SeqCNN2D[0].weight)\n",
    "        # nn.init.xavier_normal_(self.SeqCNN2D[3].weight)\n",
    "\n",
    "    def forward(self, cdd_news_embedding, ps_terms):\n",
    "        \"\"\"\n",
    "        calculate interaction tensor and reduce it to a vector\n",
    "\n",
    "        Args:\n",
    "            cdd_news_embedding: word-level representation of candidate news, [batch_size, cdd_size, signal_length, hidden_dim]\n",
    "            ps_terms: personalized terms, [batch_size, term_num, hidden_dim]\n",
    "\n",
    "        Returns:\n",
    "            reduced_tensor: output tensor after CNN2d, [batch_size, cdd_size, final_dim]\n",
    "        \"\"\"\n",
    "\n",
    "        # [bs, cs, sl, tn]\n",
    "        matching_tensor = cdd_news_embedding.matmul(ps_terms.transpose(-2,-1).unsqueeze(1)).view(-1, 1, self.signal_length, self.term_num) / math.sqrt(self.hidden_dim)\n",
    "        reduced_tensor = self.SeqCNN2D(matching_tensor).view(cdd_news_embedding.size(0), cdd_news_embedding.size(1), self.final_dim)\n",
    "        return reduced_tensor"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "class ESM(BaseModel):\n",
    "    def __init__(self, config, encoderN, encoderU, docReducer, interactor):\n",
    "        super().__init__(config)\n",
    "        self.title_size = config.title_size\n",
    "        self.k = config.k\n",
    "\n",
    "        self.encoderN = encoderN\n",
    "        self.encoderU = encoderU\n",
    "        self.docReducer = docReducer\n",
    "        # self.term_fuser = term_fuser\n",
    "        self.interactor = interactor\n",
    "\n",
    "        self.hidden_dim = encoderN.hidden_dim\n",
    "        self.final_dim = interactor.final_dim\n",
    "\n",
    "        self.learningToRank = nn.Sequential(\n",
    "            nn.Linear(self.final_dim, int(self.final_dim/2)),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(int(self.final_dim/2),1)\n",
    "        )\n",
    "\n",
    "        self.name = '-'.join(['esm', self.encoderN.name, self.encoderU.name, self.docReducer.name, self.interactor.name])\n",
    "\n",
    "    def clickPredictor(self, reduced_tensor):\n",
    "        \"\"\" calculate batch of click probabolity\n",
    "\n",
    "        Args:\n",
    "            reduced_tensor: [batch_size, cdd_size, final_dim]\n",
    "\n",
    "        Returns:\n",
    "            score of each candidate news, [batch_size, cdd_size]\n",
    "        \"\"\"\n",
    "        return self.learningToRank(reduced_tensor).squeeze(dim=-1)\n",
    "\n",
    "    def _forward(self,x):\n",
    "        if x['candidate_title'].size(0) != self.batch_size:\n",
    "            self.batch_size = x['candidate_title'].size(0)\n",
    "\n",
    "        cdd_news = x['candidate_title'].long().to(self.device)\n",
    "        cdd_news_embedding, cdd_news_repr = self.encoderN(\n",
    "            cdd_news)\n",
    "        his_news = x['clicked_title'].long().to(self.device)\n",
    "        his_news_embedding, his_news_repr = self.encoderN(\n",
    "            his_news)\n",
    "\n",
    "        user_repr = self.encoderU(his_news_repr)\n",
    "\n",
    "        ps_terms = self.docReducer(his_news_embedding, user_repr).view(self.batch_size, -1, self.hidden_dim)\n",
    "\n",
    "        reduced_tensor = self.interactor(torch.cat([cdd_news_repr.unsqueeze(-2), cdd_news_embedding], dim=-2), ps_terms)\n",
    "\n",
    "        return self.clickPredictor(reduced_tensor)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        \"\"\"\n",
    "        Decoupled function, score is unormalized click score\n",
    "        \"\"\"\n",
    "        score = self._forward(x)\n",
    "\n",
    "        if self.cdd_size > 1:\n",
    "            prob = nn.functional.log_softmax(score, dim=1)\n",
    "        else:\n",
    "            prob = torch.sigmoid(score)\n",
    "\n",
    "        return prob"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "from models.Encoders.CNN import CNN_Encoder\n",
    "from models.Encoders.RNN import RNN_User_Encoder\n",
    "\n",
    "encoderN = CNN_Encoder(config, vocab)\n",
    "encoderU = RNN_User_Encoder(encoderN.hidden_dim)\n",
    "docReducer = DRM(config.k)\n",
    "interactor = CNN_Interactor(config.title_size+1, config.k * config.his_size, encoderN.hidden_dim)\n",
    "\n",
    "esm = ESM(config, encoderN, encoderU, docReducer, interactor).to(config.device)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "esm(record)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[-1.6019, -1.6012, -1.6236, -1.5991, -1.6218],\n",
       "        [-1.6098, -1.6100, -1.6083, -1.6101, -1.6090],\n",
       "        [-1.6062, -1.6071, -1.6178, -1.6249, -1.5914],\n",
       "        [-1.6112, -1.6093, -1.6126, -1.6092, -1.6049],\n",
       "        [-1.6044, -1.6037, -1.6032, -1.6157, -1.6203],\n",
       "        [-1.6090, -1.6091, -1.6093, -1.6092, -1.6106],\n",
       "        [-1.6100, -1.6088, -1.6106, -1.6056, -1.6121],\n",
       "        [-1.6084, -1.6113, -1.6094, -1.6095, -1.6086],\n",
       "        [-1.5986, -1.6273, -1.6114, -1.6266, -1.5840],\n",
       "        [-1.6095, -1.6106, -1.6097, -1.6094, -1.6081]], device='cuda:0',\n",
       "       grad_fn=<LogSoftmaxBackward>)"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "config.epochs = 8\n",
    "config.val_freq = 2\n",
    "config.spadam = False\n",
    "esm.tune(config, loaders)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[2021-07-21 08:30:20,789] INFO (models.base_model) training...\n",
      "  0%|          | 0/295 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "RuntimeError",
     "evalue": "Adam does not support sparse gradients, please consider SparseAdam instead",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-8cbe429f57b6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mval_freq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspadam\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mesm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtune\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloaders\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Codes/Document-Reduction/models/base_model.py\u001b[0m in \u001b[0;36mtune\u001b[0;34m(self, config, loaders, tb)\u001b[0m\n\u001b[1;32m    482\u001b[0m         \u001b[0moptimizers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mschedulers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_optim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloaders\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    483\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 484\u001b[0;31m         res = self._run_tune(loaders, optimizers, loss_func, config, schedulers=schedulers,\n\u001b[0m\u001b[1;32m    485\u001b[0m                         writer=writer, interval=config.interval, save_step=int(len(loaders[0])/config.val_freq)-1)\n\u001b[1;32m    486\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Codes/Document-Reduction/models/base_model.py\u001b[0m in \u001b[0;36m_run_tune\u001b[0;34m(self, loaders, optimizers, loss_func, config, schedulers, writer, interval, save_step)\u001b[0m\n\u001b[1;32m    413\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moptimizers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 415\u001b[0;31m                     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    416\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mschedulers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nn/lib/python3.8/site-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nn/lib/python3.8/site-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m     79\u001b[0m                     \u001b[0mparams_with_grad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_sparse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m                         \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Adam does not support sparse gradients, please consider SparseAdam instead'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m                     \u001b[0mgrads\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Adam does not support sparse gradients, please consider SparseAdam instead"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.5",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('nn': conda)"
  },
  "interpreter": {
   "hash": "3eb98a31bb4fe483f921d6d3a56a708e0ea8295072fddff1b0a8d949ab7fd102"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}