{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import logging\n",
    "import math,random\n",
    "import time\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from models.Attention import Attention\n",
    "from models.Encoders.CNN import CNN_Encoder\n",
    "from models.Encoders.RNN import RNN_User_Encoder\n",
    "from models.Interactors.CNN import CNN_Interactor\n",
    "from models.Interactors.FIM import FIM_Interactor\n",
    "from models.Interactors.KNRM import KNRM_Interactor\n",
    "from models.ESM import ESM\n",
    "from models.base_model import BaseModel\n",
    "\n",
    "from data.configs.demo import config\n",
    "from utils.utils import prepare\n",
    "\n",
    "from models.base_model import BaseModel\n",
    "from models.Modules.DRM import DRM_Matching\n",
    "from models.Modules.TFM import TFM"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "config.device = 'cuda:0'\n",
    "config.k = 3\n",
    "\n",
    "vocab, loaders = prepare(config)\n",
    "record = next(iter(loaders[0]))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[2021-07-22 16:44:58,527] INFO (root) Hyper Parameters are scale:demo, mode:train, batch_size:10, title_size:20, abs_size:40, his_size:50, learning_rate:0.001, vert_num:18, subvert_num:293, npratio:4, dropout_p:0.2, query_dim:200, embedding_dim:300, filter_num:150, head_num:16, epochs:8, metrics:auc,mean_mrr,ndcg@5,ndcg@10, device:cuda:0, attrs:['title'], k:3, save_step:[0], validate:False, interval:10, spadam:False, val_freq:2, schedule:None, multiview:False, onehot:False\n",
      "[2021-07-22 16:44:58,528] INFO (root) preparing dataset...\n",
      "[2021-07-22 16:45:01,170] INFO (torchtext.vocab) Loading vectors from /home/peitian_zhang/Data/.vector_cache/glove.840B.300d.txt.pt\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "class DRM_Matching(nn.Module):\n",
    "    \"\"\"\n",
    "    basic document reducer: topk\n",
    "    \"\"\"\n",
    "    def __init__(self, k, threshold = -float('inf')):\n",
    "        super().__init__()\n",
    "\n",
    "        self.name = \"matching-based\"\n",
    "\n",
    "        self.k = k\n",
    "        self.threshold = threshold\n",
    "\n",
    "    def forward(self, news_embedding, user_repr):\n",
    "        \"\"\"\n",
    "        Extract words from news text according to the overall user interest\n",
    "\n",
    "        Args:\n",
    "            news_embedding: word-level news embedding, [batch_size, his_size, signal_length, hidden_dim]\n",
    "            user_repr: user representation, [batch_size, 1, hidden_dim]\n",
    "\n",
    "        Returns:\n",
    "            weighted_pt: weighted embedding for personalized terms, [batch_size, his_size, k, hidden_dim]\n",
    "        \"\"\"\n",
    "        # [bs, hs, sl]\n",
    "        scores = F.normalize(news_embedding, dim=-1).matmul(F.normalize(user_repr, dim=-1).transpose(-2,-1).unsqueeze(1)).squeeze(-1)\n",
    "        \n",
    "        score_k, score_kid = scores.topk(dim=-1, k=self.k)\n",
    "        personalized_terms = news_embedding.gather(dim=-2,index=score_kid.unsqueeze(-1).expand(score_kid.size() + (news_embedding.size(-1),)))\n",
    "\n",
    "        weighted_ps_terms = personalized_terms * (score_k.masked_fill(score_k < self.threshold, 0).unsqueeze(-1))\n",
    "        # weighted_ps_terms.retain_grad()\n",
    "        # print(weighted_ps_terms.grad, weighted_ps_terms.requires_grad)\n",
    "\n",
    "        return weighted_ps_terms, score_kid"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "encoderN = CNN_Encoder(config, vocab)\n",
    "encoderU = RNN_User_Encoder(encoderN.hidden_dim)\n",
    "docReducer = DRM_Matching(config.k)\n",
    "termFuser = TFM(config.his_size, config.k)\n",
    "interactor = CNN_Interactor(config.title_size + 1, config.k * config.his_size + 1, encoderN.hidden_dim)\n",
    "\n",
    "esm = ESM(config, encoderN, encoderU, docReducer, None, interactor).to(config.device)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "a.grad,b.grad"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(tensor([[[[5.7440e-01, 1.4786e+00, 2.7934e-03, 1.4655e+00, 2.2495e-01],\n",
       "           [3.9562e-01, 1.0184e+00, 1.9240e-03, 1.0094e+00, 1.5494e-01],\n",
       "           [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "           [4.6744e-01, 1.2032e+00, 2.2733e-03, 1.1926e+00, 1.8306e-01]],\n",
       " \n",
       "          [[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "           [5.5783e-01, 1.4359e+00, 2.7129e-03, 1.4233e+00, 2.1846e-01],\n",
       "           [4.2650e-01, 1.0979e+00, 2.0742e-03, 1.0882e+00, 1.6703e-01],\n",
       "           [5.6448e-01, 1.4530e+00, 2.7452e-03, 1.4402e+00, 2.2107e-01]],\n",
       " \n",
       "          [[6.2962e-01, 1.6207e+00, 3.0620e-03, 1.6064e+00, 2.4658e-01],\n",
       "           [2.9200e-01, 7.5163e-01, 1.4201e-03, 7.4502e-01, 1.1436e-01],\n",
       "           [4.4374e-01, 1.1422e+00, 2.1580e-03, 1.1322e+00, 1.7378e-01],\n",
       "           [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00]]],\n",
       " \n",
       " \n",
       "         [[[1.5224e+00, 7.5430e-01, 3.4183e-01, 1.2612e+00, 1.4784e+00],\n",
       "           [9.7296e-01, 4.8207e-01, 2.1846e-01, 8.0602e-01, 9.4486e-01],\n",
       "           [1.6428e+00, 8.1395e-01, 3.6886e-01, 1.3609e+00, 1.5953e+00],\n",
       "           [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00]],\n",
       " \n",
       "          [[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "           [1.1165e+00, 5.5321e-01, 2.5070e-01, 9.2497e-01, 1.0843e+00],\n",
       "           [1.2223e+00, 6.0562e-01, 2.7445e-01, 1.0126e+00, 1.1870e+00],\n",
       "           [1.2075e+00, 5.9828e-01, 2.7113e-01, 1.0003e+00, 1.1726e+00]],\n",
       " \n",
       "          [[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "           [1.6716e+00, 8.2823e-01, 3.7534e-01, 1.3848e+00, 1.6233e+00],\n",
       "           [1.3945e+00, 6.9094e-01, 3.1312e-01, 1.1552e+00, 1.3542e+00],\n",
       "           [1.3448e+00, 6.6633e-01, 3.0196e-01, 1.1141e+00, 1.3060e+00]]]]),\n",
       " tensor([[[ 6.9722, -2.9966,  7.4387, -1.5176, 11.6873]],\n",
       " \n",
       "         [[-1.4841,  1.8270,  3.8056,  0.8049, -0.9705]]]))"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "config.epochs = 8\n",
    "config.val_freq = 2\n",
    "esm.tune(config, loaders)\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[2021-07-22 16:39:45,572] INFO (models.base_model) training...\n",
      "epoch 1 , step 140 , loss: 1.5967:  49%|████▉     | 146/295 [00:05<00:05, 26.70it/s][2021-07-22 16:39:51,092] INFO (models.base_model) evaluating...\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 1812/1812 [00:15<00:00, 117.72it/s]\n",
      "[2021-07-22 16:40:07,070] INFO (models.base_model) current result of esm-cnn-encoder-rnn-user-encoder-matching-based-2dcnn is {'auc': 0.537, 'mean_mrr': 0.2323, 'ndcg@5': 0.2374, 'ndcg@10': 0.3117, 'epoch': 1, 'step': 146}\n",
      "[2021-07-22 16:40:08,076] INFO (models.base_model) saved model of step 146, epoch 1 at data/model_params/esm-cnn-encoder-rnn-user-encoder-matching-based-2dcnn/demo_epoch1_step146_[hs=50,topk=3].model\n",
      "epoch 1 , step 290 , loss: 1.5680:  99%|█████████▊| 291/295 [00:27<00:00, 10.65it/s][2021-07-22 16:40:12,960] INFO (models.base_model) evaluating...\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 1812/1812 [00:14<00:00, 128.91it/s]\n",
      "[2021-07-22 16:40:27,580] INFO (models.base_model) current result of esm-cnn-encoder-rnn-user-encoder-matching-based-2dcnn is {'auc': 0.5513, 'mean_mrr': 0.2427, 'ndcg@5': 0.2566, 'ndcg@10': 0.3233, 'epoch': 1, 'step': 292}\n",
      "[2021-07-22 16:40:28,533] INFO (models.base_model) saved model of step 292, epoch 1 at data/model_params/esm-cnn-encoder-rnn-user-encoder-matching-based-2dcnn/demo_epoch1_step292_[hs=50,topk=3].model\n",
      "epoch 1 , step 290 , loss: 1.5680: 100%|██████████| 295/295 [00:43<00:00,  6.84it/s]\n",
      "epoch 2 , step 140 , loss: 1.4791:  49%|████▉     | 144/295 [00:05<00:05, 26.80it/s][2021-07-22 16:40:34,182] INFO (models.base_model) evaluating...\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 1812/1812 [00:14<00:00, 124.71it/s]\n",
      "[2021-07-22 16:40:49,252] INFO (models.base_model) current result of esm-cnn-encoder-rnn-user-encoder-matching-based-2dcnn is {'auc': 0.5598, 'mean_mrr': 0.249, 'ndcg@5': 0.2637, 'ndcg@10': 0.3289, 'epoch': 2, 'step': 146}\n",
      "[2021-07-22 16:40:50,141] INFO (models.base_model) saved model of step 146, epoch 2 at data/model_params/esm-cnn-encoder-rnn-user-encoder-matching-based-2dcnn/demo_epoch2_step146_[hs=50,topk=3].model\n",
      "epoch 2 , step 290 , loss: 1.4663:  98%|█████████▊| 289/295 [00:26<00:00, 11.02it/s][2021-07-22 16:40:54,984] INFO (models.base_model) evaluating...\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.5",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('nn': conda)"
  },
  "interpreter": {
   "hash": "3eb98a31bb4fe483f921d6d3a56a708e0ea8295072fddff1b0a8d949ab7fd102"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}