{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import re\n",
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import logging\n",
    "import torch\n",
    "import math\n",
    "import time\n",
    "from torch.utils.data import Dataset\n",
    "from utils.utils import newsample, getId2idx, tokenize, getVocab, my_collate, Partition_Sampler, convert_tokens_to_words\n",
    "from data.configs.demo import config\n",
    "from torch.utils.data import DataLoader\n",
    "from collections import defaultdict\n",
    "\n",
    "from transformers import BertTokenizer,BertModel,BertTokenizerFast\n",
    "from utils.MIND import MIND\n",
    "\n",
    "logger = logging.getLogger(__name__)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "t = BertTokenizerFast.from_pretrained('bert-base-uncased')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# config.reducer = 'bm25'\n",
    "# config.reducer = 'bow'\n",
    "# config.reducer = 'matching'\n",
    "\n",
    "# config.signal_length = 10\n",
    "# config.scale = 'large'\n",
    "# config.impr_size = 100\n",
    "# config.mode = 'test'\n",
    "\n",
    "path = config.path + 'MIND/MINDdemo_train/'\n",
    "a = MIND(config, path + 'news.tsv', path + 'behaviors.tsv')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "source": [
    "a.attn_mask[2].sum(), a.encoded_news[2], a.attn_mask_dedup[2], a.attn_mask_dedup[2].sum()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(32,\n",
       " array([  101,  2753,  5409, 14243,  2005,  7579,  6638,  2122,  9428,\n",
       "        19741, 14243,  2024,  3173,  2017,  2067,  1998,  4363,  2017,\n",
       "         2013,  8328,  4667,  2008, 18162,  7579,  6638,  2005,  2204,\n",
       "         1012,  2740,  3635, 10483,  2015,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0]),\n",
       " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1,\n",
       "        1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " 27)"
      ]
     },
     "metadata": {},
     "execution_count": 29
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "a.subwords[3], t.convert_ids_to_tokens(a.encoded_news[3][:32]), a.attn_mask[3].sum()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "a.attn_mask_dedup"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "a[1]['his_attn_mask']"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "r = np.array([[[1,1],[2,2],[2,3]],[[1,1],[1,2],[1,3]]])\n",
    "r[r[:,:,0] == 1]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "source": [
    "t.convert_ids_to_tokens(a.encoded_news[3])"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['[CLS]',\n",
       " 'the',\n",
       " 'cost',\n",
       " 'of',\n",
       " 'trump',\n",
       " \"'\",\n",
       " 's',\n",
       " 'aid',\n",
       " 'freeze',\n",
       " 'in',\n",
       " 'the',\n",
       " 'trenches',\n",
       " 'of',\n",
       " 'ukraine',\n",
       " \"'\",\n",
       " 's',\n",
       " 'war',\n",
       " 'lt',\n",
       " '.',\n",
       " 'ivan',\n",
       " 'mo',\n",
       " '##lch',\n",
       " '##ane',\n",
       " '##ts',\n",
       " 'peeked',\n",
       " 'over',\n",
       " 'a',\n",
       " 'parapet',\n",
       " 'of',\n",
       " 'sand',\n",
       " 'bags',\n",
       " 'at',\n",
       " 'the',\n",
       " 'front',\n",
       " 'line',\n",
       " 'of',\n",
       " 'the',\n",
       " 'war',\n",
       " 'in',\n",
       " 'ukraine',\n",
       " '.',\n",
       " 'next',\n",
       " 'to',\n",
       " 'him',\n",
       " 'was',\n",
       " 'an',\n",
       " 'empty',\n",
       " 'helmet',\n",
       " 'propped',\n",
       " 'up',\n",
       " 'to',\n",
       " 'trick',\n",
       " 'sniper',\n",
       " '##s',\n",
       " ',',\n",
       " 'already',\n",
       " 'per',\n",
       " '##for',\n",
       " '##ated',\n",
       " 'with',\n",
       " 'multiple',\n",
       " 'holes',\n",
       " '.',\n",
       " 'news',\n",
       " 'news',\n",
       " '##world',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]']"
      ]
     },
     "metadata": {},
     "execution_count": 27
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "loader1 = DataLoader(a, batch_size=1, pin_memory=False, num_workers=0, drop_last=False, shuffle=False, sampler=Partition_Sampler(a,2,0))\n",
    "records1 = list(loader1"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "records1[0]['his_attn_mask']"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "dic = pickle.load(open('/data/workspace/Peitian/Code/Document-Reduction/Code/data/cache/bert/MINDdemo_train/news.pkl', 'rb'))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "sb = dic['subwords_first']\n",
    "sb"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "np.unique(a[:,0]),a"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "t.tokenize(\"I don't give a fuck\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.11",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.11 64-bit (conda)"
  },
  "interpreter": {
   "hash": "decb58d8582e8bebc2c9af4e5243ce054f2f8013c5b7e79ffbf7b8b9f3c0761b"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}