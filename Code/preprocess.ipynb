{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import re\r\n",
    "import os\r\n",
    "import pickle\r\n",
    "import numpy as np\r\n",
    "import pandas as pd\r\n",
    "import json\r\n",
    "import logging\r\n",
    "import torch\r\n",
    "import math\r\n",
    "import time\r\n",
    "from datetime import datetime\r\n",
    "from torch.utils.data import Dataset\r\n",
    "from utils.utils import newsample, getId2idx, tokenize, getVocab, my_collate, Partition_Sampler\r\n",
    "from data.configs.demo import config\r\n",
    "from torch.utils.data import DataLoader\r\n",
    "from collections import defaultdict\r\n",
    "# from transformers import BertTokenizer,BertModel,BertTokenizerFast,DebertaTokenizer,DebertaTokenizerFast, AutoTokenizer\r\n",
    "from utils.MIND import MIND\r\n",
    "from utils.Manager import Manager\r\n",
    "\r\n",
    "logger = logging.getLogger(__name__)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "from transformers import AutoTokenizer\r\n",
    "t = AutoTokenizer.from_pretrained('bert-base-uncased')\r\n",
    "# t2 = DebertaTokenizerFast.from_pretrained('microsoft/deberta-base', cache_dir=config.path + \"bert_cache/\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "# config.reducer = 'bm25'\r\n",
    "# config.reducer = 'bow'\r\n",
    "# config.reducer = 'matching'\r\n",
    "\r\n",
    "# config.signal_length = 10\r\n",
    "# config.scale = 'large'\r\n",
    "# config.impr_size = 100\r\n",
    "config.mode = 'dev'\r\n",
    "config.scale = 'large'\r\n",
    "\r\n",
    "# config.bert = 'microsoft/deberta-base'\r\n",
    "# config.embedding = 'deberta'\r\n",
    "\r\n",
    "# config.bert = 'bert-base-uncased\r\n",
    "# config.embedding = 'bert'\r\n",
    "\r\n",
    "manager = Manager(config)\r\n",
    "# manager.gather_same_user_impr()\r\n",
    "# a = MIND(manager)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "manager.gather_same_user_impr()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "from utils.MIND import MIND_news, MIND_history\r\n",
    "manager.shuffle_pos = False\r\n",
    "b = MIND_news(manager)\r\n",
    "c = MIND_history(manager)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[2021-09-29 10:55:18,980] INFO (utils.MIND) process NO.0 loading cached news tokenization from data/cache/bert/MINDdemo_dev/news.pkl\n",
      "[2021-09-29 10:55:19,721] INFO (utils.MIND) process NO.0 loading cached user behavior from data/cache/bert/MINDdemo_dev/10/behaviors.pkl\n",
      "[2021-09-29 10:55:19,724] INFO (utils.MIND) process NO.0 loading cached news tokenization from data/cache/bert/MINDdemo_dev/news.pkl\n",
      "[2021-09-29 10:55:20,562] INFO (utils.utils) deduplicating...\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "news = t.convert_ids_to_tokens(a[0]['his_encoded_index'][1])\r\n",
    "mask = a[0]['his_attn_mask'][1]\r\n",
    "word = manager.convert_tokens_to_words(news)\r\n",
    "subword = a[0]['his_subword_index'][1]\r\n",
    "dedup = a[0]['his_refined_mask'][1]\r\n",
    "\r\n",
    "for i,j,k,z in zip(news,mask,subword,dedup):\r\n",
    "    print(i,j,k,z)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "index = 2"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "a = [1,2,3]\r\n",
    "a[index]"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "IndexError",
     "evalue": "list index out of range",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-50c7d9850cac>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0ma\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0ma\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "x = a[1]\n",
    "x['user_index']"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "cdd = x['cdd_encoded_index'][0]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "subword = x['cdd_subword_index'][0]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "manager.convert_tokens_to_words(t.convert_ids_to_tokens(cdd))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "subword"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "t.convert_ids_to_tokens(cdd)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "t.convert_ids_to_tokens([   1, 7565,   16, 4690,    0,    0,    0,    0])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "tokens = t.tokenize(\"[CLS] I love you embeddings.\")\n",
    "tokens"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "news = pickle.load(open('/data/workspace/Peitian/Code/Document-Reduction/Code/data/cache/deberta/MINDdemo_train/news.pkl', 'rb'))\n",
    "ids = news['encoded_news']\n",
    "subwords = news['subwords_all']"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "t.convert_tokens_to_ids([i for i in r\"[.&*()+=/\\<>,!?;:~`@#$%^]\"])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.8",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.8 64-bit ('nn': conda)"
  },
  "interpreter": {
   "hash": "9616ec0cf0e0dd041cba3c8886d471a5cc72bbf20e2c795f4079199200777fdd"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}