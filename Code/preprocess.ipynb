{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import re\n",
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset\n",
    "from utils.utils import newsample, getId2idx, tokenize, getVocab, my_collate\n",
    "from data.configs.demo import config\n",
    "from torch.utils.data import DataLoader"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "class MIND_bert(Dataset):\n",
    "    \"\"\" Map Style Dataset for MIND, use bert tokenizer\n",
    "\n",
    "    Args:\n",
    "        config(dict): pre-defined dictionary of hyper parameters\n",
    "        news_file(str): path of news_file\n",
    "        behaviors_file(str): path of behaviors_file\n",
    "        shuffle(bool): whether to shuffle the order of impressions\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, config, news_file, behaviors_file, shuffle_pos=False):\n",
    "        from transformers import BertTokenizerFast\n",
    "        # initiate the whole iterator\n",
    "        self.npratio = config.npratio\n",
    "        self.shuffle_pos = shuffle_pos\n",
    "        self.signal_length = config.signal_length\n",
    "        self.his_size = config.his_size\n",
    "        self.k = config.k\n",
    "        pat = re.search('MIND/(.*_(.*)/)news', news_file)\n",
    "        self.mode = pat.group(2)\n",
    "\n",
    "        self.cache_path = '/'.join(['data/cache', config.embedding, pat.group(1)])\n",
    "        self.behav_path = re.search('(\\w*)\\.tsv', behaviors_file).group(1)\n",
    "\n",
    "        # if os.path.exists(self.cache_path + 'news.pkl'):\n",
    "        #     with open(self.cache_path + 'news.pkl', 'rb') as f:\n",
    "        #         news = pickle.load(f)\n",
    "        #         for k,v in news.items():\n",
    "        #             setattr(self, k, v)\n",
    "\n",
    "        #     with open(self.cache_path + 'behaviors.pkl', 'rb') as f:\n",
    "        #         behaviors = pickle.load(f)\n",
    "        #         for k,v in behaviors.items():\n",
    "        #             setattr(self, k, v)\n",
    "\n",
    "        # else:\n",
    "        try:\n",
    "            os.makedirs(self.cache_path, exist_ok=True)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        self.news_file = news_file\n",
    "        self.behaviors_file = behaviors_file\n",
    "        self.col_spliter = '\\t'\n",
    "\n",
    "        self.max_news_length = 512\n",
    "        self.max_his_size = 100\n",
    "\n",
    "        # there are only two types of vocabulary\n",
    "        self.tokenizer = BertTokenizerFast.from_pretrained(config.bert)\n",
    "        # self.tokenizer.max_model_input_sizes[config.bert] = 10000ok\n",
    "\n",
    "        self.nid2index = getId2idx(\n",
    "            'data/dictionaries/nid2idx_{}_{}.json'.format(config.scale, self.mode))\n",
    "        self.uid2index = getId2idx(\n",
    "            'data/dictionaries/uid2idx_{}.json'.format(config.scale))\n",
    "\n",
    "        self.init_news()\n",
    "        self.init_behaviors()\n",
    "\n",
    "    def init_news(self):\n",
    "        \"\"\"\n",
    "            init news information given news file, such as news_title_array.\n",
    "        \"\"\"\n",
    "\n",
    "        # VERY IMPORTANT!!! FIXME\n",
    "        # The nid2idx dictionary must follow the original order of news in news.tsv\n",
    "\n",
    "        documents = ['[PAD]'*self.max_news_length]\n",
    "\n",
    "        with open(self.news_file, \"r\", encoding='utf-8') as rd:\n",
    "            for idx in rd:\n",
    "                nid, vert, subvert, title, ab, url, _, _ = idx.strip(\"\\n\").split(self.col_spliter)\n",
    "                # concat all fields to form the document\n",
    "                # try:\n",
    "                #     self.tokenizer.tokenize(' '.join([title, ab, vert, subvert]))\n",
    "                # except:\n",
    "                #     print(' '.join([title, ab, vert, subvert]))\n",
    "                documents.append(' '.join([title, ab, vert, subvert]))\n",
    "\n",
    "        encoded_dict = self.tokenizer(documents, add_special_tokens=False, padding=True, truncation=True, max_length=self.max_news_length, return_tensors='np')\n",
    "        self.encoded_news = encoded_dict.input_ids\n",
    "        self.attn_mask = encoded_dict.attention_mask\n",
    "\n",
    "        with open(self.cache_path + 'news.pkl', 'wb') as f:\n",
    "            pickle.dump(\n",
    "                {\n",
    "                    'encoded_news': self.encoded_news,\n",
    "                    'attn_mask': self.attn_mask\n",
    "                },\n",
    "                f\n",
    "            )\n",
    "\n",
    "\n",
    "    def init_behaviors(self):\n",
    "        \"\"\"\n",
    "            init behavior logs given behaviors file.\n",
    "        \"\"\"\n",
    "        # list of list of history news index\n",
    "        histories = []\n",
    "        # list of user index\n",
    "        uindexes = []\n",
    "        # list of list of history padding length\n",
    "        his_sizes = []\n",
    "        # list of impression indexes\n",
    "        # self.impr_indexes = []\n",
    "\n",
    "        impr_index = 0\n",
    "\n",
    "        # only store positive behavior\n",
    "        if self.mode == 'train':\n",
    "            # list of list of his cdd news index along with its impression index\n",
    "            imprs = []\n",
    "            # dictionary of list of unhis cdd news index\n",
    "            negatives = {}\n",
    "\n",
    "            with open(self.behaviors_file, \"r\", encoding='utf-8') as rd:\n",
    "                for idx in rd:\n",
    "                    _, uid, time, history, impr = idx.strip(\"\\n\").split(self.col_spliter)\n",
    "\n",
    "                    history = [self.nid2index[i] for i in history.split()]\n",
    "                    his_sizes.append(len(history))\n",
    "\n",
    "                    # tailor user's history or pad 0\n",
    "                    history = history[:self.max_his_size] + [0] * (self.max_his_size - len(history))\n",
    "                    impr_news = [self.nid2index[i.split(\"-\")[0]] for i in impr.split()]\n",
    "                    labels = [int(i.split(\"-\")[1]) for i in impr.split()]\n",
    "                    # user will always in uid2index\n",
    "                    uindex = self.uid2index[uid]\n",
    "\n",
    "                    # store negative samples of each impression\n",
    "                    negative = []\n",
    "\n",
    "                    for news, label in zip(impr_news, labels):\n",
    "                        if label == 1:\n",
    "                            imprs.append((impr_index, news))\n",
    "                        else:\n",
    "                            negative.append(news)\n",
    "\n",
    "                    # 1 impression correspond to 1 of each of the following properties\n",
    "                    histories.append(history)\n",
    "                    negatives[impr_index] = negative\n",
    "                    uindexes.append(uindex)\n",
    "\n",
    "                    impr_index += 1\n",
    "\n",
    "            self.imprs = imprs\n",
    "            self.histories = histories\n",
    "            self.his_sizes = his_sizes\n",
    "            self.negatives = negatives\n",
    "            self.uindexes = uindexes\n",
    "\n",
    "            save_dict = {\n",
    "                'imprs': self.imprs,\n",
    "                'histories': self.histories,\n",
    "                'his_sizes': self.his_sizes,\n",
    "                'negatives': self.negatives,\n",
    "                'uindexes': self.uindexes\n",
    "            }\n",
    "\n",
    "        # store every behavior\n",
    "        elif self.mode == 'dev':\n",
    "            # list of every cdd news index along with its impression index and label\n",
    "            imprs = []\n",
    "\n",
    "            with open(self.behaviors_file, \"r\", encoding='utf-8') as rd:\n",
    "                for idx in rd:\n",
    "                    _, uid, time, history, impr = idx.strip(\"\\n\").split(self.col_spliter)\n",
    "\n",
    "                    history = [self.nid2index[i] for i in history.split()]\n",
    "                    his_sizes.append(len(history))\n",
    "                    history = history[:self.max_his_size] + [0] * (self.max_his_size - len(history))\n",
    "\n",
    "                    impr_news = [self.nid2index[i.split(\"-\")[0]] for i in impr.split()]\n",
    "                    labels = [int(i.split(\"-\")[1]) for i in impr.split()]\n",
    "                    # user will always in uid2index\n",
    "                    uindex = self.uid2index[uid]\n",
    "\n",
    "                    # store every impression\n",
    "                    imprs.append((impr_index, impr_news, labels))\n",
    "\n",
    "                    # 1 impression correspond to 1 of each of the following properties\n",
    "                    histories.append(history)\n",
    "                    uindexes.append(uindex)\n",
    "\n",
    "                    impr_index += 1\n",
    "\n",
    "            self.imprs = imprs\n",
    "            self.histories = histories\n",
    "            self.his_sizes = his_sizes\n",
    "            self.uindexes = uindexes\n",
    "\n",
    "            save_dict = {\n",
    "                'imprs': self.imprs,\n",
    "                'histories': self.histories,\n",
    "                'his_sizes': self.his_sizes,\n",
    "                'uindexes': self.uindexes\n",
    "            }\n",
    "\n",
    "        # store every behavior\n",
    "        elif self.mode == 'test':\n",
    "            # list of every cdd news index along with its impression index and label\n",
    "            imprs = []\n",
    "\n",
    "            with open(self.behaviors_file, \"r\", encoding='utf-8') as rd:\n",
    "                for idx in rd:\n",
    "                    _, uid, time, history, impr = idx.strip(\"\\n\").split(self.col_spliter)\n",
    "\n",
    "                    history = [self.nid2index[i] for i in history.split()]\n",
    "                    his_sizes.append(len(history))\n",
    "                    # tailor user's history or pad 0\n",
    "                    history = history[:self.max_his_size] + [0] * (self.max_his_size - len(history))\n",
    "\n",
    "                    impr_news = [self.nid2index[i] for i in impr.split()]\n",
    "                    # user will always in uid2index\n",
    "                    uindex = self.uid2index[uid]\n",
    "\n",
    "                    # store every impression\n",
    "                    imprs.append((impr_index, impr_news))\n",
    "\n",
    "                    # 1 impression correspond to 1 of each of the following properties\n",
    "                    histories.append(history)\n",
    "                    uindexes.append(uindex)\n",
    "\n",
    "                    impr_index += 1\n",
    "\n",
    "            self.imprs = imprs\n",
    "            self.histories = histories\n",
    "            self.his_sizes = his_sizes\n",
    "            self.uindexes = uindexes\n",
    "\n",
    "            save_dict = {\n",
    "                'imprs': self.imprs,\n",
    "                'histories': self.histories,\n",
    "                'his_sizes': self.his_sizes,\n",
    "                'uindexes': self.uindexes\n",
    "            }\n",
    "\n",
    "        with open(self.cache_path + self.behav_path + '.pkl', 'wb') as f:\n",
    "            pickle.dump(save_dict, f)\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "            return length of the whole dataset\n",
    "        \"\"\"\n",
    "        return len(self.imprs)\n",
    "\n",
    "    def __getitem__(self,index):\n",
    "        \"\"\" return data\n",
    "        Args:\n",
    "            index: the index for stored impression\n",
    "\n",
    "        Returns:\n",
    "            back_dic: dictionary of data slice\n",
    "        \"\"\"\n",
    "\n",
    "        impr = self.imprs[index] # (impression_index, news_index)\n",
    "        impr_index = impr[0]\n",
    "        impr_news = impr[1]\n",
    "\n",
    "\n",
    "        user_index = [self.uindexes[impr_index]]\n",
    "\n",
    "        # each time called to return positive one sample and its negative samples\n",
    "        if self.mode == 'train':\n",
    "            # user's unhis news in the same impression\n",
    "            negs = self.negatives[impr_index]\n",
    "            neg_list, neg_pad = newsample(negs, self.npratio)\n",
    "\n",
    "            cdd_ids = [impr_news] + neg_list\n",
    "            label = np.asarray([1] + [0] * self.npratio)\n",
    "\n",
    "            if self.shuffle_pos:\n",
    "                s = np.arange(0, len(label), 1)\n",
    "                np.random.shuffle(s)\n",
    "                cdd_ids = np.asarray(cdd_ids)[s]\n",
    "                label = np.asarray(label)[s]\n",
    "\n",
    "            label = np.arange(0, len(cdd_ids), 1)[label == 1][0]\n",
    "\n",
    "            his_ids = self.histories[impr_index][:self.his_size]\n",
    "\n",
    "            # true means the corresponding history news is padded\n",
    "            his_mask = np.zeros((self.his_size), dtype=bool)\n",
    "            his_mask[:self.his_sizes[impr_index]] = 1\n",
    "\n",
    "            # pad in cdd\n",
    "            # cdd_mask = [1] * neg_pad + [0] * (self.npratio + 1 - neg_pad)\n",
    "\n",
    "            cdd_encoded_index = self.encoded_news[cdd_ids][:, :self.signal_length]\n",
    "            his_encoded_index = self.encoded_news[his_ids][:, :self.signal_length]\n",
    "            cdd_attn_mask = self.attn_mask[cdd_ids][:, :self.signal_length]\n",
    "            his_attn_mask = self.attn_mask[his_ids][:, :self.signal_length]\n",
    "\n",
    "            back_dic = {\n",
    "                \"user_index\": np.asarray(user_index),\n",
    "                # \"cdd_mask\": np.asarray(neg_pad),\n",
    "                'cdd_id': np.asarray(cdd_ids),\n",
    "                'his_id': np.asarray(his_ids),\n",
    "                \"cdd_encoded_index\": cdd_encoded_index,\n",
    "                \"his_encoded_index\": his_encoded_index,\n",
    "                \"cdd_attn_mask\": cdd_attn_mask,\n",
    "                \"his_attn_mask\": his_attn_mask,\n",
    "                \"his_mask\": his_mask,\n",
    "                \"label\": label\n",
    "            }\n",
    "\n",
    "            return back_dic\n",
    "\n",
    "        # each time called return one sample, and no labels\n",
    "        elif self.mode == 'dev':\n",
    "            cdd_ids = impr_news\n",
    "\n",
    "            his_ids = self.histories[impr_index][:self.his_size]\n",
    "\n",
    "            user_index = [self.uindexes[impr_index]]\n",
    "            label = impr[2]\n",
    "\n",
    "            # true means the corresponding history news is padded\n",
    "            his_mask = np.zeros((self.his_size), dtype=bool)\n",
    "            his_mask[:self.his_sizes[impr_index]] = 1\n",
    "\n",
    "            cdd_encoded_index = self.encoded_news[cdd_ids][:, :self.signal_length]\n",
    "            his_encoded_index = self.encoded_news[his_ids][:, :self.signal_length]\n",
    "            cdd_attn_mask = self.attn_mask[cdd_ids][:, :self.signal_length]\n",
    "            his_attn_mask = self.attn_mask[his_ids][:, :self.signal_length]\n",
    "\n",
    "            back_dic = {\n",
    "                \"impression_index\": impr_index + 1,\n",
    "                \"user_index\": np.asarray(user_index),\n",
    "                'cdd_id': np.asarray(cdd_ids),\n",
    "                'his_id': np.asarray(his_ids),\n",
    "                \"cdd_encoded_index\": cdd_encoded_index,\n",
    "                \"his_encoded_index\": his_encoded_index,\n",
    "                \"cdd_attn_mask\": cdd_attn_mask,\n",
    "                \"his_attn_mask\": his_attn_mask,\n",
    "                \"his_mask\": his_mask,\n",
    "                \"labels\": np.asarray([label])\n",
    "            }\n",
    "            return back_dic\n",
    "\n",
    "        elif self.mode == 'test':\n",
    "            cdd_ids = [impr_news]\n",
    "\n",
    "            his_ids = self.histories[impr_index][:self.his_size]\n",
    "\n",
    "            user_index = [self.uindexes[impr_index]]\n",
    "            # true means the corresponding history news is padded\n",
    "            his_mask = np.zeros((self.his_size), dtype=bool)\n",
    "            his_mask[:self.his_sizes[impr_index]] = 1\n",
    "\n",
    "            cdd_encoded_index = self.encoded_news[cdd_ids][:, :self.signal_length]\n",
    "            his_encoded_index = self.encoded_news[his_ids][:, :self.signal_length]\n",
    "            cdd_attn_mask = self.attn_mask[cdd_ids][:, :self.signal_length]\n",
    "            his_attn_mask = self.attn_mask[his_ids][:, :self.signal_length]\n",
    "\n",
    "            back_dic = {\n",
    "                \"impression_index\": impr_index + 1,\n",
    "                \"user_index\": np.asarray(user_index),\n",
    "                'cdd_id': np.asarray(cdd_ids),\n",
    "                'his_id': np.asarray(his_ids),\n",
    "                \"cdd_encoded_index\": cdd_encoded_index,\n",
    "                \"his_encoded_index\": his_encoded_index,\n",
    "                \"cdd_attn_mask\": cdd_attn_mask,\n",
    "                \"his_attn_mask\": his_attn_mask,\n",
    "                \"his_mask\": his_mask\n",
    "            }\n",
    "            return back_dic\n",
    "\n",
    "        else:\n",
    "            raise ValueError(\"Mode {} not defined\".format(self.mode))\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "config.embedding = 'bert'\n",
    "config.signal_length = 20\n",
    "config.his_size = 10\n",
    "train_path = config.path + 'MIND/MINDdemo_dev/'\n",
    "a = MIND_bert(config, train_path + 'news.tsv', train_path + 'behaviors.tsv')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "a[0]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'impression_index': 1,\n",
       " 'user_index': array([1929]),\n",
       " 'cdd_id': array([36180, 41328, 41034, 39776, 34983, 37322, 37327, 36307, 36185,\n",
       "        36349, 38581, 39227, 37368, 33705, 39921, 39640, 36275, 38848,\n",
       "         7014, 37943, 39086, 24209]),\n",
       " 'his_id': array([ 7499, 34171, 15796, 32731, 32139, 18228,  1736, 30270, 35479,\n",
       "        30833]),\n",
       " 'cdd_encoded_index': array([[13240, 12134,  2000,  6701, 18466,  1010,  2655, 27056,  9674,\n",
       "          1005,  1055,  4506,  1005, 21873,  1005,  2867,  2411,  6985,\n",
       "          2037, 13220],\n",
       "        [ 1045,  1005,  2310,  2042,  3015,  2055,  4714,  5014,  2005,\n",
       "          1037,  2095,  1998,  2633,  2985,  1016,  6385,  1999,  1037,\n",
       "          3998,  1011],\n",
       "        [ 5448,  1024,  6972, 10556, 13699, 11795,  6799,  2003,  2055,\n",
       "          2000,  2131,  2054,  2002, 17210,  1024,  1037,  3382,  1996,\n",
       "          2203,  2089],\n",
       "        [ 1996, 10556, 13639,  6182,  6962,  2227, 25748,  2058,  1005,\n",
       "         16021,  6132, 13043,  1005,  2155,  2833,  2954,  1999, 13970,\n",
       "         26677,  2243],\n",
       "        [ 2059,  1998,  2085,  1024,  2054,  2035,  2115,  5440,  1005,\n",
       "         17233,  3340,  2024,  2725,  2651,  2122,  2540,  2705,  3217,\n",
       "          5910,  1998],\n",
       "        [ 3189,  1024,  2610, 11538,  2450,  1005,  1055,  2331,  2044,\n",
       "         17461,  1005,  2447, 18318,  6679, 16955,  2165,  2014,  2000,\n",
       "          2902,  2610],\n",
       "        [ 1057,  1012,  1055,  1012,  3629,  2097,  3280,  2065,  2027,\n",
       "          3961,  1999,  7795,  1010, 26074,  2099,  2632,  1011,  4632,\n",
       "          4215, 19428],\n",
       "        [ 1017,  5242,  6794,  6731,  2044,  1037,  2305,  1997,  5948,\n",
       "          2357,  2046,  1037,  2317,  3317, 23244,  2847,  2077,  2027,\n",
       "          2020,  2000],\n",
       "        [17188,  7260,  2185,  2011,  7064, 16092,  2179,  4142,  2021,\n",
       "          2129,  1029,  1037,  7146,  1997,  3748, 17188,  3373,  2000,\n",
       "          2031,  2042],\n",
       "        [ 6405,  4203, 18856,  8486,  2696,  2082,  5008,  5694,  2006,\n",
       "          2346,  2000,  7233,  1024,  6745,  2054,  2323,  2031,  2042,\n",
       "          1037,  3671],\n",
       "        [ 1996,  9832,  2732,  1997,  2026,  2155,  1005,  1055, 15060,\n",
       "          2795,  2009,  1005,  1055,  2524,  2000,  3342,  2166,  2077,\n",
       "         22953, 21408],\n",
       "        [12669,  4819,  2928,  2571,  1998, 18520,  7207, 10082,  2985,\n",
       "          1996,  5027,  2362,  2012, 10729,  5974,  9151, 12669,  4819,\n",
       "          2928,  2571],\n",
       "        [ 2280,  2167,  3792,  2110,  1010,  6452,  2447,  4938, 24665,\n",
       "          8630,  2100,  8289,  1999, 21690,  1010,  2610,  2360,  4938,\n",
       "         24665,  8630],\n",
       "        [ 5594, 15060, 19328,  2017,  2064,  2191,  3805,  2460,  2006,\n",
       "          2051,  1029,  2770,  2041,  1997, 17428,  2686,  1029,  2182,\n",
       "          2024,  2070],\n",
       "        [12084, 10584, 25019, 17845,  1998,  3870, 21388, 11246, 12134,\n",
       "          2005,  2037,  4506, 12084, 10584, 25019, 17845,  1998,  3870,\n",
       "         21388, 11246],\n",
       "        [ 6969, 12017,  1010, 11928,  2050, 16216, 20473,  2024,  5306,\n",
       "          1010,  2667,  2000,  2994,  1005,  2659,  6337,  1005,  6969,\n",
       "         12017,  1010],\n",
       "        [ 2045,  1005,  1055,  1037,  2173,  1999,  1996,  2149,  2073,\n",
       "          2049,  2042,  2058,  3770,  5445,  2144,  2233,  1996,  4633,\n",
       "          2326,  4311],\n",
       "        [ 4202,  9170, 16360,  4978,  2067,  2012,  2502,  3698,  1010,\n",
       "          4447,  2016,  1005,  1055,  2941, 12232,  1002,  1021,  1012,\n",
       "          1023,  2454],\n",
       "        [ 1996,  2087,  5720,  2055,  3185,  5312,  1997,  1996, 26817,\n",
       "          2292,  1005,  1055,  3046,  2000, 17902,  1996,  3893,  1010,\n",
       "          2021,  2045],\n",
       "        [19337, 11319,  3600, 12934,  2015,  2591,  2865,  1999,  7928,\n",
       "          2006,  9674,  5043,  3021, 19337, 11319,  3600,  2001,  2010,\n",
       "          4050,  2969],\n",
       "        [ 2410,  4436,  2339,  1005,  1055,  3017, 23524, 25967,  6373,\n",
       "          2005,  9179,  1005,  1996,  2317,  3124,  1005,  1999,  1996,\n",
       "          2210, 22322],\n",
       "        [ 5764,  4658,  6627,  9604,  3087,  2052,  2022, 16082,  2000,\n",
       "          4374,  2292,  1005,  1055,  2227,  2009,  1024,  3071,  4122,\n",
       "          1996, 14751]]),\n",
       " 'his_encoded_index': array([[ 1005,  5217,  1997,  7280,  1005,  4113, 18058, 26316,  1010,\n",
       "          2125,  1996, 15168,  4955,  2057,  1005,  1040,  2066,  2000,\n",
       "          9611,  1996],\n",
       "        [ 2524,  2600,  3309,  2047,  5979,  7859,  1024,  2280,  2609,\n",
       "          3992, 21094,  1999,  8332,  3992,  4787, 27838, 28989,  2499,\n",
       "          2006,  1996],\n",
       "        [27357, 21301,  2386,  4269,  3827,  6251,  2005,  2267, 20247,\n",
       "          8040,  3286,  1996,  3883,  2097,  5247,  2403,  2420,  2503,\n",
       "          1037,  2976],\n",
       "        [ 6058,  5085, 12642, 16655, 22425,  2214,  2911, 13088, 11012,\n",
       "          2013,  1005, 16685,  1997,  1996,  4448,  1005,  1037,  3522,\n",
       "          4040,  2006],\n",
       "        [14381,  1005,  1055,  2003,  4855,  1037,  6209, 13896,  8094,\n",
       "          2005,  1002, 11176,  1010,  2199,  2169,  4653,  3397,  2484,\n",
       "          5167,  2164],\n",
       "        [ 2023,  5854,  3380,  2663,  2638, 16078,  2080,  2003,  3458,\n",
       "         23677,  2005, 10470,  2006,  3288,  1037,  9117,  1024,  1996,\n",
       "          2087, 11951],\n",
       "        [18669, 29504,  4115,  2003,  1005,  7078, 10215,  1005,  2044,\n",
       "          2108,  2718,  2007,  2047,  3715, 18669, 29504,  4115,  2003,\n",
       "          1005,  7078],\n",
       "        [ 5503, 12688,  2716, 27668,  5405,  2000,  4000,  2044,  3752,\n",
       "          2014,  2338, 27668,  2347,  1005,  1056,  2469,  2129,  2014,\n",
       "          4654,  2052],\n",
       "        [ 8958,  4268,  2059,  1998,  2085,  1024,  2156,  2129,  2027,\n",
       "          1005,  2310,  4961,  2156,  2054,  1996,  2336,  1997,  6173,\n",
       "          2064,  2532],\n",
       "        [27357, 21301,  2386,  8451,  2004,  2016,  4269,  2451,  2326,\n",
       "          2206,  3827,  2713,  1996,  5179,  1011,  2095,  1011,  2214,\n",
       "          3883,  2001]]),\n",
       " 'cdd_attn_mask': array([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]),\n",
       " 'his_attn_mask': array([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]),\n",
       " 'his_mask': array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True]),\n",
       " 'labels': array([[0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])}"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "from torch.utils.data.distributed import DistributedSampler\n",
    "s = DistributedSampler(a, num_replicas=2, rank=0, shuffle=False)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "loader_train = DataLoader(a, batch_size=1, pin_memory=False, num_workers=0, drop_last=False, shuffle=False, sampler=None)\n",
    "record = next(iter(loader_train))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "record"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'impression_index': [1],\n",
       " 'user_index': tensor([[1929]]),\n",
       " 'cdd_id': tensor([[36180, 41328, 41034, 39776, 34983, 37322, 37327, 36307, 36185, 36349,\n",
       "          38581, 39227, 37368, 33705, 39921, 39640, 36275, 38848,  7014, 37943,\n",
       "          39086, 24209]]),\n",
       " 'his_id': tensor([[ 7499, 34171, 15796, 32731, 32139, 18228,  1736, 30270, 35479, 30833]]),\n",
       " 'cdd_encoded_index': tensor([[[13240, 12134,  2000,  6701, 18466,  1010,  2655, 27056,  9674,  1005,\n",
       "            1055,  4506,  1005, 21873,  1005,  2867,  2411,  6985,  2037, 13220],\n",
       "          [ 1045,  1005,  2310,  2042,  3015,  2055,  4714,  5014,  2005,  1037,\n",
       "            2095,  1998,  2633,  2985,  1016,  6385,  1999,  1037,  3998,  1011],\n",
       "          [ 5448,  1024,  6972, 10556, 13699, 11795,  6799,  2003,  2055,  2000,\n",
       "            2131,  2054,  2002, 17210,  1024,  1037,  3382,  1996,  2203,  2089],\n",
       "          [ 1996, 10556, 13639,  6182,  6962,  2227, 25748,  2058,  1005, 16021,\n",
       "            6132, 13043,  1005,  2155,  2833,  2954,  1999, 13970, 26677,  2243],\n",
       "          [ 2059,  1998,  2085,  1024,  2054,  2035,  2115,  5440,  1005, 17233,\n",
       "            3340,  2024,  2725,  2651,  2122,  2540,  2705,  3217,  5910,  1998],\n",
       "          [ 3189,  1024,  2610, 11538,  2450,  1005,  1055,  2331,  2044, 17461,\n",
       "            1005,  2447, 18318,  6679, 16955,  2165,  2014,  2000,  2902,  2610],\n",
       "          [ 1057,  1012,  1055,  1012,  3629,  2097,  3280,  2065,  2027,  3961,\n",
       "            1999,  7795,  1010, 26074,  2099,  2632,  1011,  4632,  4215, 19428],\n",
       "          [ 1017,  5242,  6794,  6731,  2044,  1037,  2305,  1997,  5948,  2357,\n",
       "            2046,  1037,  2317,  3317, 23244,  2847,  2077,  2027,  2020,  2000],\n",
       "          [17188,  7260,  2185,  2011,  7064, 16092,  2179,  4142,  2021,  2129,\n",
       "            1029,  1037,  7146,  1997,  3748, 17188,  3373,  2000,  2031,  2042],\n",
       "          [ 6405,  4203, 18856,  8486,  2696,  2082,  5008,  5694,  2006,  2346,\n",
       "            2000,  7233,  1024,  6745,  2054,  2323,  2031,  2042,  1037,  3671],\n",
       "          [ 1996,  9832,  2732,  1997,  2026,  2155,  1005,  1055, 15060,  2795,\n",
       "            2009,  1005,  1055,  2524,  2000,  3342,  2166,  2077, 22953, 21408],\n",
       "          [12669,  4819,  2928,  2571,  1998, 18520,  7207, 10082,  2985,  1996,\n",
       "            5027,  2362,  2012, 10729,  5974,  9151, 12669,  4819,  2928,  2571],\n",
       "          [ 2280,  2167,  3792,  2110,  1010,  6452,  2447,  4938, 24665,  8630,\n",
       "            2100,  8289,  1999, 21690,  1010,  2610,  2360,  4938, 24665,  8630],\n",
       "          [ 5594, 15060, 19328,  2017,  2064,  2191,  3805,  2460,  2006,  2051,\n",
       "            1029,  2770,  2041,  1997, 17428,  2686,  1029,  2182,  2024,  2070],\n",
       "          [12084, 10584, 25019, 17845,  1998,  3870, 21388, 11246, 12134,  2005,\n",
       "            2037,  4506, 12084, 10584, 25019, 17845,  1998,  3870, 21388, 11246],\n",
       "          [ 6969, 12017,  1010, 11928,  2050, 16216, 20473,  2024,  5306,  1010,\n",
       "            2667,  2000,  2994,  1005,  2659,  6337,  1005,  6969, 12017,  1010],\n",
       "          [ 2045,  1005,  1055,  1037,  2173,  1999,  1996,  2149,  2073,  2049,\n",
       "            2042,  2058,  3770,  5445,  2144,  2233,  1996,  4633,  2326,  4311],\n",
       "          [ 4202,  9170, 16360,  4978,  2067,  2012,  2502,  3698,  1010,  4447,\n",
       "            2016,  1005,  1055,  2941, 12232,  1002,  1021,  1012,  1023,  2454],\n",
       "          [ 1996,  2087,  5720,  2055,  3185,  5312,  1997,  1996, 26817,  2292,\n",
       "            1005,  1055,  3046,  2000, 17902,  1996,  3893,  1010,  2021,  2045],\n",
       "          [19337, 11319,  3600, 12934,  2015,  2591,  2865,  1999,  7928,  2006,\n",
       "            9674,  5043,  3021, 19337, 11319,  3600,  2001,  2010,  4050,  2969],\n",
       "          [ 2410,  4436,  2339,  1005,  1055,  3017, 23524, 25967,  6373,  2005,\n",
       "            9179,  1005,  1996,  2317,  3124,  1005,  1999,  1996,  2210, 22322],\n",
       "          [ 5764,  4658,  6627,  9604,  3087,  2052,  2022, 16082,  2000,  4374,\n",
       "            2292,  1005,  1055,  2227,  2009,  1024,  3071,  4122,  1996, 14751]]]),\n",
       " 'his_encoded_index': tensor([[[ 1005,  5217,  1997,  7280,  1005,  4113, 18058, 26316,  1010,  2125,\n",
       "            1996, 15168,  4955,  2057,  1005,  1040,  2066,  2000,  9611,  1996],\n",
       "          [ 2524,  2600,  3309,  2047,  5979,  7859,  1024,  2280,  2609,  3992,\n",
       "           21094,  1999,  8332,  3992,  4787, 27838, 28989,  2499,  2006,  1996],\n",
       "          [27357, 21301,  2386,  4269,  3827,  6251,  2005,  2267, 20247,  8040,\n",
       "            3286,  1996,  3883,  2097,  5247,  2403,  2420,  2503,  1037,  2976],\n",
       "          [ 6058,  5085, 12642, 16655, 22425,  2214,  2911, 13088, 11012,  2013,\n",
       "            1005, 16685,  1997,  1996,  4448,  1005,  1037,  3522,  4040,  2006],\n",
       "          [14381,  1005,  1055,  2003,  4855,  1037,  6209, 13896,  8094,  2005,\n",
       "            1002, 11176,  1010,  2199,  2169,  4653,  3397,  2484,  5167,  2164],\n",
       "          [ 2023,  5854,  3380,  2663,  2638, 16078,  2080,  2003,  3458, 23677,\n",
       "            2005, 10470,  2006,  3288,  1037,  9117,  1024,  1996,  2087, 11951],\n",
       "          [18669, 29504,  4115,  2003,  1005,  7078, 10215,  1005,  2044,  2108,\n",
       "            2718,  2007,  2047,  3715, 18669, 29504,  4115,  2003,  1005,  7078],\n",
       "          [ 5503, 12688,  2716, 27668,  5405,  2000,  4000,  2044,  3752,  2014,\n",
       "            2338, 27668,  2347,  1005,  1056,  2469,  2129,  2014,  4654,  2052],\n",
       "          [ 8958,  4268,  2059,  1998,  2085,  1024,  2156,  2129,  2027,  1005,\n",
       "            2310,  4961,  2156,  2054,  1996,  2336,  1997,  6173,  2064,  2532],\n",
       "          [27357, 21301,  2386,  8451,  2004,  2016,  4269,  2451,  2326,  2206,\n",
       "            3827,  2713,  1996,  5179,  1011,  2095,  1011,  2214,  3883,  2001]]]),\n",
       " 'cdd_attn_mask': tensor([[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]]),\n",
       " 'his_attn_mask': tensor([[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]]),\n",
       " 'his_mask': tensor([[True, True, True, True, True, True, True, True, True, True]]),\n",
       " 'labels': tensor([[[0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]])}"
      ]
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "loader_train = DataLoader(b, batch_size=config.batch_size, pin_memory=False, num_workers=0, drop_last=False, shuffle=False, collate_fn=my_collate, sampler=None)\n",
    "record = next(iter(loader_train))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "record['cdd_attn_mask'].shape, record['cdd_encoded_index'].shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(torch.Size([10, 5, 20]), torch.Size([10, 5, 20]))"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.11",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.11 64-bit (conda)"
  },
  "interpreter": {
   "hash": "decb58d8582e8bebc2c9af4e5243ce054f2f8013c5b7e79ffbf7b8b9f3c0761b"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}