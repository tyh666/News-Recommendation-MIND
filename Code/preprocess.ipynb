{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "from transformers import AutoModel,BertModel\n",
    "\n",
    "b = BertModel.from_pretrained('bert-base-uncased')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "b.embeddings"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "BertEmbeddings(\n",
       "  (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "  (position_embeddings): Embedding(512, 768)\n",
       "  (token_type_embeddings): Embedding(2, 768)\n",
       "  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       ")"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import numpy as np\n",
    "import re\n",
    "from torch.utils.data import Dataset\n",
    "from utils.utils import newsample, getId2idx, my_collate\n",
    "from data.configs.demo import config\n",
    "from torch.utils.data import DataLoader"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "class MIND_bert(Dataset):\n",
    "    \"\"\" Map Style Dataset for MIND, use bert tokenizer\n",
    "\n",
    "    Args:\n",
    "        config(dict): pre-defined dictionary of hyper parameters\n",
    "        news_file(str): path of news_file\n",
    "        behaviors_file(str): path of behaviors_file\n",
    "        shuffle(bool): whether to shuffle the order of impressions\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, config, news_file, behaviors_file, shuffle_pos=False, validate=False):\n",
    "        from transformers import BertTokenizerFast\n",
    "        # initiate the whole iterator\n",
    "        self.npratio = config.npratio\n",
    "        self.shuffle_pos = shuffle_pos\n",
    "\n",
    "        self.news_file = news_file\n",
    "        self.behaviors_file = behaviors_file\n",
    "        self.col_spliter = '\\t'\n",
    "        self.batch_size = config.batch_size\n",
    "        self.title_size = config.title_size\n",
    "        self.abs_size = config.abs_size\n",
    "        self.his_size = config.his_size\n",
    "\n",
    "        self.k = config.k\n",
    "        self.mode = re.search(\n",
    "            'MIND/.*_(.*)/news', news_file).group(1)\n",
    "\n",
    "        # there are only two types of vocabulary\n",
    "        self.tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')\n",
    "\n",
    "        self.nid2index = getId2idx(\n",
    "            'data/dictionaries/nid2idx_{}_{}.json'.format(config.scale, self.mode))\n",
    "        self.uid2index = getId2idx(\n",
    "            'data/dictionaries/uid2idx_{}.json'.format(config.scale))\n",
    "        if validate:\n",
    "            self.mode = 'dev'\n",
    "\n",
    "        self.init_news()\n",
    "        self.init_behaviors()\n",
    "\n",
    "    def init_news(self):\n",
    "        \"\"\"\n",
    "            init news information given news file, such as news_title_array.\n",
    "        \"\"\"\n",
    "\n",
    "        # VERY IMPORTANT!!! FIXME\n",
    "        # The nid2idx dictionary must follow the original order of news in news.tsv\n",
    "\n",
    "        documents = ['hello BERT']\n",
    "\n",
    "        with open(self.news_file, \"r\", encoding='utf-8') as rd:\n",
    "            for idx in rd:\n",
    "                nid, vert, subvert, title, ab, url, _, _ = idx.strip(\"\\n\").split(self.col_spliter)\n",
    "                # concat all fields to form the document\n",
    "                # try:\n",
    "                #     self.tokenizer.tokenize(' '.join([title, ab, vert, subvert]))\n",
    "                # except:\n",
    "                #     print(' '.join([title, ab, vert, subvert]))\n",
    "                documents.append(' '.join([title, ab, vert, subvert]))\n",
    "\n",
    "        encoded_dict = self.tokenizer(documents, add_special_tokens=False, padding=True, truncation=True, max_length=512, return_tensors='np')\n",
    "        self.encoded_news = encoded_dict.input_ids\n",
    "        self.attn_mask = encoded_dict.attention_mask\n",
    "\n",
    "\n",
    "    def init_behaviors(self):\n",
    "        \"\"\"\n",
    "            init behavior logs given behaviors file.\n",
    "        \"\"\"\n",
    "        # list of list of history news index\n",
    "        self.histories = []\n",
    "        # list of user index\n",
    "        self.uindexes = []\n",
    "        # list of list of history padding length\n",
    "        self.his_pad = []\n",
    "        # list of impression indexes\n",
    "        # self.impr_indexes = []\n",
    "\n",
    "        impr_index = 0\n",
    "\n",
    "        # only store positive behavior\n",
    "        if self.mode == 'train':\n",
    "            # list of list of clicked candidate news index along with its impression index\n",
    "            self.imprs = []\n",
    "            # dictionary of list of unclicked candidate news index\n",
    "            self.negtives = {}\n",
    "\n",
    "            with open(self.behaviors_file, \"r\", encoding='utf-8') as rd:\n",
    "                for idx in rd:\n",
    "                    _, uid, time, history, impr = idx.strip(\"\\n\").split(self.col_spliter)\n",
    "                    # important to subtract 1 because all list related to behaviors start from 0\n",
    "\n",
    "                    history = [self.nid2index[i] for i in history.split()]\n",
    "                    if self.k:\n",
    "                        # guarantee there are at least k history not masked\n",
    "                        self.his_pad.append(\n",
    "                            min(max(self.his_size - len(history), 0), self.his_size - self.k))\n",
    "                    else:\n",
    "                        self.his_pad.append(max(self.his_size - len(history), 0))\n",
    "\n",
    "                    # tailor user's history or pad 0\n",
    "                    history = history[:self.his_size] + [0] * (self.his_size - len(history))\n",
    "                    impr_news = [self.nid2index[i.split(\"-\")[0]] for i in impr.split()]\n",
    "                    labels = [int(i.split(\"-\")[1]) for i in impr.split()]\n",
    "                    # user will always in uid2index\n",
    "                    uindex = self.uid2index[uid]\n",
    "\n",
    "                    # store negative samples of each impression\n",
    "                    negatives = []\n",
    "\n",
    "                    for news, label in zip(impr_news, labels):\n",
    "                        if label == 1:\n",
    "                            self.imprs.append((impr_index, news))\n",
    "                        else:\n",
    "                            negatives.append(news)\n",
    "\n",
    "                    # 1 impression correspond to 1 of each of the following properties\n",
    "                    self.histories.append(history)\n",
    "                    self.negtives[impr_index] = negatives\n",
    "                    self.uindexes.append(uindex)\n",
    "\n",
    "                    impr_index += 1\n",
    "\n",
    "        # store every behavior\n",
    "        elif self.mode == 'dev':\n",
    "            # list of every candidate news index along with its impression index and label\n",
    "            self.imprs = []\n",
    "\n",
    "            with open(self.behaviors_file, \"r\", encoding='utf-8') as rd:\n",
    "                for idx in rd:\n",
    "                    _, uid, time, history, impr = idx.strip(\"\\n\").split(self.col_spliter)\n",
    "\n",
    "                    history = [self.nid2index[i] for i in history.split()]\n",
    "                    if self.k:\n",
    "                        # guarantee there are at least k history not masked\n",
    "                        self.his_pad.append(\n",
    "                            min(max(self.his_size - len(history), 0), self.his_size - self.k))\n",
    "                    else:\n",
    "                        self.his_pad.append(max(self.his_size - len(history), 0))\n",
    "\n",
    "                    # tailor user's history or pad 0\n",
    "                    history = history[:self.his_size] + [0] * (self.his_size - len(history))\n",
    "                    impr_news = [self.nid2index[i.split(\"-\")[0]] for i in impr.split()]\n",
    "                    labels = [int(i.split(\"-\")[1]) for i in impr.split()]\n",
    "                    # user will always in uid2index\n",
    "                    uindex = self.uid2index[uid]\n",
    "\n",
    "                    # store every impression\n",
    "                    for news, label in zip(impr_news, labels):\n",
    "                        self.imprs.append((impr_index, news, label))\n",
    "\n",
    "                    # 1 impression correspond to 1 of each of the following properties\n",
    "                    self.histories.append(history)\n",
    "                    self.uindexes.append(uindex)\n",
    "\n",
    "                    impr_index += 1\n",
    "\n",
    "        # store every behavior\n",
    "        elif self.mode == 'test':\n",
    "            # list of every candidate news index along with its impression index and label\n",
    "            self.imprs = []\n",
    "\n",
    "            with open(self.behaviors_file, \"r\", encoding='utf-8') as rd:\n",
    "                for idx in rd:\n",
    "                    _, uid, time, history, impr = idx.strip(\"\\n\").split(self.col_spliter)\n",
    "\n",
    "                    history = [self.nid2index[i] for i in history.split()]\n",
    "                    if self.k:\n",
    "                        # guarantee there are at least k history not masked\n",
    "                        self.his_pad.append(\n",
    "                            min(max(self.his_size - len(history), 0), self.his_size - self.k))\n",
    "                    else:\n",
    "                        self.his_pad.append(max(self.his_size - len(history), 0))\n",
    "\n",
    "                    # tailor user's history or pad 0\n",
    "                    history = history[:self.his_size] + [0] * (self.his_size - len(history))\n",
    "                    impr_news = [self.nid2index[i] for i in impr.split()]\n",
    "                    # user will always in uid2index\n",
    "                    uindex = self.uid2index[uid]\n",
    "\n",
    "                    # store every impression\n",
    "                    for news in impr_news:\n",
    "                        self.imprs.append((impr_index, news))\n",
    "\n",
    "                    # 1 impression correspond to 1 of each of the following properties\n",
    "                    self.histories.append(history)\n",
    "                    self.uindexes.append(uindex)\n",
    "\n",
    "                    impr_index += 1\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "            return length of the whole dataset\n",
    "        \"\"\"\n",
    "        return len(self.imprs)\n",
    "\n",
    "    def __getitem__(self,index):\n",
    "        \"\"\" return data\n",
    "        Args:\n",
    "            index: the index for stored impression\n",
    "\n",
    "        Returns:\n",
    "            back_dic: dictionary of data slice\n",
    "        \"\"\"\n",
    "\n",
    "        impr = self.imprs[index] # (impression_index, news_index)\n",
    "        impr_index = impr[0]\n",
    "        impr_news = impr[1]\n",
    "\n",
    "\n",
    "        user_index = [self.uindexes[impr_index]]\n",
    "\n",
    "        # each time called to return positive one sample and its negative samples\n",
    "        if self.mode == 'train':\n",
    "            # user's unclicked news in the same impression\n",
    "            negs = self.negtives[impr_index]\n",
    "            neg_list, neg_pad = newsample(negs, self.npratio)\n",
    "\n",
    "            cdd_ids = [impr_news] + neg_list\n",
    "            label = [1] + [0] * self.npratio\n",
    "\n",
    "            if self.shuffle_pos:\n",
    "                s = np.arange(0, len(label), 1)\n",
    "                np.random.shuffle(s)\n",
    "                cdd_ids = np.asarray(cdd_ids)[s]\n",
    "                label = np.asarray(label)[s]\n",
    "\n",
    "            # true means the corresponding history news is padded\n",
    "            his_mask = np.zeros((self.his_size, 1), dtype=bool)\n",
    "            his_ids = self.histories[impr_index]\n",
    "\n",
    "            # in case the user has no history records, do not mask\n",
    "            if self.his_pad[impr_index] == self.his_size or self.his_pad[impr_index] == 0:\n",
    "                his_mask = his_mask\n",
    "            else:\n",
    "                his_mask[-self.his_pad[impr_index]:] = [True]\n",
    "\n",
    "            # pad in candidate\n",
    "            # candidate_mask = [1] * neg_pad + [0] * (self.npratio + 1 - neg_pad)\n",
    "\n",
    "            cdd_encoded_index = self.encoded_news[cdd_ids]\n",
    "            his_encoded_index = self.encoded_news[his_ids]\n",
    "            cdd_attn_mask = self.attn_mask[cdd_ids]\n",
    "            his_attn_mask = self.attn_mask[his_ids]\n",
    "\n",
    "            back_dic = {\n",
    "                \"user_index\": np.asarray(user_index),\n",
    "                # \"cdd_mask\": np.asarray(neg_pad),\n",
    "                'cdd_id': np.asarray(cdd_ids),\n",
    "                'his_id': np.asarray(his_ids),\n",
    "                \"cdd_encoded_index\": cdd_encoded_index,\n",
    "                \"his_encoded_index\": his_encoded_index,\n",
    "                \"cdd_attn_mask\": cdd_attn_mask,\n",
    "                \"his_attn_mask\": his_attn_mask,\n",
    "                \"his_mask\": his_mask,\n",
    "                \"labels\": label\n",
    "            }\n",
    "\n",
    "            return back_dic\n",
    "\n",
    "        # each time called return one sample, and no labels\n",
    "        elif self.mode == 'dev':\n",
    "            cdd_ids = [impr_news]\n",
    "\n",
    "            # true means the corresponding history news is padded\n",
    "            his_mask = np.zeros((self.his_size, 1), dtype=bool)\n",
    "            his_ids = self.histories[impr_index]\n",
    "\n",
    "            user_index = [self.uindexes[impr_index]]\n",
    "            label = impr[2]\n",
    "\n",
    "            # in case the user has no history records, do not mask\n",
    "            if self.his_pad[impr_index] == self.his_size or self.his_pad[impr_index] == 0:\n",
    "                his_mask = his_mask\n",
    "            else:\n",
    "                his_mask[-self.his_pad[impr_index]:] = [True]\n",
    "\n",
    "            cdd_encoded_index = self.encoded_news[cdd_ids]\n",
    "            his_encoded_index = self.encoded_news[his_ids]\n",
    "            cdd_attn_mask = self.attn_mask[cdd_ids]\n",
    "            his_attn_mask = self.attn_mask[his_ids]\n",
    "\n",
    "            back_dic = {\n",
    "                \"impression_index\": impr_index + 1,\n",
    "                \"user_index\": np.asarray(user_index),\n",
    "                'cdd_id': np.asarray(cdd_ids),\n",
    "                'his_id': np.asarray(his_ids),\n",
    "                \"cdd_encoded_index\": cdd_encoded_index,\n",
    "                \"his_encoded_index\": his_encoded_index,\n",
    "                \"cdd_attn_mask\": cdd_attn_mask,\n",
    "                \"his_attn_mask\": his_attn_mask,\n",
    "                \"his_mask\": his_mask,\n",
    "                \"labels\": np.asarray([label])\n",
    "            }\n",
    "            return back_dic\n",
    "\n",
    "        elif self.mode == 'test':\n",
    "            cdd_ids = [impr_news]\n",
    "\n",
    "            # true means the corresponding history news is padded\n",
    "            his_mask = np.zeros((self.his_size, 1), dtype=bool)\n",
    "            his_ids = self.histories[impr_index]\n",
    "\n",
    "            user_index = [self.uindexes[impr_index]]\n",
    "\n",
    "            # in case the user has no history records, do not mask\n",
    "            if self.his_pad[impr_index] == self.his_size or self.his_pad[impr_index] == 0:\n",
    "                his_mask = his_mask\n",
    "            else:\n",
    "                his_mask[-self.his_pad[impr_index]:] = [True]\n",
    "\n",
    "            cdd_encoded_index = self.encoded_news[cdd_ids]\n",
    "            his_encoded_index = self.encoded_news[his_ids]\n",
    "            cdd_attn_mask = self.attn_mask[cdd_ids]\n",
    "            his_attn_mask = self.attn_mask[his_ids]\n",
    "\n",
    "            back_dic = {\n",
    "                \"impression_index\": impr_index + 1,\n",
    "                \"user_index\": np.asarray(user_index),\n",
    "                'cdd_id': np.asarray(cdd_ids),\n",
    "                'his_id': np.asarray(his_ids),\n",
    "                \"cdd_encoded_index\": cdd_encoded_index,\n",
    "                \"his_encoded_index\": his_encoded_index,\n",
    "                \"cdd_attn_mask\": cdd_attn_mask,\n",
    "                \"his_attn_mask\": his_attn_mask,\n",
    "                \"his_mask\": his_mask\n",
    "            }\n",
    "            return back_dic\n",
    "\n",
    "        else:\n",
    "            raise ValueError(\"Mode {} not defined\".format(self.mode))\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "train_path = \"C:/MIND/MINDdemo_train/\"\n",
    "a = MIND_bert(config, train_path + 'news.tsv', train_path + 'behaviors.tsv')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "a[10]['cdd_encoded_index'].shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(5, 512)"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "loader_train = DataLoader(a, batch_size=config.batch_size, pin_memory=False, num_workers=0, drop_last=False, shuffle=False, collate_fn=my_collate)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "next(iter(loader_train))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "from transformers import BertTokenizerFast\n",
    "tok = BertTokenizerFast.from_pretrained('bert-base-uncased')"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['i', 'love', 'you', 'you', 'love']"
      ]
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "import torch"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "from models.Encoders.CNN import CNN_Encoder\n",
    "from models.Encoders.FIM import FIM_Encoder"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "a = CNN_Encoder()"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "TypeError",
     "evalue": "__init__() missing 1 required positional argument: 'config'",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-d948ec75f5f3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0ma\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCNN_Encoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: __init__() missing 1 required positional argument: 'config'"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "from models.Encoders.FIM import FIM_Encoder\n",
    "import torch\n",
    "from data.configs.demo import config\n",
    "config.embedding_dim = 5\n",
    "config.hidden_dim = 6\n",
    "a = torch.rand(2,3,4,5)\n",
    "\n",
    "enc = FIM_Encoder(config)\n",
    "b = enc(a)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "b[0].size(),b[1].size()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(torch.Size([2, 3, 4, 3, 6]), torch.Size([2, 3, 6]))"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "e = nn.Embedding(2,3)\n",
    "a = torch.arange(2)\n",
    "loss = (e(a)**2).sum()\n",
    "loss.backward()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "e.weight.grad"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[ 1.0602,  1.5902,  0.2758],\n",
       "        [-1.4698,  0.2487,  1.1723]])"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "e.zero_grad()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "loss = (e.weight**2).sum()\n",
    "loss.backward()\n",
    "e.weight.grad"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[ 1.0602,  1.5902,  0.2758],\n",
       "        [-1.4698,  0.2487,  1.1723]])"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.5",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('nn': conda)"
  },
  "interpreter": {
   "hash": "3eb98a31bb4fe483f921d6d3a56a708e0ea8295072fddff1b0a8d949ab7fd102"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}