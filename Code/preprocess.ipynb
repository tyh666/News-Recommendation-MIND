{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import re\n",
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import logging\n",
    "import torch\n",
    "import math\n",
    "import time\n",
    "from torch.utils.data import Dataset\n",
    "from utils.utils import newsample, getId2idx, tokenize, getVocab, my_collate, Partition_Sampler\n",
    "from data.configs.demo import config\n",
    "from torch.utils.data import DataLoader\n",
    "from collections import defaultdict\n",
    "from transformers import BertTokenizer,BertModel,BertTokenizerFast,DebertaTokenizer,DebertaTokenizerFast, AutoTokenizer\n",
    "from utils.MIND import MIND\n",
    "from utils.Manager import Manager\n",
    "\n",
    "logger = logging.getLogger(__name__)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "t = AutoTokenizer.from_pretrained('bert-base-uncased', cache_dir=config.path + \"bert_cache/\")\n",
    "t2 = DebertaTokenizerFast.from_pretrained('microsoft/deberta-base', cache_dir=config.path + \"bert_cache/\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "t.vocab['_']"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "1035"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "sorted([1031,1012,1004,1008,1006,1007,1009,1027,1013,1032,1026,1028,1010,999,1029,1025,1024,1066,1036,1030,1001,1002,1003,1034,1033,1011,1529,1035])"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "TypeError",
     "evalue": "sequence item 0: expected str instance, int found",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_402447/4092366060.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;34m\" \"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1031\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1012\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1004\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1008\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1006\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1007\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1009\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1027\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1013\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1032\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1026\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1028\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1010\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m999\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1029\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1025\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1024\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1066\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1036\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1030\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1001\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1002\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1003\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1034\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1033\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1011\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1529\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1035\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: sequence item 0: expected str instance, int found"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "t2.tokenize('Word embeddings.')"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['Word', 'Ġembed', 'd', 'ings', '.']"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "token = '[PAD]'\n",
    "t.convert_tokens_to_ids(token), t2.convert_tokens_to_ids(token)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(0, 0)"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "special_token_map = {\n",
    "    \"[CLS]\":{\n",
    "        \"bert-base-uncased\": 101,\n",
    "        \"deberta-base\": 1\n",
    "    },\n",
    "    \"SEP\":{\n",
    "        \"bert-base-uncased\": 102,\n",
    "        \"deberta-base\": 2\n",
    "    }\n",
    "}"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "t.save_pretrained('.')"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "('./vocab.txt',)"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "t.convert_tokens_to_string(['ings', '.'])"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'ings.'"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "t.tokenize(\"A is embeddings.\")"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['A', 'Ġis', 'Ġembed', 'd', 'ings', '.']"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "# config.reducer = 'bm25'\n",
    "# config.reducer = 'bow'\n",
    "# config.reducer = 'matching'\n",
    "\n",
    "# config.signal_length = 10\n",
    "# config.scale = 'large'\n",
    "# config.impr_size = 100\n",
    "# config.mode = 'test'\n",
    "\n",
    "config.bert = 'microsoft/deberta-base'\n",
    "config.embedding = 'deberta'\n",
    "\n",
    "# config.bert = 'bert-base-uncased\n",
    "# config.embedding = 'bert'\n",
    "\n",
    "manager = Manager(config)\n",
    "path = manager.path + 'MIND/MINDdemo_train/'\n",
    "a = MIND(manager, path + 'news.tsv', path + 'behaviors.tsv')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[2021-09-10 16:16:53,024] INFO (utils.MIND) encoding user behaviors of ../../../Data/MIND/MINDdemo_train/behaviors.tsv...\n",
      "2000it [00:00, 17043.71it/s]\n",
      "[2021-09-10 16:17:03,591] INFO (utils.MIND) encoding news of ../../../Data/MIND/MINDdemo_train/news.tsv...\n",
      "51282it [00:19, 2593.66it/s]\n",
      "[2021-09-10 16:17:23,392] INFO (utils.utils) computing BM25 scores...\n",
      "[2021-09-10 16:17:26,383] INFO (utils.MIND) tokenizing news...\n",
      "[2021-09-10 16:18:32,037] INFO (utils.MIND) tokenizing bm25 ordered news...\n",
      "[2021-09-10 16:18:56,648] INFO (utils.MIND) tokenizing entities...\n",
      "[2021-09-10 16:19:08,314] INFO (utils.MIND) process NO.0 loading cached user behavior from data/cache/deberta/MINDdemo_train/10/behaviors..pkl\n",
      "[2021-09-10 16:19:08,324] INFO (utils.MIND) process NO.0 loading cached news tokenization from data/cache/deberta/MINDdemo_train/news.pkl\n",
      "[2021-09-10 16:19:09,034] INFO (utils.utils) deduplicating...\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "source": [
    "parse_texts_deberta(t, [\"Trump is Elizabeth\"], 8)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(array([[   1, 7565,   16, 4690,    0,    0,    0,    0]]),\n",
       " array([[1, 1, 1, 1, 0, 0, 0, 0]]),\n",
       " array([[[0, 0],\n",
       "         [1, 1],\n",
       "         [2, 2],\n",
       "         [3, 3],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0]]]),\n",
       " array([[[0, 0],\n",
       "         [1, 1],\n",
       "         [2, 2],\n",
       "         [3, 3],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0]]]))"
      ]
     },
     "metadata": {},
     "execution_count": 25
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "source": [
    "t.convert_ids_to_tokens([   1, 7565,   16, 4690,    0,    0,    0,    0])"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['[CLS]', 'Trump', 'Ġis', 'ĠElizabeth', '[PAD]', '[PAD]', '[PAD]', '[PAD]']"
      ]
     },
     "metadata": {},
     "execution_count": 26
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "tokens = t.tokenize(\"[CLS] I love you embeddings.\")\n",
    "tokens"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['[CLS]', 'ĠI', 'Ġlove', 'Ġyou', 'Ġembed', 'd', 'ings', '.']"
      ]
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "news = pickle.load(open('/data/workspace/Peitian/Code/Document-Reduction/Code/data/cache/deberta/MINDdemo_train/news.pkl', 'rb'))\n",
    "ids = news['encoded_news']\n",
    "subwords = news['subwords_all']"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "t.convert_tokens_to_ids([i for i in r\"[.&*()+=/\\<>,!?;:~`@#$%^]\"])"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[1031,\n",
       " 1012,\n",
       " 1004,\n",
       " 1008,\n",
       " 1006,\n",
       " 1007,\n",
       " 1009,\n",
       " 1027,\n",
       " 1013,\n",
       " 1032,\n",
       " 1026,\n",
       " 1028,\n",
       " 1010,\n",
       " 999,\n",
       " 1029,\n",
       " 1025,\n",
       " 1024,\n",
       " 1066,\n",
       " 1036,\n",
       " 1030,\n",
       " 1001,\n",
       " 1002,\n",
       " 1003,\n",
       " 1034,\n",
       " 1033]"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.11",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.11 64-bit (conda)"
  },
  "interpreter": {
   "hash": "decb58d8582e8bebc2c9af4e5243ce054f2f8013c5b7e79ffbf7b8b9f3c0761b"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}