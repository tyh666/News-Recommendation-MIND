{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import re\n",
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import logging\n",
    "import torch\n",
    "import math\n",
    "import time\n",
    "from torch.utils.data import Dataset\n",
    "from utils.utils import newsample, getId2idx, tokenize, getVocab, my_collate, Partition_Sampler\n",
    "from data.configs.demo import config\n",
    "from torch.utils.data import DataLoader\n",
    "from collections import defaultdict\n",
    "\n",
    "from transformers import BertTokenizer,BertModel,BertTokenizerFast\n",
    "from utils.MIND import MIND\n",
    "\n",
    "logger = logging.getLogger(__name__)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "# config.reducer = 'bm25'\n",
    "# config.reducer = 'bow'\n",
    "# config.reducer = 'matching'\n",
    "\n",
    "# config.signal_length = 10\n",
    "# config.scale = 'large'\n",
    "# config.impr_size = 100\n",
    "# config.mode = 'test'\n",
    "\n",
    "path = config.path + 'MIND/MINDdemo_train/'\n",
    "a = MIND(config, path + 'news.tsv', path + 'behaviors.tsv')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[2021-08-31 12:50:10,648] INFO (utils.MIND) encoding user behaviors of ../../../Data/MIND/MINDdemo_train/behaviors.tsv...\n",
      "[2021-08-31 12:50:10,789] INFO (utils.MIND) encoding news of ../../../Data/MIND/MINDdemo_train/news.tsv...\n",
      "[2021-08-31 12:51:27,106] INFO (utils.MIND) reducing news of ../../../Data/MIND/MINDdemo_train/news.tsv...\n",
      "[2021-08-31 12:51:27,110] INFO (utils.utils) unmasking at least k...\n",
      "[2021-08-31 12:51:27,420] INFO (utils.utils) deduplicating...\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "a.encoded_news[3][:110]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([  101,  1996,  3465,  1997,  8398,  1005,  1055,  4681, 13184,\n",
       "        1999,  1996, 19874,  1997,  5924,  1005,  1055,  2162,  8318,\n",
       "        1012,  7332,  9587, 29358,  7231,  3215, 18652,  2058,  1037,\n",
       "       27372,  1997,  5472,  8641,  2012,  1996,  2392,  2240,  1997,\n",
       "        1996,  2162,  1999,  5924,  1012,  2279,  2000,  2032,  2001,\n",
       "        2019,  4064, 10412, 16863,  2039,  2000,  7577, 17515,  2015,\n",
       "        1010,  2525,  2566, 29278,  4383,  2007,  3674,  8198,  1012,\n",
       "        2739,  2739, 11108,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0])"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "t.convert_ids_to_tokens(a.encoded_news[3][:110])"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['[CLS]',\n",
       " 'the',\n",
       " 'cost',\n",
       " 'of',\n",
       " 'trump',\n",
       " \"'\",\n",
       " 's',\n",
       " 'aid',\n",
       " 'freeze',\n",
       " 'in',\n",
       " 'the',\n",
       " 'trenches',\n",
       " 'of',\n",
       " 'ukraine',\n",
       " \"'\",\n",
       " 's',\n",
       " 'war',\n",
       " 'lt',\n",
       " '.',\n",
       " 'ivan',\n",
       " 'mo',\n",
       " '##lch',\n",
       " '##ane',\n",
       " '##ts',\n",
       " 'peeked',\n",
       " 'over',\n",
       " 'a',\n",
       " 'parapet',\n",
       " 'of',\n",
       " 'sand',\n",
       " 'bags',\n",
       " 'at',\n",
       " 'the',\n",
       " 'front',\n",
       " 'line',\n",
       " 'of',\n",
       " 'the',\n",
       " 'war',\n",
       " 'in',\n",
       " 'ukraine',\n",
       " '.',\n",
       " 'next',\n",
       " 'to',\n",
       " 'him',\n",
       " 'was',\n",
       " 'an',\n",
       " 'empty',\n",
       " 'helmet',\n",
       " 'propped',\n",
       " 'up',\n",
       " 'to',\n",
       " 'trick',\n",
       " 'sniper',\n",
       " '##s',\n",
       " ',',\n",
       " 'already',\n",
       " 'per',\n",
       " '##for',\n",
       " '##ated',\n",
       " 'with',\n",
       " 'multiple',\n",
       " 'holes',\n",
       " '.',\n",
       " 'news',\n",
       " 'news',\n",
       " '##world',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]']"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "a.subwords[3][:110]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[ 0,  0],\n",
       "       [ 1,  1],\n",
       "       [ 2,  2],\n",
       "       [ 3,  3],\n",
       "       [ 4,  4],\n",
       "       [ 5,  5],\n",
       "       [ 6,  6],\n",
       "       [ 7,  7],\n",
       "       [ 8,  8],\n",
       "       [ 9,  9],\n",
       "       [10, 10],\n",
       "       [11, 11],\n",
       "       [12, 12],\n",
       "       [13, 13],\n",
       "       [14, 14],\n",
       "       [15, 15],\n",
       "       [16, 16],\n",
       "       [17, 17],\n",
       "       [18, 18],\n",
       "       [19, 19],\n",
       "       [20, 20],\n",
       "       [20, 21],\n",
       "       [20, 22],\n",
       "       [20, 23],\n",
       "       [21, 24],\n",
       "       [22, 25],\n",
       "       [23, 26],\n",
       "       [24, 27],\n",
       "       [25, 28],\n",
       "       [26, 29],\n",
       "       [27, 30],\n",
       "       [28, 31],\n",
       "       [29, 32],\n",
       "       [30, 33],\n",
       "       [31, 34],\n",
       "       [32, 35],\n",
       "       [33, 36],\n",
       "       [34, 37],\n",
       "       [35, 38],\n",
       "       [36, 39],\n",
       "       [37, 40],\n",
       "       [38, 41],\n",
       "       [39, 42],\n",
       "       [40, 43],\n",
       "       [41, 44],\n",
       "       [42, 45],\n",
       "       [43, 46],\n",
       "       [44, 47],\n",
       "       [45, 48],\n",
       "       [46, 49],\n",
       "       [47, 50],\n",
       "       [48, 51],\n",
       "       [49, 52],\n",
       "       [49, 53],\n",
       "       [50, 54],\n",
       "       [51, 55],\n",
       "       [52, 56],\n",
       "       [52, 57],\n",
       "       [52, 58],\n",
       "       [53, 59],\n",
       "       [54, 60],\n",
       "       [55, 61],\n",
       "       [56, 62],\n",
       "       [57, 63],\n",
       "       [58, 64],\n",
       "       [58, 65],\n",
       "       [ 0,  0],\n",
       "       [ 0,  0],\n",
       "       [ 0,  0],\n",
       "       [ 0,  0],\n",
       "       [ 0,  0],\n",
       "       [ 0,  0],\n",
       "       [ 0,  0],\n",
       "       [ 0,  0],\n",
       "       [ 0,  0],\n",
       "       [ 0,  0],\n",
       "       [ 0,  0],\n",
       "       [ 0,  0],\n",
       "       [ 0,  0],\n",
       "       [ 0,  0],\n",
       "       [ 0,  0],\n",
       "       [ 0,  0],\n",
       "       [ 0,  0],\n",
       "       [ 0,  0],\n",
       "       [ 0,  0],\n",
       "       [ 0,  0],\n",
       "       [ 0,  0],\n",
       "       [ 0,  0],\n",
       "       [ 0,  0],\n",
       "       [ 0,  0],\n",
       "       [ 0,  0],\n",
       "       [ 0,  0],\n",
       "       [ 0,  0],\n",
       "       [ 0,  0],\n",
       "       [ 0,  0],\n",
       "       [ 0,  0],\n",
       "       [ 0,  0],\n",
       "       [ 0,  0],\n",
       "       [ 0,  0],\n",
       "       [ 0,  0],\n",
       "       [ 0,  0],\n",
       "       [ 0,  0],\n",
       "       [ 0,  0],\n",
       "       [ 0,  0],\n",
       "       [ 0,  0],\n",
       "       [ 0,  0],\n",
       "       [ 0,  0],\n",
       "       [ 0,  0],\n",
       "       [ 0,  0],\n",
       "       [ 0,  0]])"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "loader1 = DataLoader(a, batch_size=1, pin_memory=False, num_workers=0, drop_last=False, shuffle=False, sampler=Partition_Sampler(a,2,0))\n",
    "records1 = list(loader1"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "records1[0]['his_attn_mask']"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[[1., 1., 1.,  ..., 0., 0., 0.],\n",
       "         [1., 1., 1.,  ..., 0., 0., 0.],\n",
       "         [1., 1., 1.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]]])"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "dic = pickle.load(open('/data/workspace/Peitian/Code/Document-Reduction/Code/data/cache/bert/MINDdemo_train/news.pkl', 'rb'))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "sb = dic['subwords_first']\n",
    "sb"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([list([]),\n",
       "       list([[0, 0], [1, 1], [2, 2], [3, 3], [4, 4], [5, 5], [6, 6], [7, 7], [8, 8], [9, 9], [10, 10], [11, 11], [12, 12], [13, 13], [14, 14], [15, 15], [16, 16], [0, 0], [17, 18], [18, 19], [19, 20], [20, 21], [21, 22], [22, 23], [23, 24], [24, 25], [25, 26], [26, 27], [27, 28], [28, 29], [29, 30], [30, 31], [31, 32], [32, 33], [0, 0], [0, 0]]),\n",
       "       list([[0, 0], [1, 1], [2, 2], [3, 3], [4, 4], [5, 5], [6, 6], [7, 7], [8, 8], [9, 9], [10, 10], [11, 11], [12, 12], [13, 13], [14, 14], [15, 15], [16, 16], [17, 17], [18, 18], [19, 19], [0, 0], [20, 21], [21, 22], [22, 23], [23, 24], [24, 25], [25, 26], [26, 27], [27, 28], [28, 29], [0, 0], [0, 0]]),\n",
       "       ...,\n",
       "       list([[0, 0], [1, 1], [2, 2], [3, 3], [4, 4], [5, 5], [6, 6], [7, 7], [8, 8], [9, 9], [10, 10], [11, 11], [12, 12], [13, 13], [14, 14], [15, 15], [16, 16], [17, 17], [18, 18], [19, 19], [0, 0], [20, 21], [21, 22], [22, 23], [23, 24], [24, 25], [25, 26], [26, 27], [27, 28], [28, 29], [29, 30], [30, 31], [31, 32], [32, 33], [33, 34], [34, 35], [35, 36], [36, 37], [37, 38], [38, 39], [39, 40], [40, 41], [41, 42], [42, 43], [43, 44], [44, 45], [45, 46], [46, 47], [47, 48], [48, 49], [49, 50], [50, 51], [51, 52], [52, 53], [53, 54], [54, 55], [55, 56], [56, 57], [57, 58], [58, 59], [59, 60], [60, 61], [61, 62], [62, 63], [63, 64], [64, 65], [65, 66], [66, 67], [67, 68], [68, 69], [69, 70], [70, 71], [0, 0], [71, 73], [72, 74], [73, 75], [74, 76], [75, 77], [76, 78], [77, 79], [78, 80], [79, 81], [80, 82], [81, 83], [82, 84], [83, 85], [84, 86], [85, 87], [86, 88], [87, 89], [88, 90], [89, 91], [90, 92], [91, 93], [92, 94], [93, 95], [94, 96], [95, 97], [96, 98], [97, 99], [98, 100], [99, 101], [100, 102], [101, 103], [102, 104], [103, 105], [104, 106], [105, 107], [106, 108], [107, 109], [108, 110], [109, 111], [110, 112], [111, 113], [112, 114], [113, 115], [114, 116], [115, 117], [116, 118], [117, 119], [118, 120]]),\n",
       "       list([[0, 0], [1, 1], [2, 2], [3, 3], [0, 0], [4, 5], [5, 6], [6, 7], [7, 8], [8, 9], [9, 10], [10, 11], [11, 12], [12, 13], [13, 14], [14, 15], [15, 16], [16, 17], [17, 18], [18, 19], [0, 0], [19, 21], [20, 22], [21, 23], [22, 24], [23, 25], [24, 26], [0, 0]]),\n",
       "       list([[0, 0], [1, 1], [2, 2], [3, 3], [4, 4], [5, 5], [6, 6], [7, 7], [0, 0], [8, 9], [0, 0], [0, 0]])],\n",
       "      dtype=object)"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "np.unique(a[:,0]),a"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(array([0, 1, 2, 3, 4, 5, 6, 7, 8]),\n",
       " array([[0, 0],\n",
       "        [1, 1],\n",
       "        [2, 2],\n",
       "        [2, 3],\n",
       "        [3, 4],\n",
       "        [4, 5],\n",
       "        [5, 6],\n",
       "        [6, 7],\n",
       "        [7, 8],\n",
       "        [8, 9]]))"
      ]
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "t = BertTokenizerFast.from_pretrained('bert-base-uncased')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "t.tokenize(\"I don't give a fuck\")"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['i', 'don', \"'\", 't', 'give', 'a', 'fuck']"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.11",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.11 64-bit (conda)"
  },
  "interpreter": {
   "hash": "decb58d8582e8bebc2c9af4e5243ce054f2f8013c5b7e79ffbf7b8b9f3c0761b"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}