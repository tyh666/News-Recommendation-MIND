{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import re\n",
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import logging\n",
    "import torch\n",
    "import math\n",
    "import time\n",
    "from datetime import datetime\n",
    "from torch.utils.data import Dataset\n",
    "from utils.utils import newsample, getId2idx, tokenize, getVocab, my_collate, Partition_Sampler\n",
    "from data.configs.demo import config\n",
    "from torch.utils.data import DataLoader\n",
    "from collections import defaultdict\n",
    "from transformers import BertTokenizer,BertModel,BertTokenizerFast,DebertaTokenizer,DebertaTokenizerFast, AutoTokenizer\n",
    "from utils.MIND import MIND\n",
    "from utils.Manager import Manager\n",
    "\n",
    "logger = logging.getLogger(__name__)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "t = AutoTokenizer.from_pretrained('bert-base-uncased', cache_dir=config.path + \"bert_cache/\")\n",
    "# t2 = DebertaTokenizerFast.from_pretrained('microsoft/deberta-base', cache_dir=config.path + \"bert_cache/\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# config.reducer = 'bm25'\n",
    "# config.reducer = 'bow'\n",
    "# config.reducer = 'matching'\n",
    "\n",
    "# config.signal_length = 10\n",
    "# config.scale = 'large'\n",
    "# config.impr_size = 100\n",
    "# config.mode = 'dev'\n",
    "# config.scale = 'large'\n",
    "\n",
    "# config.bert = 'microsoft/deberta-base'\n",
    "# config.embedding = 'deberta'\n",
    "\n",
    "# config.bert = 'bert-base-uncased\n",
    "# config.embedding = 'bert'\n",
    "\n",
    "manager = Manager(config)\n",
    "# manager.gather_same_user_impr()\n",
    "a = MIND(manager)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from utils.MIND import MIND_news, MIND_history\n",
    "b = MIND_news(manager)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "manager.fast = True\n",
    "\n",
    "loaders = manager.prepare()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "x = list(loaders[2])[85]['cdd_subword_index']"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "news = pickle.load(open('/data/workspace/Peitian/Code/Document-Reduction/Code/data/cache/bert/MINDlarge_test/news.pkl', 'rb'))\n",
    "ids = news['encoded_news']\n",
    "subwords = news['subwords_all']"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "a = c\n",
    "\n",
    "news = t.convert_ids_to_tokens(a[0]['his_encoded_index'][1])\n",
    "mask = a[0]['his_attn_mask'][1]\n",
    "word = manager.convert_tokens_to_words(news)\n",
    "subword = a[0]['his_subword_index'][1]\n",
    "dedup = a[0]['his_refined_mask'][1]\n",
    "\n",
    "for i,j,k,z in zip(news,mask,subword,dedup):\n",
    "    print(i,j,k,z)"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.11",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.11 64-bit (conda)"
  },
  "interpreter": {
   "hash": "decb58d8582e8bebc2c9af4e5243ce054f2f8013c5b7e79ffbf7b8b9f3c0761b"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}