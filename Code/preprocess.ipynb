{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import re\n",
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import logging\n",
    "import torch\n",
    "import math\n",
    "from torch.utils.data import Dataset\n",
    "from utils.utils import newsample, getId2idx, tokenize, getVocab, my_collate, Partition_Sampler\n",
    "from data.configs.demo import config\n",
    "from torch.utils.data import DataLoader\n",
    "from collections import defaultdict\n",
    "\n",
    "from transformers import BertTokenizer,BertModel\n",
    "from utils.MIND import MIND\n",
    "\n",
    "logger = logging.getLogger(__name__)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "class MIND(Dataset):\n",
    "    \"\"\" Map Style Dataset for MIND, use bert tokenizer\n",
    "\n",
    "    Args:\n",
    "        config(dict): pre-defined dictionary of hyper parameters\n",
    "        news_file(str): path of news_file\n",
    "        behaviors_file(str): path of behaviors_file\n",
    "        shuffle(bool): whether to shuffle the order of impressions\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, config, news_file, behaviors_file, shuffle_pos=False):\n",
    "        # initiate the whole iterator\n",
    "        self.npratio = config.npratio\n",
    "        self.shuffle_pos = shuffle_pos\n",
    "        self.signal_length = config.signal_length\n",
    "        self.his_size = config.his_size\n",
    "        self.impr_size = config.impr_size\n",
    "        self.k = config.k\n",
    "        self.order_history = config.order_history\n",
    "        pat = re.search('MIND/(.*_(.*)/)news', news_file)\n",
    "        self.mode = pat.group(2)\n",
    "\n",
    "        self.cache_directory = '/'.join(['data/cache', config.embedding, pat.group(1)])\n",
    "        self.behav_path = self.cache_directory + '{}/{}'.format(self.impr_size, re.search('(\\w*\\.)tsv', behaviors_file).group(1) + '.pkl')\n",
    "\n",
    "        if os.path.exists(self.behav_path):\n",
    "            logger.info('using cached user behavior from {}'.format(self.behav_path))\n",
    "            with open(self.behav_path, 'rb') as f:\n",
    "                behaviors = pickle.load(f)\n",
    "                for k,v in behaviors.items():\n",
    "                    setattr(self, k, v)\n",
    "\n",
    "        else:\n",
    "            if config.rank in [-1, 0]:\n",
    "                logger.info(\"encoding user behaviors of {}...\".format(behaviors_file))\n",
    "                os.makedirs(self.cache_directory + str(self.impr_size), exist_ok=True)\n",
    "                self.behaviors_file = behaviors_file\n",
    "                self.nid2index = getId2idx('data/dictionaries/nid2idx_{}_{}.json'.format(config.scale, self.mode))\n",
    "                self.uid2index = getId2idx('data/dictionaries/uid2idx_{}.json'.format(config.scale))\n",
    "\n",
    "                self.init_behaviors()\n",
    "\n",
    "        self.reducer = config.reducer\n",
    "\n",
    "        if config.reducer == 'bm25':\n",
    "            self.news_path = self.cache_directory + 'news_bm25.pkl'\n",
    "            if os.path.exists(self.news_path):\n",
    "                logger.info('using cached news tokenization from {}'.format(self.news_path))\n",
    "                with open(self.news_path, 'rb') as f:\n",
    "                    news = pickle.load(f)\n",
    "                    for k,v in news.items():\n",
    "                        setattr(self, k, v)\n",
    "            else:\n",
    "                if config.rank in [-1, 0]:\n",
    "                    from transformers import BertTokenizerFast\n",
    "                    from utils.utils import BM25\n",
    "                    logger.info(\"encoding news of {}...\".format(news_file))\n",
    "                    self.news_file = news_file\n",
    "                    self.max_news_length = 512\n",
    "                    # there are only two types of vocabulary\n",
    "                    self.tokenizer = BertTokenizerFast.from_pretrained(config.bert, cache=config.path + 'bert_cache/')\n",
    "                    self.nid2index = getId2idx('data/dictionaries/nid2idx_{}_{}.json'.format(config.scale, self.mode))\n",
    "                    self.init_news(reducer=BM25())\n",
    "\n",
    "        else:\n",
    "            self.news_path = self.cache_directory + 'news.pkl'\n",
    "            if os.path.exists(self.news_path):\n",
    "                logger.info('using cached news tokenization from {}'.format(self.news_path))\n",
    "                with open(self.news_path, 'rb') as f:\n",
    "                    news = pickle.load(f)\n",
    "                    for k,v in news.items():\n",
    "                        setattr(self, k, v)\n",
    "            else:\n",
    "                if config.rank in [-1, 0]:\n",
    "                    from transformers import BertTokenizerFast\n",
    "                    logger.info(\"encoding news of {}...\".format(news_file))\n",
    "                    self.news_file = news_file\n",
    "                    self.max_news_length = 512\n",
    "                    # there are only two types of vocabulary\n",
    "                    self.tokenizer = BertTokenizerFast.from_pretrained(config.bert, cache=config.path + 'bert_cache/')\n",
    "                    self.nid2index = getId2idx('data/dictionaries/nid2idx_{}_{}.json'.format(config.scale, self.mode))\n",
    "                    self.init_news()\n",
    "\n",
    "\n",
    "    def init_news(self, reducer=None):\n",
    "        \"\"\"\n",
    "            init news information given news file, such as news_title_array.\n",
    "\n",
    "        Args:\n",
    "            bm25: whether to sort the terms by bm25 score\n",
    "        \"\"\"\n",
    "\n",
    "        # VERY IMPORTANT!!! FIXME\n",
    "        # The nid2idx dictionary must follow the original order of news in news.tsv\n",
    "\n",
    "        documents = ['']\n",
    "\n",
    "        with open(self.news_file, \"r\", encoding='utf-8') as rd:\n",
    "            for idx in rd:\n",
    "                nid, vert, subvert, title, ab, url, _, _ = idx.strip(\"\\n\").split('\\t')\n",
    "                documents.append(' '.join(['[CLS]', title, ab, vert, subvert]))\n",
    "\n",
    "        if reducer:\n",
    "            encoded_dict = self.tokenizer(documents, add_special_tokens=False, padding=True, truncation=True, max_length=self.max_news_length, return_tensors='np')\n",
    "            self.encoded_news = encoded_dict.input_ids\n",
    "            self.attn_mask = encoded_dict.attention_mask\n",
    "\n",
    "            documents_sorted, attn_mask_sorted = reducer(self.encoded_news)\n",
    "            print(attn_mask_sorted)\n",
    "\n",
    "            self.encoded_news_sorted = documents_sorted\n",
    "            self.attn_mask_sorted = attn_mask_sorted * self.attn_mask\n",
    "\n",
    "            with open(self.news_path, 'wb') as f:\n",
    "                pickle.dump(\n",
    "                    {\n",
    "                        'encoded_news': self.encoded_news,\n",
    "                        'encoded_news_sorted': self.encoded_news_sorted,\n",
    "                        'attn_mask': self.attn_mask,\n",
    "                        'attn_mask_sorted': self.attn_mask_sorted\n",
    "                    },\n",
    "                    f\n",
    "                )\n",
    "        else:\n",
    "            encoded_dict = self.tokenizer(documents, add_special_tokens=False, padding=True, truncation=True, max_length=self.max_news_length, return_tensors='np')\n",
    "            self.encoded_news = encoded_dict.input_ids\n",
    "            self.attn_mask = encoded_dict.attention_mask\n",
    "\n",
    "            with open(self.news_path, 'wb') as f:\n",
    "                pickle.dump(\n",
    "                    {\n",
    "                        'encoded_news': self.encoded_news,\n",
    "                        'attn_mask': self.attn_mask\n",
    "                    },\n",
    "                    f\n",
    "                )\n",
    "\n",
    "\n",
    "    def init_behaviors(self):\n",
    "        \"\"\"\n",
    "            init behavior logs given behaviors file.\n",
    "        \"\"\"\n",
    "        # list of list of history news index\n",
    "        histories = []\n",
    "        # list of user index\n",
    "        uindexes = []\n",
    "        # list of impression indexes\n",
    "        # self.impr_indexes = []\n",
    "\n",
    "        impr_index = 0\n",
    "\n",
    "        # only store positive behavior\n",
    "        if self.mode == 'train':\n",
    "            # list of lists, each list represents a\n",
    "            imprs = []\n",
    "            negatives = []\n",
    "\n",
    "            with open(self.behaviors_file, \"r\", encoding='utf-8') as rd:\n",
    "                for idx in rd:\n",
    "                    _, uid, time, history, impr = idx.strip(\"\\n\").split('\\t')\n",
    "\n",
    "                    history = [self.nid2index[i] for i in history.split()]\n",
    "\n",
    "                    impr_news = [self.nid2index[i.split(\"-\")[0]] for i in impr.split()]\n",
    "                    labels = [int(i.split(\"-\")[1]) for i in impr.split()]\n",
    "\n",
    "                    # user will always in uid2index\n",
    "                    uindex = self.uid2index[uid]\n",
    "                    # store negative samples of each impression\n",
    "                    negative = []\n",
    "\n",
    "                    for news, label in zip(impr_news, labels):\n",
    "                        if label == 1:\n",
    "                            imprs.append((impr_index, news))\n",
    "                        else:\n",
    "                            negative.append(news)\n",
    "\n",
    "                    # 1 impression correspond to 1 of each of the following properties\n",
    "                    histories.append(history)\n",
    "                    negatives.append(negative)\n",
    "                    uindexes.append(uindex)\n",
    "\n",
    "                    impr_index += 1\n",
    "\n",
    "            self.imprs = imprs\n",
    "            self.histories = histories\n",
    "            self.negatives = negatives\n",
    "            self.uindexes = uindexes\n",
    "\n",
    "            save_dict = {\n",
    "                'imprs': self.imprs,\n",
    "                'histories': self.histories,\n",
    "                'negatives': self.negatives,\n",
    "                'uindexes': self.uindexes\n",
    "            }\n",
    "\n",
    "        # store every behavior\n",
    "        elif self.mode == 'dev':\n",
    "            # list of every cdd news index along with its impression index and label\n",
    "            imprs = []\n",
    "\n",
    "            with open(self.behaviors_file, \"r\", encoding='utf-8') as rd:\n",
    "                for idx in rd:\n",
    "                    _, uid, time, history, impr = idx.strip(\"\\n\").split('\\t')\n",
    "\n",
    "                    history = [self.nid2index[i] for i in history.split()]\n",
    "\n",
    "                    impr_news = [self.nid2index[i.split(\"-\")[0]] for i in impr.split()]\n",
    "                    labels = [int(i.split(\"-\")[1]) for i in impr.split()]\n",
    "                    # user will always in uid2index\n",
    "                    uindex = self.uid2index[uid]\n",
    "\n",
    "                    # store every impression\n",
    "                    for i in range(0, len(impr_news), self.impr_size):\n",
    "                        imprs.append((impr_index, impr_news[i:i+self.impr_size], labels[i:i+self.impr_size]))\n",
    "\n",
    "                    # 1 impression correspond to 1 of each of the following properties\n",
    "                    histories.append(history)\n",
    "                    uindexes.append(uindex)\n",
    "\n",
    "                    impr_index += 1\n",
    "\n",
    "            self.imprs = imprs\n",
    "            self.histories = histories\n",
    "            self.uindexes = uindexes\n",
    "\n",
    "            save_dict = {\n",
    "                'imprs': self.imprs,\n",
    "                'histories': self.histories,\n",
    "                'uindexes': self.uindexes\n",
    "            }\n",
    "\n",
    "        # store every behavior\n",
    "        elif self.mode == 'test':\n",
    "            # list of every cdd news index along with its impression index and label\n",
    "            imprs = []\n",
    "\n",
    "            with open(self.behaviors_file, \"r\", encoding='utf-8') as rd:\n",
    "                for idx in rd:\n",
    "                    _, uid, time, history, impr = idx.strip(\"\\n\").split('\\t')\n",
    "\n",
    "                    history = [self.nid2index[i] for i in history.split()]\n",
    "\n",
    "                    impr_news = [self.nid2index[i] for i in impr.split()]\n",
    "                    # user will always in uid2index\n",
    "                    uindex = self.uid2index[uid]\n",
    "\n",
    "                    # store every impression\n",
    "                    for i in range(0, len(impr_news), self.impr_size):\n",
    "                        imprs.append((impr_index, impr_news[i:i+self.impr_size]))\n",
    "\n",
    "                    # 1 impression correspond to 1 of each of the following properties\n",
    "                    histories.append(history)\n",
    "                    uindexes.append(uindex)\n",
    "\n",
    "                    impr_index += 1\n",
    "\n",
    "            self.imprs = imprs\n",
    "            self.histories = histories\n",
    "            self.uindexes = uindexes\n",
    "\n",
    "            save_dict = {\n",
    "                'imprs': self.imprs,\n",
    "                'histories': self.histories,\n",
    "                'uindexes': self.uindexes\n",
    "            }\n",
    "\n",
    "        with open(self.behav_path, 'wb') as f:\n",
    "            pickle.dump(save_dict, f)\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "            return length of the whole dataset\n",
    "        \"\"\"\n",
    "        return len(self.imprs)\n",
    "\n",
    "    def __getitem__(self,index):\n",
    "        \"\"\" return data\n",
    "        Args:\n",
    "            index: the index for stored impression\n",
    "\n",
    "        Returns:\n",
    "            back_dic: dictionary of data slice\n",
    "        \"\"\"\n",
    "\n",
    "        impr = self.imprs[index] # (impression_index, news_index)\n",
    "        impr_index = impr[0]\n",
    "        impr_news = impr[1]\n",
    "\n",
    "\n",
    "        user_index = [self.uindexes[impr_index]]\n",
    "\n",
    "        # each time called to return positive one sample and its negative samples\n",
    "        if self.mode == 'train':\n",
    "            # user's unhis news in the same impression\n",
    "            negs = self.negatives[impr_index]\n",
    "            neg_list, neg_pad = newsample(negs, self.npratio)\n",
    "\n",
    "            cdd_ids = [impr_news] + neg_list\n",
    "            label = np.asarray([1] + [0] * self.npratio)\n",
    "\n",
    "            if self.shuffle_pos:\n",
    "                s = np.arange(0, len(label), 1)\n",
    "                np.random.shuffle(s)\n",
    "                cdd_ids = np.asarray(cdd_ids)[s]\n",
    "                label = np.asarray(label)[s]\n",
    "\n",
    "            label = np.arange(0, len(cdd_ids), 1)[label == 1][0]\n",
    "\n",
    "            his_ids = self.histories[impr_index][:self.his_size]\n",
    "            # true means the corresponding history news is padded\n",
    "            his_mask = np.zeros((self.his_size), dtype=bool)\n",
    "            his_mask[:len(his_ids)] = 1\n",
    "\n",
    "            if self.order_history:\n",
    "                his_ids = his_ids + [0] * (self.his_size - len(his_ids))\n",
    "            else:\n",
    "                his_ids = his_ids[::-1] + [0] * (self.his_size - len(his_ids))\n",
    "\n",
    "            # pad in cdd\n",
    "            # cdd_mask = [1] * neg_pad + [0] * (self.npratio + 1 - neg_pad)\n",
    "\n",
    "            cdd_encoded_index = self.encoded_news[cdd_ids][:, :self.signal_length]\n",
    "            cdd_attn_mask = self.attn_mask[cdd_ids][:, :self.signal_length]\n",
    "            if self.reducer == 'bm25':\n",
    "                his_encoded_index = self.encoded_news_sorted[his_ids][:, :self.k + 1]\n",
    "                his_attn_mask = self.attn_mask_sorted[his_ids][:, :self.k + 1]\n",
    "            else:\n",
    "                his_encoded_index = self.encoded_news[his_ids][:, :self.signal_length]\n",
    "                his_attn_mask = self.attn_mask[his_ids][:, :self.signal_length]\n",
    "                his_attn_mask[:, :self.k+1] = 1\n",
    "\n",
    "            back_dic = {\n",
    "                \"user_index\": np.asarray(user_index),\n",
    "                # \"cdd_mask\": np.asarray(neg_pad),\n",
    "                'cdd_id': np.asarray(cdd_ids),\n",
    "                'his_id': np.asarray(his_ids),\n",
    "                \"cdd_encoded_index\": cdd_encoded_index,\n",
    "                \"his_encoded_index\": his_encoded_index,\n",
    "                \"cdd_attn_mask\": cdd_attn_mask,\n",
    "                \"his_attn_mask\": his_attn_mask,\n",
    "                \"his_mask\": his_mask,\n",
    "                \"label\": label\n",
    "            }\n",
    "\n",
    "            return back_dic\n",
    "\n",
    "        # each time called return one sample, and no labels\n",
    "        elif self.mode == 'dev':\n",
    "            cdd_ids = impr_news\n",
    "\n",
    "            his_ids = self.histories[impr_index][:self.his_size]\n",
    "            # true means the corresponding history news is padded\n",
    "            his_mask = np.zeros((self.his_size), dtype=bool)\n",
    "            his_mask[:len(his_ids)] = 1\n",
    "\n",
    "            if self.order_history:\n",
    "                his_ids = his_ids + [0] * (self.his_size - len(his_ids))\n",
    "            else:\n",
    "                his_ids = his_ids[::-1] + [0] * (self.his_size - len(his_ids))\n",
    "\n",
    "            user_index = [self.uindexes[impr_index]]\n",
    "            label = impr[2]\n",
    "\n",
    "            cdd_encoded_index = self.encoded_news[cdd_ids][:, :self.signal_length]\n",
    "            cdd_attn_mask = self.attn_mask[cdd_ids][:, :self.signal_length]\n",
    "            if self.reducer == 'bm25':\n",
    "                his_encoded_index = self.encoded_news_sorted[his_ids][:, :self.k + 1]\n",
    "                his_attn_mask = self.attn_mask_sorted[his_ids][:, :self.k + 1]\n",
    "            else:\n",
    "                his_encoded_index = self.encoded_news[his_ids][:, :self.signal_length]\n",
    "                his_attn_mask = self.attn_mask[his_ids][:, :self.signal_length]\n",
    "                his_attn_mask[:, :self.k+1] = 1\n",
    "\n",
    "            back_dic = {\n",
    "                \"impr_index\": impr_index + 1,\n",
    "                \"user_index\": np.asarray(user_index),\n",
    "                'cdd_id': np.asarray(cdd_ids),\n",
    "                'his_id': np.asarray(his_ids),\n",
    "                \"cdd_encoded_index\": cdd_encoded_index,\n",
    "                \"his_encoded_index\": his_encoded_index,\n",
    "                \"cdd_attn_mask\": cdd_attn_mask,\n",
    "                \"his_attn_mask\": his_attn_mask,\n",
    "                \"his_mask\": his_mask,\n",
    "                \"label\": np.asarray(label)\n",
    "            }\n",
    "            return back_dic\n",
    "\n",
    "        elif self.mode == 'test':\n",
    "            cdd_ids = impr_news\n",
    "\n",
    "            his_ids = self.histories[impr_index][:self.his_size]\n",
    "            # true means the corresponding history news is padded\n",
    "            his_mask = np.zeros((self.his_size), dtype=bool)\n",
    "            his_mask[:len(his_ids)] = 1\n",
    "\n",
    "            if self.order_history:\n",
    "                his_ids = his_ids + [0] * (self.his_size - len(his_ids))\n",
    "            else:\n",
    "                his_ids = his_ids[::-1] + [0] * (self.his_size - len(his_ids))\n",
    "\n",
    "            user_index = [self.uindexes[impr_index]]\n",
    "\n",
    "            cdd_encoded_index = self.encoded_news[cdd_ids][:, :self.signal_length]\n",
    "            cdd_attn_mask = self.attn_mask[cdd_ids][:, :self.signal_length]\n",
    "            if self.reducer == 'bm25':\n",
    "                his_encoded_index = self.encoded_news_sorted[his_ids][:, :self.k + 1]\n",
    "                his_attn_mask = self.attn_mask_sorted[his_ids][:, :self.k + 1]\n",
    "            else:\n",
    "                his_encoded_index = self.encoded_news[his_ids][:, :self.signal_length]\n",
    "                his_attn_mask = self.attn_mask[his_ids][:, :self.signal_length]\n",
    "                his_attn_mask[:, :self.k+1] = 1\n",
    "\n",
    "            back_dic = {\n",
    "                \"impr_index\": impr_index + 1,\n",
    "                \"user_index\": np.asarray(user_index),\n",
    "                'cdd_id': np.asarray(cdd_ids),\n",
    "                'his_id': np.asarray(his_ids),\n",
    "                \"cdd_encoded_index\": cdd_encoded_index,\n",
    "                \"his_encoded_index\": his_encoded_index,\n",
    "                \"cdd_attn_mask\": cdd_attn_mask,\n",
    "                \"his_attn_mask\": his_attn_mask,\n",
    "                \"his_mask\": his_mask\n",
    "            }\n",
    "            return back_dic\n",
    "\n",
    "        else:\n",
    "            raise ValueError(\"Mode {} not defined\".format(self.mode))\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "config.reducer = 'bm25'\n",
    "# config.reducer = 'matching'\n",
    "\n",
    "path = config.path + 'MIND/MINDdemo_dev/'\n",
    "a = MIND(config, path + 'news.tsv', path + 'behaviors.tsv')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[2021-08-19 22:06:27,570] INFO (__main__) using cached user behavior from data/cache/bert/MINDdemo_dev/10/behaviors..pkl\n",
      "[2021-08-19 22:06:27,576] INFO (__main__) encoding news of ../../../Data/MIND/MINDdemo_dev/news.tsv...\n",
      "[2021-08-19 22:06:47,171] INFO (utils.utils) computing BM25 scores...\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[1 0 0 ... 0 0 0]\n",
      " [1 1 1 ... 0 0 0]\n",
      " [1 1 1 ... 0 0 0]\n",
      " ...\n",
      " [1 1 1 ... 0 0 0]\n",
      " [1 1 1 ... 0 0 0]\n",
      " [1 1 1 ... 0 0 0]]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "a[1]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'impr_index': 1,\n",
       " 'user_index': array([1929]),\n",
       " 'cdd_id': array([38581, 39227, 37368, 33705, 39921, 39640, 36275, 38848,  7014,\n",
       "        37943]),\n",
       " 'his_id': array([36210,  1692, 30302, 26650, 12951, 30833, 35479, 30270,  1736,\n",
       "        18228, 32139, 32731, 15796, 34171,  7499,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0]),\n",
       " 'cdd_encoded_index': array([[  101,  1996,  9832,  2732,  1997,  2026,  2155,  1005,  1055,\n",
       "         15060,  2795,  2009,  1005,  1055,  2524,  2000,  3342,  2166,\n",
       "          2077, 22953, 21408,  3669,  8808,  5785, 16220, 10624,  2571,\n",
       "          1012,  2030,  1010,  1038,  1012,  1038,  1012,  1039,  1012,\n",
       "          1054,  1012,  1039,  1012,  1041,  1012,  1006,  2077, 22953,\n",
       "         21408,  3669,  8808,  5785, 16220, 10624,  2571,  3690,  1007,\n",
       "          1012,  2054,  2106,  1996,  5035,  6338,  2031,  2000,  2298,\n",
       "          2830,  2000,  2296, 15060,  2077,  1996, 18178,  2229,  2100,\n",
       "          2155,  1011,  5440,  2217,  9841,  3133,  2256,  3268],\n",
       "        [  101, 12669,  4819,  2928,  2571,  1998, 18520,  7207, 10082,\n",
       "          2985,  1996,  5027,  2362,  2012, 10729,  5974,  9151, 12669,\n",
       "          4819,  2928,  2571, 18675, 18520,  7207,  2000,  2014, 10729,\n",
       "          5974,  9151,  2188,  9580,  9580, 13238,  9777,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0],\n",
       "        [  101,  2280,  2167,  3792,  2110,  1010,  6452,  2447,  4938,\n",
       "         24665,  8630,  2100,  8289,  1999, 21690,  1010,  2610,  2360,\n",
       "          4938, 24665,  8630,  2100,  5652,  2012,  2167,  3792,  2110,\n",
       "          2077,  2652, 12145,  1012,  2002,  2001,  2730,  1999,  1037,\n",
       "         21690,  9432,  1999, 11577,  1012,  2998,  2062,  1035,  2998,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0],\n",
       "        [  101,  5594, 15060, 19328,  2017,  2064,  2191,  3805,  2460,\n",
       "          2006,  2051,  1029,  2770,  2041,  1997, 17428,  2686,  1029,\n",
       "          2182,  2024,  2070,  2191,  1011,  3805, 10447,  2005,  1037,\n",
       "         25180,  3238,  9831,  1012,  2833,  5685, 13626, 19839,  4248,\n",
       "          5685,  5243,  6508,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0],\n",
       "        [  101, 12084, 10584, 25019, 17845,  1998,  3870, 21388, 11246,\n",
       "         12134,  2005,  2037,  4506, 12084, 10584, 25019, 17845,  1998,\n",
       "          3870, 21388, 11246,  6866, 25380,  2000, 10474,  2044,  2027,\n",
       "          2020,  3491,  2006, 18182,  2478,  1037,  3507, 10832,  1005,\n",
       "          1055,  6101,  2466,  2000,  2037,  5056,  1999,  1996,  2208,\n",
       "          2694,  2694,  2638,  9333,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0],\n",
       "        [  101,  6969, 12017,  1010, 11928,  2050, 16216, 20473,  2024,\n",
       "          5306,  1010,  2667,  2000,  2994,  1005,  2659,  6337,  1005,\n",
       "          6969, 12017,  1010, 11928,  2050, 16216, 20473,  2024,  5306,\n",
       "          1010,  2667,  2000,  2994,  1005,  2659,  6337,  1005,  2694,\n",
       "          2694,  1011,  8958,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0],\n",
       "        [  101,  2045,  1005,  1055,  1037,  2173,  1999,  1996,  2149,\n",
       "          2073,  2049,  2042,  2058,  3770,  5445,  2144,  2233,  1996,\n",
       "          4633,  2326,  4311,  1996,  2197,  2051,  1996,  3679,  2152,\n",
       "          2001,  2917,  3770,  5445,  2001,  2006,  2233,  2676,  2043,\n",
       "          1996,  2152,  2069,  2584,  6275,  5445,  1011,  1011,  2029,\n",
       "          1010,  2292,  1005,  1055,  2022,  7481,  1010,  2003,  2145,\n",
       "          3492,  4010,  1012,  4633,  4633, 25181, 29469,  2229,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0],\n",
       "        [  101,  4202,  9170, 16360,  4978,  2067,  2012,  2502,  3698,\n",
       "          1010,  4447,  2016,  1005,  1055,  2941, 12232,  1002,  1021,\n",
       "          1012,  1023,  2454,  1999, 23850, 25335,  4202,  9170,  1005,\n",
       "          1055,  2136, 16412,  2000,  2502,  3698,  1005,  1055, 14920,\n",
       "          1012,  2189,  2189,  2638,  9333,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0],\n",
       "        [  101,  1996,  2087,  5720,  2055,  3185,  5312,  1997,  1996,\n",
       "         26817,  2292,  1005,  1055,  3046,  2000, 17902,  1996,  3893,\n",
       "          1010,  2021,  2045,  1005,  1055,  2028,  3327,  5537,  2008,\n",
       "          2001,  2061,  2569,  1999,  2049,  9643,  2791,  1010,  2009,\n",
       "          2018,  2000,  2175,  2006,  2023,  2862,  1012,  2156,  2065,\n",
       "          2017,  2064,  3984,  2029,  2028,  2009,  2003,  1012,  5691,\n",
       "          5691,  1011,  3916,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0],\n",
       "        [  101, 19337, 11319,  3600, 12934,  2015,  2591,  2865,  1999,\n",
       "          7928,  2006,  9674,  5043,  3021, 19337, 11319,  3600,  2001,\n",
       "          2010,  4050,  2969,  2750,  1996,  2012, 22571,  7476,  6214,\n",
       "          2008,  2253,  2006,  2076,  1996, 13240,  1011, 15280,  2208,\n",
       "          9432,  2305,  1012,  2998,  2374,  1035,  5088,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0]]),\n",
       " 'his_encoded_index': array([[  101, 22758,  3193,  7658],\n",
       "        [  101,  9025, 11802, 17500],\n",
       "        [  101, 25664, 10297, 10851],\n",
       "        [  101, 24352,  5477, 23191],\n",
       "        [  101, 12078, 16641, 18934],\n",
       "        [  101,  8451,  3827, 27357],\n",
       "        [  101, 12582, 14517, 20016],\n",
       "        [  101, 27668, 12688,  2338],\n",
       "        [  101, 10215, 29504,  7078],\n",
       "        [  101,  3380, 11951,  7958],\n",
       "        [  101, 16527, 27212, 19688],\n",
       "        [  101, 16685, 14621, 12006],\n",
       "        [  101, 27357, 21301, 20247],\n",
       "        [  101,  3992, 28989,  8332],\n",
       "        [  101,  4955, 10503, 10149],\n",
       "        [  101,     0,     0,     0],\n",
       "        [  101,     0,     0,     0],\n",
       "        [  101,     0,     0,     0],\n",
       "        [  101,     0,     0,     0],\n",
       "        [  101,     0,     0,     0],\n",
       "        [  101,     0,     0,     0],\n",
       "        [  101,     0,     0,     0],\n",
       "        [  101,     0,     0,     0],\n",
       "        [  101,     0,     0,     0],\n",
       "        [  101,     0,     0,     0],\n",
       "        [  101,     0,     0,     0],\n",
       "        [  101,     0,     0,     0],\n",
       "        [  101,     0,     0,     0],\n",
       "        [  101,     0,     0,     0],\n",
       "        [  101,     0,     0,     0],\n",
       "        [  101,     0,     0,     0],\n",
       "        [  101,     0,     0,     0],\n",
       "        [  101,     0,     0,     0],\n",
       "        [  101,     0,     0,     0],\n",
       "        [  101,     0,     0,     0],\n",
       "        [  101,     0,     0,     0],\n",
       "        [  101,     0,     0,     0],\n",
       "        [  101,     0,     0,     0],\n",
       "        [  101,     0,     0,     0],\n",
       "        [  101,     0,     0,     0],\n",
       "        [  101,     0,     0,     0],\n",
       "        [  101,     0,     0,     0],\n",
       "        [  101,     0,     0,     0],\n",
       "        [  101,     0,     0,     0],\n",
       "        [  101,     0,     0,     0],\n",
       "        [  101,     0,     0,     0],\n",
       "        [  101,     0,     0,     0],\n",
       "        [  101,     0,     0,     0],\n",
       "        [  101,     0,     0,     0],\n",
       "        [  101,     0,     0,     0]]),\n",
       " 'cdd_attn_mask': array([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]),\n",
       " 'his_attn_mask': array([[1, 1, 1, 1],\n",
       "        [1, 1, 1, 1],\n",
       "        [1, 1, 1, 1],\n",
       "        [1, 1, 1, 1],\n",
       "        [1, 1, 1, 1],\n",
       "        [1, 1, 1, 1],\n",
       "        [1, 1, 1, 1],\n",
       "        [1, 1, 1, 1],\n",
       "        [1, 1, 1, 1],\n",
       "        [1, 1, 1, 1],\n",
       "        [1, 1, 1, 1],\n",
       "        [1, 1, 1, 1],\n",
       "        [1, 1, 1, 1],\n",
       "        [1, 1, 1, 1],\n",
       "        [1, 1, 1, 1],\n",
       "        [0, 0, 0, 0],\n",
       "        [0, 0, 0, 0],\n",
       "        [0, 0, 0, 0],\n",
       "        [0, 0, 0, 0],\n",
       "        [0, 0, 0, 0],\n",
       "        [0, 0, 0, 0],\n",
       "        [0, 0, 0, 0],\n",
       "        [0, 0, 0, 0],\n",
       "        [0, 0, 0, 0],\n",
       "        [0, 0, 0, 0],\n",
       "        [0, 0, 0, 0],\n",
       "        [0, 0, 0, 0],\n",
       "        [0, 0, 0, 0],\n",
       "        [0, 0, 0, 0],\n",
       "        [0, 0, 0, 0],\n",
       "        [0, 0, 0, 0],\n",
       "        [0, 0, 0, 0],\n",
       "        [0, 0, 0, 0],\n",
       "        [0, 0, 0, 0],\n",
       "        [0, 0, 0, 0],\n",
       "        [0, 0, 0, 0],\n",
       "        [0, 0, 0, 0],\n",
       "        [0, 0, 0, 0],\n",
       "        [0, 0, 0, 0],\n",
       "        [0, 0, 0, 0],\n",
       "        [0, 0, 0, 0],\n",
       "        [0, 0, 0, 0],\n",
       "        [0, 0, 0, 0],\n",
       "        [0, 0, 0, 0],\n",
       "        [0, 0, 0, 0],\n",
       "        [0, 0, 0, 0],\n",
       "        [0, 0, 0, 0],\n",
       "        [0, 0, 0, 0],\n",
       "        [0, 0, 0, 0],\n",
       "        [0, 0, 0, 0]]),\n",
       " 'his_mask': array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False]),\n",
       " 'label': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0])}"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "a.attn_mask_sorted"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [1, 1, 1, ..., 0, 0, 0],\n",
       "       [1, 1, 1, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [1, 1, 1, ..., 0, 0, 0],\n",
       "       [1, 1, 1, ..., 0, 0, 0],\n",
       "       [1, 1, 1, ..., 0, 0, 0]])"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "t = BertTokenizer.from_pretrained('bert-base-uncased')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "t('')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "loader1 = DataLoader(a, batch_size=1, pin_memory=False, num_workers=0, drop_last=False, shuffle=False)\n",
    "records1 = list(loader1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "records1[0]['his_id'], records1[0]['his_mask'] "
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(tensor([[36210,  1692, 30302, 26650, 12951, 30833, 35479, 30270,  1736, 18228,\n",
       "          32139, 32731, 15796, 34171,  7499,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0]]),\n",
       " tensor([[ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "           True,  True,  True,  True,  True, False, False, False, False, False,\n",
       "          False, False, False, False, False, False, False, False, False, False,\n",
       "          False, False, False, False, False, False, False, False, False, False,\n",
       "          False, False, False, False, False, False, False, False, False, False]]))"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "t = BertTokenizer.from_pretrained('bert-base-uncased')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.11",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.11 64-bit (conda)"
  },
  "interpreter": {
   "hash": "decb58d8582e8bebc2c9af4e5243ce054f2f8013c5b7e79ffbf7b8b9f3c0761b"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}