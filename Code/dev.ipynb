{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import torch\r\n",
    "import torch.nn as nn"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "a = torch.tensor([[1.,2,3],[4,5,6]])\r\n",
    "b = nn.Embedding.from_pretrained(a, freeze=False)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "loss = b(torch.tensor([0])).sum()\r\n",
    "loss.backward()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "'fast' in 'dev_fast'"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import re\r\n",
    "import logging\r\n",
    "import torch\r\n",
    "import numpy as np\r\n",
    "import torch.nn as nn\r\n",
    "import torch.nn.functional as F\r\n",
    "import math\r\n",
    "import time\r\n",
    "import pickle\r\n",
    "from collections import defaultdict\r\n",
    "from data.configs.demo import config\r\n",
    "from collections import defaultdict\r\n",
    "\r\n",
    "from transformers import AutoTokenizer, AutoModel, BertModel, BertConfig\r\n",
    "from utils.Manager import Manager\r\n",
    "\r\n",
    "from models.Embeddings.BERT import BERT_Embedding\r\n",
    "from models.Encoders.CNN import CNN_Encoder,CNN_User_Encoder\r\n",
    "from models.Encoders.RNN import RNN_Encoder,RNN_User_Encoder\r\n",
    "from models.Encoders.MHA import MHA_Encoder, MHA_User_Encoder\r\n",
    "from models.Modules.DRM import Matching_Reducer, Slicing_Reducer\r\n",
    "from models.Rankers.BERT import BERT_Onepass_Ranker, BERT_Original_Ranker\r\n",
    "from models.Rankers.CNN import CNN_Ranker\r\n",
    "from models.Encoders.Pooling import Attention_Pooling, Average_Pooling\r\n",
    "\r\n",
    "from models.Encoders.BERT import BERT_Encoder\r\n",
    "from models.Encoders.Pooling import *\r\n",
    "\r\n",
    "from models.ESM import ESM\r\n",
    "from models.TTMS import TTMS\r\n",
    " \r\n",
    "from models.Modules.Attention import MultiheadAttention, get_attn_mask, XSoftmax\r\n",
    "torch.set_printoptions(threshold=100000)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "one_pass_attn = torch.cat([torch.eye(4).repeat_interleave(2,dim=-1).repeat_interleave(2,dim=0), torch.ones(8,4)], dim=-1).unsqueeze(0)\r\n",
    "attn_mask = torch.tensor([[1,1,1,0,1,1,0,0,1,1,0,0], [1,0,1,0,1,1,0,0,1,1,1,0]])\r\n",
    "attn_mask = get_attn_mask(attn_mask).squeeze(1)\r\n",
    "one_pass_attn * attn_mask[:,:8]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[[1., 1., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0.],\n",
       "         [1., 1., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0.],\n",
       "         [0., 0., 1., 0., 0., 0., 0., 0., 1., 1., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 1., 1., 0., 0., 1., 1., 0., 0.],\n",
       "         [0., 0., 0., 0., 1., 1., 0., 0., 1., 1., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
       "\n",
       "        [[1., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 1., 0., 0., 0., 0., 0., 1., 1., 1., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 1., 1., 0., 0., 1., 1., 1., 0.],\n",
       "         [0., 0., 0., 0., 1., 1., 0., 0., 1., 1., 1., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]])"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# m = AutoModel.from_pretrained('bert-base-uncased',cache_dir=config.path + 'bert_cache/')\n",
    "# m2 = AutoModel.from_pretrained('microsoft/deberta-base',cache_dir=config.path + 'bert_cache/')\n",
    "# m3 = AutoModel.from_pretrained(\"microsoft/unilm-base-cased\",cache_dir=config.path + 'bert_cache/')\n",
    "\n",
    "# t = AutoTokenizer.from_pretrained('bert-base-uncased', cache_dir=config.path + \"bert_cache/\")\n",
    "# t2 = DebertaTokenizerFast.from_pretrained('microsoft/deberta-base', cache_dir=config.path + \"bert_cache/\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "# config.reducer = 'entity'\n",
    "# config.embedding = 'deberta'\n",
    "# config.bert = 'microsoft/deberta-base'\n",
    "# config.device = 0\n",
    "\n",
    "manager = Manager(config)\n",
    "loaders = manager.prepare()\n",
    "X1 = list(loaders[0])\n",
    "X2 = list(loaders[1])\n",
    "x1 = X1[0]\n",
    "x2 = X2[0]"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[2021-09-27 16:31:25,074] INFO (utils.Manager) Hyper Parameters are \n",
      "{\n",
      "    \"scale\": \"demo\",\n",
      "    \"mode\": \"tune\",\n",
      "    \"batch_size\": 5,\n",
      "    \"k\": 5,\n",
      "    \"threshold\": -Infinity,\n",
      "    \"abs_length\": 40,\n",
      "    \"signal_length\": 100,\n",
      "    \"his_size\": 50,\n",
      "    \"cdd_size\": 5,\n",
      "    \"impr_size\": 10,\n",
      "    \"dropout_p\": 0.2,\n",
      "    \"lr\": 0.0001,\n",
      "    \"bert_lr\": 3e-05,\n",
      "    \"embedding\": \"bert\",\n",
      "    \"encoderN\": \"cnn\",\n",
      "    \"encoderU\": \"rnn\",\n",
      "    \"selector\": \"sfi\",\n",
      "    \"reducer\": \"matching\",\n",
      "    \"ranker\": \"onepass\",\n",
      "    \"embedding_dim\": 768,\n",
      "    \"hidden_dim\": 384,\n",
      "    \"base_rank\": 0,\n",
      "    \"world_size\": 0,\n",
      "    \"seed\": 42,\n",
      "    \"granularity\": \"avg\",\n",
      "    \"debias\": false,\n",
      "    \"full_attn\": true,\n",
      "    \"ascend_history\": false,\n",
      "    \"save_pos\": false,\n",
      "    \"sep_his\": false,\n",
      "    \"diversify\": false,\n",
      "    \"no_dedup\": false,\n",
      "    \"no_order_embed\": false,\n",
      "    \"no_rm_punc\": false,\n",
      "    \"scheduler\": \"linear\",\n",
      "    \"warmup\": 100,\n",
      "    \"shuffle\": false,\n",
      "    \"bert\": \"bert-base-uncased\",\n",
      "    \"tb\": false\n",
      "}\n",
      "[2021-09-27 16:31:25,075] INFO (utils.Manager) preparing dataset...\n",
      "[2021-09-27 16:31:25,078] INFO (utils.MIND) process NO.0 loading cached user behavior from data/cache/bert/MINDdemo_train/10/behaviors..pkl\n",
      "[2021-09-27 16:31:25,094] INFO (utils.MIND) process NO.0 loading cached news tokenization from data/cache/bert/MINDdemo_train/news.pkl\n",
      "[2021-09-27 16:31:26,291] INFO (utils.utils) deduplicating...\n",
      "[2021-09-27 16:31:27,934] INFO (utils.MIND) process NO.0 loading cached user behavior from data/cache/bert/MINDdemo_dev/10/behaviors..pkl\n",
      "[2021-09-27 16:31:27,937] INFO (utils.MIND) process NO.0 loading cached news tokenization from data/cache/bert/MINDdemo_dev/news.pkl\n",
      "[2021-09-27 16:31:28,680] INFO (utils.utils) deduplicating...\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "embedding = BERT_Embedding(manager)\n",
    "\n",
    "encoderN = CNN_Encoder(manager)\n",
    "# encoderN = RNN_Encoder(manager)\n",
    "# encoderN = MHA_Encoder(manager)\n",
    "\n",
    "# encoderU = CNN_User_Encoder(manager)\n",
    "encoderU = RNN_User_Encoder(manager)\n",
    "# encoderU = MHA_User_Encoder(manager)\n",
    "# encoderU = Attention_Pooling(manager)\n",
    "# encoderU = Average_Pooling(manager)\n",
    "\n",
    "reducer = Matching_Reducer(manager)\n",
    "# reducer = Slicing_Reducer(manager)\n",
    "\n",
    "# ranker = CNN_Ranker(manager)\n",
    "ranker = BERT_Onepass_Ranker(manager)\n",
    "# ranker = BERT_Original_Ranker(manager)\n",
    "\n",
    "# model = TTMS(manager, embedding, encoderN, encoderU, reducer).to(manager.device)\n",
    "model = ESM(manager, embedding, encoderN, encoderU, reducer, ranker).to(manager.device)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "# model.eval()\n",
    "# a,b = model(x2)\n",
    "\n",
    "a,b = model(x1)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.8",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.8 64-bit ('nn': conda)"
  },
  "interpreter": {
   "hash": "9616ec0cf0e0dd041cba3c8886d471a5cc72bbf20e2c795f4079199200777fdd"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}