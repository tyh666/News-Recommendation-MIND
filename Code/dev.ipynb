{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import re\n",
    "import logging\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "import time\n",
    "import pickle\n",
    "# from thop import profile\n",
    "from collections import defaultdict\n",
    "from data.configs.demo import config\n",
    "from collections import defaultdict\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModel, BertModel, BertConfig, AutoModelForSequenceClassification\n",
    "from utils.Manager import Manager\n",
    "\n",
    "from models.Embeddings.BERT import BERT_Embedding\n",
    "from models.Encoders.CNN import CNN_Encoder,CNN_User_Encoder\n",
    "from models.Encoders.RNN import RNN_Encoder,RNN_User_Encoder\n",
    "from models.Encoders.MHA import MHA_Encoder, MHA_User_Encoder\n",
    "from models.Modules.DRM import Matching_Reducer, Identical_Reducer\n",
    "from models.Rankers.BERT import BERT_Onepass_Ranker, BERT_Original_Ranker\n",
    "from models.Rankers.CNN import CNN_Ranker\n",
    "from models.Encoders.Pooling import Attention_Pooling, Average_Pooling\n",
    "from models.UniLM.modeling import TuringNLRv3Model, TuringNLRv3ForSequenceClassification, relative_position_bucket\n",
    "from models.UniLM.configuration_tnlrv3 import TuringNLRv3Config\n",
    "\n",
    "from models.TwoTowerBaseModel import TwoTowerBaseModel\n",
    "\n",
    "from models.Encoders.BERT import BERT_Encoder\n",
    "from models.Encoders.Pooling import *\n",
    "\n",
    "from models.TESRec import TESRec\n",
    "from models.XFormer import XFormer\n",
    " \n",
    "from models.Modules.Attention import MultiheadAttention, get_attn_mask, XSoftmax\n",
    "torch.set_printoptions(threshold=100000)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "# m = AutoModel.from_pretrained('bert-base-uncased',cache_dir=config.path + 'bert_cache/')\n",
    "# m2 = AutoModel.from_pretrained('microsoft/deberta-base',cache_dir=config.path + 'bert_cache/')\n",
    "# m3 = TuringNLRv3ForSequenceClassification.from_pretrained(config.unilm_path, config=TuringNLRv3Config.from_pretrained(config.unilm_config_path))\n",
    "# m4 = AutoModel.from_pretrained('google/reformer-crime-and-punishment', cache_dir=config.path + \"bert_cache/\")\n",
    "\n",
    "# t = AutoTokenizer.from_pretrained('bert-base-uncased', cache_dir=config.path + \"bert_cache/\")\n",
    "# t2 = AutoTokenizer.from_pretrained('microsoft/deberta-base', cache_dir=config.path + \"bert_cache/\")\n",
    "# t3 = AutoTokenizer.from_pretrained('allenai/longformer-base-4096', cache_dir=config.path + \"bert_cache/\")\n",
    "t4 = AutoTokenizer.from_pretrained('google/reformer-crime-and-punishment', cache_dir=config.path + \"bert_cache/\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "t4.convert_ids_to_tokens(1)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'<s>'"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "source": [
    "t4.pad_token = t4.eos_token\n",
    "x = t4(\"He loves embedings\", return_tensors=\"pt\", padding=\"max_length\", max_length=20, add_special_tokens=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "source": [
    "output = m4(**x)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/data/v-pezhang/nn/lib/python3.8/site-packages/transformers/models/reformer/modeling_reformer.py:1164: UserWarning: where received a uint8 condition tensor. This behavior is deprecated and will be removed in a future version of PyTorch. Use a boolean condition instead. (Triggered internally at  ../aten/src/ATen/native/TensorCompare.cpp:255.)\n",
      "  query_key_dots = torch.where(mask, query_key_dots, mask_value)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "source": [
    "output[0].shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([1, 20, 512])"
      ]
     },
     "metadata": {},
     "execution_count": 29
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "source": [
    "t4.convert_ids_to_tokens(2)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'</s>'"
      ]
     },
     "metadata": {},
     "execution_count": 33
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "source": [
    "m4.config.hidden_dropout_prob"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "ReformerConfig {\n",
       "  \"_name_or_path\": \"google/reformer-crime-and-punishment\",\n",
       "  \"architectures\": [\n",
       "    \"ReformerModelWithLMHead\"\n",
       "  ],\n",
       "  \"attention_head_size\": 64,\n",
       "  \"attention_probs_dropout_prob\": 0.1,\n",
       "  \"attn_layers\": [\n",
       "    \"local\",\n",
       "    \"lsh\",\n",
       "    \"local\",\n",
       "    \"lsh\",\n",
       "    \"local\",\n",
       "    \"lsh\"\n",
       "  ],\n",
       "  \"axial_norm_std\": 1.0,\n",
       "  \"axial_pos_embds\": true,\n",
       "  \"axial_pos_embds_dim\": [\n",
       "    64,\n",
       "    192\n",
       "  ],\n",
       "  \"axial_pos_shape\": [\n",
       "    512,\n",
       "    1024\n",
       "  ],\n",
       "  \"chunk_size_lm_head\": 0,\n",
       "  \"classifier_dropout\": null,\n",
       "  \"eos_token_id\": 2,\n",
       "  \"feed_forward_size\": 512,\n",
       "  \"hash_seed\": null,\n",
       "  \"hidden_act\": \"relu\",\n",
       "  \"hidden_dropout_prob\": 0.05,\n",
       "  \"hidden_size\": 256,\n",
       "  \"initializer_range\": 0.02,\n",
       "  \"intermediate_size\": 3072,\n",
       "  \"is_decoder\": true,\n",
       "  \"layer_norm_eps\": 1e-12,\n",
       "  \"local_attention_probs_dropout_prob\": 0.05,\n",
       "  \"local_attn_chunk_length\": 64,\n",
       "  \"local_num_chunks_after\": 0,\n",
       "  \"local_num_chunks_before\": 1,\n",
       "  \"lsh_attention_probs_dropout_prob\": 0.0,\n",
       "  \"lsh_attn_chunk_length\": 64,\n",
       "  \"lsh_num_chunks_after\": 0,\n",
       "  \"lsh_num_chunks_before\": 1,\n",
       "  \"max_position_embeddings\": 524288,\n",
       "  \"model_type\": \"reformer\",\n",
       "  \"num_attention_heads\": 2,\n",
       "  \"num_buckets\": [\n",
       "    64,\n",
       "    128\n",
       "  ],\n",
       "  \"num_chunks_after\": 0,\n",
       "  \"num_chunks_before\": 1,\n",
       "  \"num_hashes\": 1,\n",
       "  \"num_hidden_layers\": 6,\n",
       "  \"output_past\": true,\n",
       "  \"pad_token_id\": 0,\n",
       "  \"task_specific_params\": {\n",
       "    \"text-generation\": {\n",
       "      \"do_sample\": true,\n",
       "      \"max_length\": 100\n",
       "    }\n",
       "  },\n",
       "  \"tie_word_embeddings\": false,\n",
       "  \"transformers_version\": \"4.10.0\",\n",
       "  \"use_cache\": true,\n",
       "  \"vocab_size\": 320\n",
       "}"
      ]
     },
     "metadata": {},
     "execution_count": 35
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# config.reducer = 'entity'\n",
    "# config.embedding = 'deberta'\n",
    "# config.bert = 'longformer'\n",
    "# config.seed = None\n",
    "config.mode = \"recall\"\n",
    "config.recall_type = \"s\"\n",
    "config.scale = \"large\"\n",
    "config.case = False\n",
    "\n",
    "manager = Manager(config)\n",
    "\n",
    "loaders = manager.prepare()\n",
    "X1 = list(loaders[0])\n",
    "# X2 = list(loaders[1])\n",
    "x1 = X1[0]\n",
    "# x2 = X2[0]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "embedding = BERT_Embedding(manager)\n",
    "\n",
    "encoderN = CNN_Encoder(manager)\n",
    "# encoderN = RNN_Encoder(manager)\n",
    "# encoderN = MHA_Encoder(manager)\n",
    "\n",
    "# encoderU = CNN_User_Encoder(manager)\n",
    "encoderU = RNN_User_Encoder(manager)\n",
    "# encoderU = MHA_User_Encoder(manager)\n",
    "# encoderU = Attention_Pooling(manager)\n",
    "# encoderU = Average_Pooling(manager)\n",
    "\n",
    "reducer = Matching_Reducer(manager)\n",
    "# reducer = Identical_Reducer(manager)\n",
    "\n",
    "# ranker = CNN_Ranker(manager)\n",
    "# ranker = BERT_Onepass_Ranker(manager)\n",
    "# ranker = BERT_Original_Ranker(manager)\n",
    "\n",
    "model = TESRec(manager, embedding, encoderN, encoderU, reducer).to(manager.device)\n",
    "# model = ESM(manager, embedding, encoderN, encoderU, reducer, ranker).to(manager.device)\n",
    "# model = XFormer(manager).to(manager.device)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "manager.load(model, 230000)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "a,b,c,d,e = model.encode_user(x1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "np.asarray(t.convert_ids_to_tokens(x1['his_encoded_index'][0,0])[1:])[[86,2,93]]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "e[0,3,35], e.shape"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "t.convert_ids_to_tokens(x1['his_encoded_index'][0,3,[36]])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(t.convert_ids_to_tokens(x1['his_encoded_index'][0,3]))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "e[0,3], e.shape, e.topk(dim=-1, k=3)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "recall = 0\n",
    "count = 0\n",
    "for x in tqdm(loaders[0], ncols=120, leave=True):\n",
    "    kid = model.encode_user(x)[1]\n",
    "    ps_terms = x['his_encoded_index'][:, :, 1:].to(manager.device).gather(index=kid, dim=-1).view(-1).tolist()\n",
    "    "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "embedding = 32*50*2*100*768\n",
    "ext_encoding = 32*50*(2*3*384*100 + 4*100*384) + 32*8*2*384*384*50\n",
    "reduction = (2*100*768 + 100*math.log2(100))*32*50*2+32*50*3\n",
    "bert_embedding = 32*150*768*2\n",
    "bert_project = 32*150*768*2*3\n",
    "bert_attn = 32*150*12*64*64*2 + 32*150*12*12*64*2\n",
    "bert_intm = 32*150*768*768*2 + 32*150*768*2 + 32*150*768*3072*4\n",
    "bert_pool = 32*150*768*4\n",
    "bert = (bert_project + bert_attn + bert_intm) * 12 + bert_pool\n",
    "\n",
    "total_isrec = embedding + ext_encoding + reduction + bert\n",
    "\n",
    "embedding = 32*50*2*100*768 + 32*50*100*768*2\n",
    "bert_project = 32*5000*768*2*3\n",
    "bert_attn = 32*5000*12*64*64*2 + 32*5000*12*12*64*2\n",
    "bert_intm = 32*5000*768*768*2 + 32*5000*768*2 + 32*5000*768*3072*4\n",
    "bert_pool = 32*5000*768*4\n",
    "bert = (bert_project + bert_attn + bert_intm) * 12 + bert_pool\n",
    "\n",
    "total =  embedding + bert + 32*8*2*768*768*50\n",
    "\n",
    "total_isrec, total"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.11",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.11 64-bit (conda)"
  },
  "interpreter": {
   "hash": "0f43efc2da5f33d61ae1bd929e6c7df9dd2aa7f250aadb5586d31de3e27bb6a5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}