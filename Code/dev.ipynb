{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import logging\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "from collections import defaultdict\n",
    "from utils.utils import prepare\n",
    "from data.configs.demo import config\n",
    "\n",
    "from transformers import BertTokenizer,BertModel\n",
    "from utils.Manager import Manager\n",
    "\n",
    "from models.Embeddings.BERT import BERT_Embedding\n",
    "from models.Encoders.CNN import CNN_Encoder\n",
    "from models.Encoders.RNN import RNN_User_Encoder\n",
    "from models.Modules.DRM import Matching_Reducer\n",
    "from models.Modules.DRM import BM25_Reducer\n",
    "from models.Rankers.BERT import BERT_Onepass_Ranker\n",
    "from models.Rankers.BERT import BERT_Original_Ranker\n",
    "from models.Rankers.CNN import CNN_Ranker\n",
    "from models.ESM import ESM"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "manager = Manager(config)\n",
    "loaders = prepare(manager)\n",
    "\n",
    "record = list(loaders[0])[0]"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[2021-08-22 13:38:51,634] INFO (utils.utils) Hyper Parameters are \n",
      "scale:demo\n",
      "mode:tune\n",
      "epochs:8\n",
      "batch_size:10\n",
      "k:5\n",
      "threshold:-inf\n",
      "title_length:20\n",
      "abs_length:40\n",
      "signal_length:80\n",
      "npratio:4\n",
      "his_size:50\n",
      "cdd_size:5\n",
      "impr_size:10\n",
      "dropout_p:0.2\n",
      "device:cpu\n",
      "lr:0.0001\n",
      "bert_lr:3e-05\n",
      "metrics:auc,mean_mrr,ndcg@5,ndcg@10\n",
      "embedding:bert\n",
      "selector:sfi\n",
      "reducer:matching\n",
      "interactor:onepass\n",
      "embedding_dim:300\n",
      "hidden_dim:150\n",
      "rank:0\n",
      "world_size:0\n",
      "step:0\n",
      "seeds:42\n",
      "interval:10\n",
      "ascend_history:False\n",
      "no_dedup:False\n",
      "scheduler:linear\n",
      "warmup:100\n",
      "pin_memory:False\n",
      "shuffle:False\n",
      "bert:bert-base-uncased\n",
      "num_workers:0\n",
      "smoothing:0.3\n",
      "path:../../../Data/\n",
      "tb:False\n",
      "[2021-08-22 13:38:51,635] INFO (utils.utils) preparing dataset...\n",
      "[2021-08-22 13:38:51,640] INFO (utils.MIND) using cached user behavior from data/cache/bert/MINDdemo_train/10/behaviors..pkl\n",
      "[2021-08-22 13:38:51,654] INFO (utils.MIND) using cached news tokenization from data/cache/bert/MINDdemo_train/news.pkl\n",
      "[2021-08-22 13:38:52,175] INFO (utils.utils) deduplicating...\n",
      "[2021-08-22 13:38:53,503] INFO (utils.MIND) using cached user behavior from data/cache/bert/MINDdemo_dev/10/behaviors..pkl\n",
      "[2021-08-22 13:38:53,506] INFO (utils.MIND) using cached news tokenization from data/cache/bert/MINDdemo_dev/news.pkl\n",
      "[2021-08-22 13:38:53,916] INFO (utils.utils) deduplicating...\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "class ESM(nn.Module):\n",
    "    def __init__(self, config, embedding, encoderN, encoderU, reducer, fuser, ranker):\n",
    "        super().__init__()\n",
    "\n",
    "        self.scale = config.scale\n",
    "        self.cdd_size = config.cdd_size\n",
    "        self.batch_size = config.batch_size\n",
    "        self.his_size = config.his_size\n",
    "        self.device = config.device\n",
    "\n",
    "        self.k = config.k\n",
    "\n",
    "        self.embedding = embedding\n",
    "        self.encoderN = encoderN\n",
    "        self.encoderU = encoderU\n",
    "        self.reducer = reducer\n",
    "        self.fuser = fuser\n",
    "        self.ranker = ranker\n",
    "\n",
    "        self.final_dim = ranker.final_dim\n",
    "\n",
    "        self.learningToRank = nn.Sequential(\n",
    "            nn.Linear(self.final_dim + 1, int(self.final_dim/2)),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(int(self.final_dim/2),1)\n",
    "        )\n",
    "\n",
    "        self.name = '__'.join(['esm', self.encoderN.name, self.encoderU.name, self.reducer.name, self.ranker.name])\n",
    "        config.name = self.name\n",
    "\n",
    "    def clickPredictor(self, reduced_tensor, cdd_news_repr, user_repr):\n",
    "        \"\"\" calculate batch of click probabolity\n",
    "\n",
    "        Args:\n",
    "            reduced_tensor: [batch_size, cdd_size, final_dim]\n",
    "            cdd_news_repr: news-level representation, [batch_size, cdd_size, hidden_dim]\n",
    "            user_repr: user representation, [batch_size, 1, hidden_dim]\n",
    "\n",
    "        Returns:\n",
    "            score of each candidate news, [batch_size, cdd_size]\n",
    "        \"\"\"\n",
    "        score_coarse = cdd_news_repr.matmul(user_repr.transpose(-2,-1))\n",
    "        score = torch.cat([reduced_tensor, score_coarse], dim=-1)\n",
    "\n",
    "        return self.learningToRank(score).squeeze(dim=-1)\n",
    "\n",
    "    def _forward(self,x):\n",
    "        if x[\"cdd_encoded_index\"].size(0) != self.batch_size:\n",
    "            self.batch_size = x[\"cdd_encoded_index\"].size(0)\n",
    "\n",
    "        cdd_news = x[\"cdd_encoded_index\"].long().to(self.device)\n",
    "        cdd_news_embedding = self.embedding(cdd_news)\n",
    "        _, cdd_news_repr = self.encoderN(\n",
    "            cdd_news_embedding\n",
    "        )\n",
    "        if self.reducer.name == 'bm25':\n",
    "            his_news = x[\"his_reduced_index\"].long().to(self.device)\n",
    "        else:\n",
    "            his_news = x[\"his_encoded_index\"].long().to(self.device)\n",
    "        his_news_embedding = self.embedding(his_news)\n",
    "        his_news_encoded_embedding, his_news_repr = self.encoderN(\n",
    "            his_news_embedding\n",
    "        )\n",
    "\n",
    "        user_repr = self.encoderU(his_news_repr)\n",
    "        if self.reducer.name == 'matching':\n",
    "            ps_terms, ps_term_mask, scores = self.reducer(his_news_encoded_embedding, his_news_embedding, user_repr, x[\"his_attn_mask\"].to(self.device), x[\"his_attn_mask_k\"].to(self.device).bool())\n",
    "        else:\n",
    "            ps_terms, ps_term_mask = self.reducer(his_news_encoded_embedding, his_news_embedding, user_repr, x[\"his_attn_mask\"].to(self.device))\n",
    "\n",
    "        if self.fuser:\n",
    "            ps_terms, ps_term_mask = self.fuser(ps_terms, ps_term_mask)\n",
    "\n",
    "        # reduced_tensor = self.ranker(torch.cat([cdd_news_repr.unsqueeze(-2), cdd_news_embedding], dim=-2), torch.cat([user_repr, ps_terms], dim=-2))\n",
    "        reduced_tensor = self.ranker(cdd_news_embedding, ps_terms, x[\"cdd_attn_mask\"].to(self.device), ps_term_mask)\n",
    "\n",
    "        return self.clickPredictor(reduced_tensor, cdd_news_repr, user_repr), scores\n",
    "\n",
    "    def forward(self,x):\n",
    "        \"\"\"\n",
    "        Decoupled function, score is unormalized click score\n",
    "        \"\"\"\n",
    "        score, scores = self._forward(x)\n",
    "\n",
    "        if self.training:\n",
    "            prob = nn.functional.log_softmax(score, dim=1)\n",
    "        else:\n",
    "            prob = torch.sigmoid(score)\n",
    "\n",
    "        return prob, scores"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "class Matching_Reducer(nn.Module):\n",
    "    \"\"\"\n",
    "    basic document reducer: topk of each historical article\n",
    "    \"\"\"\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "\n",
    "        self.name = \"matching\"\n",
    "\n",
    "        self.k = config.k\n",
    "\n",
    "        config.term_num = config.k * config.his_size\n",
    "\n",
    "        threshold = torch.tensor([config.threshold])\n",
    "        self.register_buffer('threshold', threshold)\n",
    "\n",
    "    def forward(self, news_selection_embedding, news_embedding, user_repr, his_attn_mask, his_attn_mask_k):\n",
    "        \"\"\"\n",
    "        Extract words from news text according to the overall user interest\n",
    "\n",
    "        Args:\n",
    "            news_selection_embedding: encoded word-level embedding, [batch_size, his_size, signal_length, hidden_dim]\n",
    "            news_embedding: word-level news embedding, [batch_size, his_size, signal_length, hidden_dim]\n",
    "            user_repr: user representation, [batch_size, 1, hidden_dim]\n",
    "\n",
    "        Returns:\n",
    "            ps_terms: weighted embedding for personalized terms, [batch_size, his_size, k, hidden_dim]\n",
    "            ps_term_mask: attention mask of output terms, [batch_size, his_size, k]\n",
    "        \"\"\"\n",
    "        # strip off [CLS]\n",
    "        news_selection_embedding = news_selection_embedding[:, :, 1:]\n",
    "        news_embedding = news_embedding[:, :, 1:]\n",
    "\n",
    "        # [bs, hs, sl - 1]\n",
    "        scores = F.normalize(news_selection_embedding, dim=-1).matmul(F.normalize(user_repr, dim=-1).transpose(-2,-1).unsqueeze(1)).squeeze(-1)\n",
    "        # mask the padded term\n",
    "        scores = scores.masked_fill(~his_attn_mask_k[:, :, 1:], -float('inf'))\n",
    "\n",
    "        score_k, score_kid = scores.topk(dim=-1, k=self.k, sorted=False)\n",
    "\n",
    "        personalized_terms = news_embedding.gather(dim=-2,index=score_kid.unsqueeze(-1).expand(score_kid.size() + (news_embedding.size(-1),)))\n",
    "        ps_term_mask = his_attn_mask[:, :, 1:].gather(dim=-1, index=score_kid)\n",
    "\n",
    "        mask_pos = score_k < self.threshold\n",
    "        # ps_terms = personalized_terms * (nn.functional.softmax(score_k.masked_fill(score_k < self.threshold, 0), dim=-1).unsqueeze(-1))\n",
    "        ps_terms = personalized_terms * (score_k.masked_fill(mask_pos, 0).unsqueeze(-1))\n",
    "        ps_term_mask = ps_term_mask * (~mask_pos)\n",
    "\n",
    "        scores.retain_grad()\n",
    "\n",
    "        # weighted_ps_terms.retain_grad()\n",
    "        # print(weighted_ps_terms.grad, weighted_ps_terms.requires_grad)\n",
    "\n",
    "        return ps_terms, ps_term_mask, scores"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from transformers import BertModel,BertConfig\n",
    "\n",
    "class BERT_Onepass_Ranker(nn.Module):\n",
    "    \"\"\"\n",
    "    one-pass bert: cdd1 cdd2 ... cddn [SEP] pst1 pst2 ...\n",
    "    \"\"\"\n",
    "    def __init__(self, config):\n",
    "        from models.Rankers.Modules.OnePassAttn import BertSelfAttention\n",
    "        # confirm the hidden dim to be 768\n",
    "        assert config.embedding_dim == 768\n",
    "        # confirm term_num + signal_length is less than 512\n",
    "        # assert config.k * config.his_size + config.his_size + config.signal_length < 512\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        self.name = 'onepass-bert'\n",
    "        self.signal_length = config.signal_length\n",
    "        self.term_num = config.term_num + 1\n",
    "        self.embedding_dim = config.embedding_dim\n",
    "        self.final_dim = self.embedding_dim\n",
    "\n",
    "        bert_config = BertConfig()\n",
    "        # primary bert\n",
    "        prim_bert = BertModel(bert_config).encoder\n",
    "        bert_config.signal_length = self.signal_length\n",
    "        bert_config.term_num = config.term_num + 1\n",
    "        bert_config.cdd_size = config.cdd_size\n",
    "        for l in prim_bert.layer:\n",
    "            l.attention.self = BertSelfAttention(bert_config)\n",
    "\n",
    "        bert = BertModel.from_pretrained(\n",
    "            config.bert,\n",
    "            cache_dir=config.path + 'bert_cache/'\n",
    "        )\n",
    "        prim_bert.load_state_dict(bert.encoder.state_dict())\n",
    "        self.bert = prim_bert\n",
    "\n",
    "        self.dropOut = bert.embeddings.dropout\n",
    "\n",
    "        # [2, embedding_dim]\n",
    "        self.token_type_embedding = nn.Parameter(bert.embeddings.token_type_embeddings.weight)\n",
    "        # [SEP] token\n",
    "        self.sep_embedding = nn.Parameter(bert.embeddings.word_embeddings(torch.tensor([102])).clone().detach().requires_grad_(True).view(1,1,self.embedding_dim))\n",
    "\n",
    "\n",
    "    def forward(self, cdd_news_embedding, ps_terms, cdd_attn_mask, his_attn_mask):\n",
    "        \"\"\"\n",
    "        calculate interaction tensor and reduce it to a vector\n",
    "\n",
    "        Args:\n",
    "            cdd_news_embedding: word-level representation of candidate news, [batch_size, cdd_size, signal_length, embedding_dim]\n",
    "            ps_terms: concatenated historical news or personalized terms, [batch_size, term_num, embedding_dim]\n",
    "            cdd_attn_mask: attention mask of the candidate news, [batch_size, cdd_size, signal_length]\n",
    "            his_attn_mask: attention mask of the history sequence, [batch_size, his_size, k]/[batch_size, cdd_size, k, signal_length]\n",
    "\n",
    "        Returns:\n",
    "            reduced_tensor: output tensor after CNN2d, [batch_size, cdd_size, final_dim]\n",
    "        \"\"\"\n",
    "        batch_size = cdd_news_embedding.size(0)\n",
    "        cdd_size = cdd_news_embedding.size(1)\n",
    "\n",
    "        ps_terms = ps_terms.view(batch_size, -1, self.embedding_dim)\n",
    "        # [bs,tn,hd]\n",
    "        ps_terms = torch.cat([self.sep_embedding.expand(batch_size, 1, self.embedding_dim), ps_terms], dim=1)\n",
    "        ps_terms[:,1:] += self.token_type_embedding[1]\n",
    "        ps_terms[:,0] += self.token_type_embedding[0]\n",
    "\n",
    "        # [bs, cs*sl, hd]\n",
    "        cdd_news_embedding = (cdd_news_embedding + self.token_type_embedding[0]).view(batch_size, -1, self.embedding_dim)\n",
    "\n",
    "        bert_input = torch.cat([cdd_news_embedding, ps_terms], dim=-2)\n",
    "        # bert_input = self.dropOut(bert_input)\n",
    "\n",
    "        # [bs, cs*sl]\n",
    "        attn_mask = cdd_attn_mask.view(batch_size, -1)\n",
    "        attn_mask = torch.cat([attn_mask, torch.ones(batch_size, 1, device=cdd_attn_mask.device), his_attn_mask.view(batch_size, -1)], dim=-1).view(batch_size, 1, 1, -1)\n",
    "        \n",
    "        bert_output = self.bert(bert_input, attention_mask=attn_mask).last_hidden_state[:, 0 : cdd_size * (self.signal_length) : self.signal_length].view(batch_size, cdd_size, self.embedding_dim)\n",
    "\n",
    "        return bert_output"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "embedding = BERT_Embedding(manager)\n",
    "encoderN = CNN_Encoder(manager)\n",
    "encoderU = RNN_User_Encoder(manager)\n",
    "\n",
    "docReducer = Matching_Reducer(manager)\n",
    "# docReducer = BM25_Reducer(manager)\n",
    "\n",
    "# ranker = CNN_Ranker(manager)\n",
    "ranker = BERT_Onepass_Ranker(manager)\n",
    "# ranker = BERT_Original_Ranker(manager)\n",
    "\n",
    "esm = ESM(manager, embedding, encoderN, encoderU, docReducer, None, ranker).to(manager.device)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "prob, scores = esm(record)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "manager.inspect_ps_terms(esm, 3534, loaders[0], bm25=False)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "esm.encoderU.lstm.weight_hh_l0 == a"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[False, False, False,  ..., False, False, False],\n",
       "        [False, False, False,  ..., False, False, False],\n",
       "        [False, False, False,  ..., False, False, False],\n",
       "        ...,\n",
       "        [False, False, False,  ..., False, False, False],\n",
       "        [False, False, False,  ..., False, False, False],\n",
       "        [False, False, False,  ..., False, False, False]])"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.11",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.11 64-bit (conda)"
  },
  "interpreter": {
   "hash": "decb58d8582e8bebc2c9af4e5243ce054f2f8013c5b7e79ffbf7b8b9f3c0761b"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}