{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import logging\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "from collections import defaultdict\n",
    "from utils.utils import prepare\n",
    "from data.configs.demo import config\n",
    "\n",
    "from transformers import BertTokenizer,BertModel\n",
    "from utils.Manager import Manager\n",
    "\n",
    "from models.Embeddings.BERT import BERT_Embedding\n",
    "from models.Encoders.CNN import CNN_Encoder\n",
    "from models.Encoders.RNN import RNN_User_Encoder\n",
    "from models.Modules.DRM import Matching_Reducer\n",
    "from models.Modules.DRM import BM25_Reducer\n",
    "from models.Rankers.BERT import BERT_Onepass_Ranker\n",
    "from models.Rankers.BERT import BERT_Original_Ranker\n",
    "from models.Rankers.CNN import CNN_Ranker\n",
    "from models.ESM import ESM"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "manager = Manager(config)\n",
    "loaders = prepare(manager)\n",
    "\n",
    "record = list(loaders[0])[0]"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[2021-08-21 17:13:24,111] INFO (utils.utils) Hyper Parameters are \n",
      "scale:demo\n",
      "mode:tune\n",
      "epochs:8\n",
      "batch_size:10\n",
      "k:5\n",
      "threshold:-inf\n",
      "title_length:20\n",
      "abs_length:40\n",
      "signal_length:80\n",
      "npratio:4\n",
      "his_size:50\n",
      "cdd_size:5\n",
      "impr_size:10\n",
      "dropout_p:0.2\n",
      "device:cpu\n",
      "lr:0.0001\n",
      "bert_lr:3e-05\n",
      "metrics:auc,mean_mrr,ndcg@5,ndcg@10\n",
      "embedding:bert\n",
      "selector:sfi\n",
      "reducer:matching\n",
      "interactor:onepass\n",
      "embedding_dim:300\n",
      "hidden_dim:150\n",
      "rank:0\n",
      "world_size:0\n",
      "step:0\n",
      "seeds:42\n",
      "interval:10\n",
      "ascend_history:False\n",
      "no_dedup:False\n",
      "schedule:linear\n",
      "warmup:100\n",
      "pin_memory:False\n",
      "shuffle:False\n",
      "bert:bert-base-uncased\n",
      "num_workers:0\n",
      "path:../../../Data/\n",
      "tb:False\n",
      "[2021-08-21 17:13:24,111] INFO (utils.utils) preparing dataset...\n",
      "[2021-08-21 17:13:24,114] INFO (utils.MIND) using cached user behavior from data/cache/bert/MINDdemo_train/10/behaviors..pkl\n",
      "[2021-08-21 17:13:24,127] INFO (utils.MIND) using cached news tokenization from data/cache/bert/MINDdemo_train/news.pkl\n",
      "[2021-08-21 17:13:24,388] INFO (utils.utils) deduplicating...\n",
      "[2021-08-21 17:13:25,849] INFO (utils.MIND) using cached user behavior from data/cache/bert/MINDdemo_dev/10/behaviors..pkl\n",
      "[2021-08-21 17:13:25,851] INFO (utils.MIND) using cached news tokenization from data/cache/bert/MINDdemo_dev/news.pkl\n",
      "[2021-08-21 17:13:26,062] INFO (utils.utils) deduplicating...\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "class ESM(nn.Module):\n",
    "    def __init__(self, config, embedding, encoderN, encoderU, reducer, fuser, ranker):\n",
    "        super().__init__()\n",
    "\n",
    "        self.scale = config.scale\n",
    "        self.cdd_size = config.cdd_size\n",
    "        self.batch_size = config.batch_size\n",
    "        self.his_size = config.his_size\n",
    "        self.device = config.device\n",
    "\n",
    "        self.k = config.k\n",
    "\n",
    "        self.embedding = embedding\n",
    "        self.encoderN = encoderN\n",
    "        self.encoderU = encoderU\n",
    "        self.reducer = reducer\n",
    "        self.fuser = fuser\n",
    "        self.ranker = ranker\n",
    "\n",
    "        self.final_dim = ranker.final_dim\n",
    "\n",
    "        self.learningToRank = nn.Sequential(\n",
    "            nn.Linear(self.final_dim + 1, int(self.final_dim/2)),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(int(self.final_dim/2),1)\n",
    "        )\n",
    "\n",
    "        self.name = '__'.join(['esm', self.encoderN.name, self.encoderU.name, self.reducer.name, self.ranker.name])\n",
    "        config.name = self.name\n",
    "\n",
    "    def clickPredictor(self, reduced_tensor, cdd_news_repr, user_repr):\n",
    "        \"\"\" calculate batch of click probabolity\n",
    "\n",
    "        Args:\n",
    "            reduced_tensor: [batch_size, cdd_size, final_dim]\n",
    "            cdd_news_repr: news-level representation, [batch_size, cdd_size, hidden_dim]\n",
    "            user_repr: user representation, [batch_size, 1, hidden_dim]\n",
    "\n",
    "        Returns:\n",
    "            score of each candidate news, [batch_size, cdd_size]\n",
    "        \"\"\"\n",
    "        score_coarse = cdd_news_repr.matmul(user_repr.transpose(-2,-1))\n",
    "        score = torch.cat([reduced_tensor, score_coarse], dim=-1)\n",
    "\n",
    "        return self.learningToRank(score).squeeze(dim=-1)\n",
    "\n",
    "    def _forward(self,x):\n",
    "        if x[\"cdd_encoded_index\"].size(0) != self.batch_size:\n",
    "            self.batch_size = x[\"cdd_encoded_index\"].size(0)\n",
    "\n",
    "        cdd_news = x[\"cdd_encoded_index\"].long().to(self.device)\n",
    "        cdd_news_embedding = self.embedding(cdd_news)\n",
    "        _, cdd_news_repr = self.encoderN(\n",
    "            cdd_news_embedding\n",
    "        )\n",
    "        if self.reducer.name == 'bm25':\n",
    "            his_news = x[\"his_reduced_index\"].long().to(self.device)\n",
    "        else:\n",
    "            his_news = x[\"his_encoded_index\"].long().to(self.device)\n",
    "        his_news_embedding = self.embedding(his_news)\n",
    "        his_news_encoded_embedding, his_news_repr = self.encoderN(\n",
    "            his_news_embedding\n",
    "        )\n",
    "\n",
    "        user_repr = self.encoderU(his_news_repr)\n",
    "        if self.reducer.name == 'matching':\n",
    "            ps_terms, ps_term_mask = self.reducer(his_news_encoded_embedding, his_news_embedding, user_repr, x[\"his_attn_mask\"].to(self.device), x[\"his_attn_mask_k\"].to(self.device).bool())\n",
    "        else:\n",
    "            ps_terms, ps_term_mask = self.reducer(his_news_encoded_embedding, his_news_embedding, user_repr, x[\"his_attn_mask\"].to(self.device))\n",
    "\n",
    "        if self.fuser:\n",
    "            ps_terms, ps_term_mask = self.fuser(ps_terms, ps_term_mask)\n",
    "\n",
    "        # reduced_tensor = self.ranker(torch.cat([cdd_news_repr.unsqueeze(-2), cdd_news_embedding], dim=-2), torch.cat([user_repr, ps_terms], dim=-2))\n",
    "        print(ps_term_mask)\n",
    "        reduced_tensor = self.ranker(cdd_news_embedding, ps_terms, x[\"cdd_attn_mask\"].to(self.device), ps_term_mask)\n",
    "\n",
    "        return self.clickPredictor(reduced_tensor, cdd_news_repr, user_repr)\n",
    "\n",
    "    def forward(self,x):\n",
    "        \"\"\"\n",
    "        Decoupled function, score is unormalized click score\n",
    "        \"\"\"\n",
    "        score = self._forward(x)\n",
    "\n",
    "        if self.training:\n",
    "            prob = nn.functional.log_softmax(score, dim=1)\n",
    "        else:\n",
    "            prob = torch.sigmoid(score)\n",
    "\n",
    "        return prob"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "class Matching_Reducer(nn.Module):\n",
    "    \"\"\"\n",
    "    basic document reducer: topk of each historical article\n",
    "    \"\"\"\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "\n",
    "        self.name = \"matching\"\n",
    "\n",
    "        self.k = config.k\n",
    "\n",
    "        config.term_num = config.k * config.his_size\n",
    "\n",
    "        threshold = torch.tensor([config.threshold])\n",
    "        self.register_buffer('threshold', threshold)\n",
    "\n",
    "    def forward(self, news_selection_embedding, news_embedding, user_repr, his_attn_mask, his_attn_mask_k):\n",
    "        \"\"\"\n",
    "        Extract words from news text according to the overall user interest\n",
    "\n",
    "        Args:\n",
    "            news_selection_embedding: encoded word-level embedding, [batch_size, his_size, signal_length, hidden_dim]\n",
    "            news_embedding: word-level news embedding, [batch_size, his_size, signal_length, hidden_dim]\n",
    "            user_repr: user representation, [batch_size, 1, hidden_dim]\n",
    "\n",
    "        Returns:\n",
    "            ps_terms: weighted embedding for personalized terms, [batch_size, his_size, k, hidden_dim]\n",
    "            ps_term_mask: attention mask of output terms, [batch_size, his_size, k]\n",
    "        \"\"\"\n",
    "        # strip off [CLS]\n",
    "        news_selection_embedding = news_selection_embedding[:, :, 1:]\n",
    "        news_embedding = news_embedding[:, :, 1:]\n",
    "\n",
    "        # [bs, hs, sl - 1]\n",
    "        scores = F.normalize(news_selection_embedding, dim=-1).matmul(F.normalize(user_repr, dim=-1).transpose(-2,-1).unsqueeze(1)).squeeze(-1)\n",
    "        # mask the padded term\n",
    "        scores = scores.masked_fill(~his_attn_mask_k[:, :, 1:], -float('inf'))\n",
    "\n",
    "        score_k, score_kid = scores.topk(dim=-1, k=self.k, sorted=False)\n",
    "\n",
    "        personalized_terms = news_embedding.gather(dim=-2,index=score_kid.unsqueeze(-1).expand(score_kid.size() + (news_embedding.size(-1),)))\n",
    "        ps_term_mask = his_attn_mask[:, :, 1:].gather(dim=-1, index=score_kid)\n",
    "\n",
    "        mask_pos = score_k < self.threshold\n",
    "        # ps_terms = personalized_terms * (nn.functional.softmax(score_k.masked_fill(score_k < self.threshold, 0), dim=-1).unsqueeze(-1))\n",
    "        ps_terms = personalized_terms * (score_k.masked_fill(mask_pos, 0).unsqueeze(-1))\n",
    "        ps_term_mask = ps_term_mask * (~mask_pos)\n",
    "\n",
    "        # weighted_ps_terms.retain_grad()\n",
    "        # print(weighted_ps_terms.grad, weighted_ps_terms.requires_grad)\n",
    "\n",
    "        return ps_terms, ps_term_mask"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "from transformers import BertModel,BertConfig\n",
    "\n",
    "class BERT_Onepass_Ranker(nn.Module):\n",
    "    \"\"\"\n",
    "    one-pass bert: cdd1 cdd2 ... cddn [SEP] pst1 pst2 ...\n",
    "    \"\"\"\n",
    "    def __init__(self, config):\n",
    "        from models.Rankers.Modules.OnePassAttn import BertSelfAttention\n",
    "        # confirm the hidden dim to be 768\n",
    "        assert config.embedding_dim == 768\n",
    "        # confirm term_num + signal_length is less than 512\n",
    "        # assert config.k * config.his_size + config.his_size + config.signal_length < 512\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        self.name = 'onepass-bert'\n",
    "        self.signal_length = config.signal_length\n",
    "        self.term_num = config.term_num + 1\n",
    "        self.embedding_dim = config.embedding_dim\n",
    "        self.final_dim = self.embedding_dim\n",
    "\n",
    "        bert_config = BertConfig()\n",
    "        # primary bert\n",
    "        prim_bert = BertModel(bert_config).encoder\n",
    "        bert_config.signal_length = self.signal_length\n",
    "        bert_config.term_num = config.term_num + 1\n",
    "        bert_config.cdd_size = config.cdd_size\n",
    "        for l in prim_bert.layer:\n",
    "            l.attention.self = BertSelfAttention(bert_config)\n",
    "\n",
    "        bert = BertModel.from_pretrained(\n",
    "            config.bert,\n",
    "            cache_dir=config.path + 'bert_cache/'\n",
    "        )\n",
    "        prim_bert.load_state_dict(bert.encoder.state_dict())\n",
    "        self.bert = prim_bert\n",
    "\n",
    "        self.dropOut = bert.embeddings.dropout\n",
    "\n",
    "        # [2, embedding_dim]\n",
    "        self.token_type_embedding = nn.Parameter(bert.embeddings.token_type_embeddings.weight)\n",
    "        # [SEP] token\n",
    "        self.sep_embedding = nn.Parameter(bert.embeddings.word_embeddings(torch.tensor([102])).clone().detach().requires_grad_(True).view(1,1,self.embedding_dim))\n",
    "\n",
    "\n",
    "    def forward(self, cdd_news_embedding, ps_terms, cdd_attn_mask, his_attn_mask):\n",
    "        \"\"\"\n",
    "        calculate interaction tensor and reduce it to a vector\n",
    "\n",
    "        Args:\n",
    "            cdd_news_embedding: word-level representation of candidate news, [batch_size, cdd_size, signal_length, embedding_dim]\n",
    "            ps_terms: concatenated historical news or personalized terms, [batch_size, term_num, embedding_dim]\n",
    "            cdd_attn_mask: attention mask of the candidate news, [batch_size, cdd_size, signal_length]\n",
    "            his_attn_mask: attention mask of the history sequence, [batch_size, his_size, k]/[batch_size, cdd_size, k, signal_length]\n",
    "\n",
    "        Returns:\n",
    "            reduced_tensor: output tensor after CNN2d, [batch_size, cdd_size, final_dim]\n",
    "        \"\"\"\n",
    "        batch_size = cdd_news_embedding.size(0)\n",
    "        cdd_size = cdd_news_embedding.size(1)\n",
    "\n",
    "        ps_terms = ps_terms.view(batch_size, -1, self.embedding_dim)\n",
    "        # [bs,tn,hd]\n",
    "        ps_terms = torch.cat([self.sep_embedding.expand(batch_size, 1, self.embedding_dim), ps_terms], dim=1)\n",
    "        ps_terms[:,1:] += self.token_type_embedding[1]\n",
    "        ps_terms[:,0] += self.token_type_embedding[0]\n",
    "\n",
    "        # [bs, cs*sl, hd]\n",
    "        cdd_news_embedding = (cdd_news_embedding + self.token_type_embedding[0]).view(batch_size, -1, self.embedding_dim)\n",
    "\n",
    "        bert_input = torch.cat([cdd_news_embedding, ps_terms], dim=-2)\n",
    "        # bert_input = self.dropOut(bert_input)\n",
    "\n",
    "        # [bs, cs*sl]\n",
    "        attn_mask = cdd_attn_mask.view(batch_size, -1)\n",
    "        attn_mask = torch.cat([attn_mask, torch.ones(batch_size, 1, device=cdd_attn_mask.device), his_attn_mask.view(batch_size, -1)], dim=-1).view(batch_size, 1, 1, -1)\n",
    "        print(attn_mask[0])\n",
    "        \n",
    "        bert_output = self.bert(bert_input, attention_mask=attn_mask).last_hidden_state[:, 0 : cdd_size * (self.signal_length) : self.signal_length].view(batch_size, cdd_size, self.embedding_dim)\n",
    "\n",
    "        return bert_output"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "embedding = BERT_Embedding(manager)\n",
    "encoderN = CNN_Encoder(manager)\n",
    "encoderU = RNN_User_Encoder(manager)\n",
    "\n",
    "docReducer = Matching_Reducer(manager)\n",
    "# docReducer = BM25_Reducer(manager)\n",
    "\n",
    "# ranker = CNN_Ranker(manager)\n",
    "ranker = BERT_Onepass_Ranker(manager)\n",
    "# ranker = BERT_Original_Ranker(manager)\n",
    "\n",
    "esm = ESM(manager, embedding, encoderN, encoderU, docReducer, None, ranker).to(manager.device)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "(loaders[0].dataset.attn_mask == loaders[0].dataset.attn_mask_k).all()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "esm(record)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([[[1, 1, 1, 1, 1],\n",
      "         [1, 1, 1, 1, 1],\n",
      "         [1, 1, 1, 1, 1],\n",
      "         ...,\n",
      "         [1, 1, 1, 1, 1],\n",
      "         [1, 1, 1, 1, 1],\n",
      "         [1, 1, 1, 1, 1]],\n",
      "\n",
      "        [[1, 1, 1, 1, 1],\n",
      "         [1, 1, 1, 1, 1],\n",
      "         [1, 1, 1, 1, 1],\n",
      "         ...,\n",
      "         [1, 1, 1, 1, 1],\n",
      "         [1, 1, 1, 1, 1],\n",
      "         [1, 1, 1, 1, 1]],\n",
      "\n",
      "        [[1, 1, 1, 1, 1],\n",
      "         [1, 1, 1, 1, 1],\n",
      "         [1, 1, 1, 1, 1],\n",
      "         ...,\n",
      "         [1, 1, 1, 1, 1],\n",
      "         [1, 1, 1, 1, 1],\n",
      "         [1, 1, 1, 1, 1]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[1, 1, 1, 1, 1],\n",
      "         [1, 1, 1, 1, 1],\n",
      "         [1, 1, 1, 1, 1],\n",
      "         ...,\n",
      "         [1, 1, 1, 1, 1],\n",
      "         [1, 1, 1, 1, 1],\n",
      "         [1, 1, 1, 1, 1]],\n",
      "\n",
      "        [[1, 1, 1, 1, 1],\n",
      "         [1, 1, 1, 1, 1],\n",
      "         [1, 1, 1, 1, 1],\n",
      "         ...,\n",
      "         [1, 1, 1, 1, 1],\n",
      "         [1, 1, 1, 1, 1],\n",
      "         [1, 1, 1, 1, 1]],\n",
      "\n",
      "        [[1, 1, 1, 1, 1],\n",
      "         [1, 1, 1, 1, 1],\n",
      "         [1, 1, 1, 1, 1],\n",
      "         ...,\n",
      "         [1, 1, 1, 1, 1],\n",
      "         [1, 1, 1, 1, 1],\n",
      "         [1, 1, 1, 1, 1]]])\n",
      "tensor([[[1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 0., 0., 1., 1., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 1.,\n",
      "          1., 1., 1., 1., 0., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1.,\n",
      "          1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1.,\n",
      "          1., 0., 0., 1., 1., 1., 0., 0., 0., 1., 0., 0., 1., 0., 0., 1., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1.,\n",
      "          1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "          1., 1., 1., 1., 1.]]])\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[-1.5851, -1.6109, -1.6148, -1.6561, -1.5820],\n",
       "        [-1.6126, -1.5892, -1.5712, -1.6273, -1.6487],\n",
       "        [-1.6104, -1.5912, -1.5931, -1.5829, -1.6723],\n",
       "        [-1.5769, -1.6119, -1.6413, -1.5965, -1.6218],\n",
       "        [-1.6055, -1.6400, -1.6116, -1.5712, -1.6201],\n",
       "        [-1.6131, -1.6186, -1.5975, -1.5854, -1.6333],\n",
       "        [-1.6145, -1.5444, -1.6235, -1.6531, -1.6149],\n",
       "        [-1.6277, -1.6099, -1.6221, -1.6224, -1.5664],\n",
       "        [-1.6078, -1.5574, -1.6018, -1.6369, -1.6457],\n",
       "        [-1.6062, -1.6365, -1.6297, -1.5680, -1.6082]],\n",
       "       grad_fn=<LogSoftmaxBackward>)"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "manager.inspect_ps_terms(esm, 3534, loaders[0], bm25=False)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[2021-08-21 17:13:42,199] INFO (utils.Manager) loading model from data/model_params/esm__cnn__rnn-u__matching__onepass-bert/demo_step3534_[k=5].model...\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/model_params/esm__cnn__rnn-u__matching__onepass-bert/demo_step3534_[k=5].model'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_457907/2388837086.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmanager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minspect_ps_terms\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mesm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3534\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloaders\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbm25\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/data/workspace/Peitian/nn/lib/python3.8/site-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/workspace/Peitian/Code/Document-Reduction/Code/utils/Manager.py\u001b[0m in \u001b[0;36minspect_ps_terms\u001b[0;34m(self, model, checkpoint, loader, bm25)\u001b[0m\n\u001b[1;32m    598\u001b[0m             \u001b[0mbm25_terms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbm25_file\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'encoded_news_sorted'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    599\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 600\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheckpoint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    601\u001b[0m         \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBertTokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'bert-base-uncased'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    602\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/workspace/Peitian/Code/Document-Reduction/Code/utils/Manager.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(self, model, step, optimizer)\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"loading model from {}...\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msave_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m         \u001b[0mstate_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msave_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mworld_size\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/workspace/Peitian/nn/lib/python3.8/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    579\u001b[0m         \u001b[0mpickle_load_args\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'encoding'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    580\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 581\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    582\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_is_zipfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    583\u001b[0m             \u001b[0;31m# The zipfile reader is going to advance the current file position.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/workspace/Peitian/nn/lib/python3.8/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_is_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 230\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    231\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'w'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/workspace/Peitian/nn/lib/python3.8/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_opener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_open_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/model_params/esm__cnn__rnn-u__matching__onepass-bert/demo_step3534_[k=5].model'"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.11",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.11 64-bit (conda)"
  },
  "interpreter": {
   "hash": "decb58d8582e8bebc2c9af4e5243ce054f2f8013c5b7e79ffbf7b8b9f3c0761b"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}