{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import re\n",
    "import logging\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "import time\n",
    "import pickle\n",
    "from collections import defaultdict\n",
    "from utils.utils import prepare\n",
    "from data.configs.demo import config\n",
    "from collections import defaultdict\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModel, BertModel, BertConfig\n",
    "from utils.Manager import Manager\n",
    "\n",
    "from models.Embeddings.BERT import BERT_Embedding\n",
    "from models.Encoders.CNN import CNN_Encoder,CNN_User_Encoder\n",
    "from models.Encoders.RNN import RNN_Encoder,RNN_User_Encoder\n",
    "from models.Encoders.MHA import MHA_Encoder, MHA_User_Encoder\n",
    "from models.Modules.DRM import Matching_Reducer, Slicing_Reducer\n",
    "from models.Rankers.BERT import BERT_Onepass_Ranker, BERT_Original_Ranker\n",
    "from models.Rankers.CNN import CNN_Ranker\n",
    "from models.Encoders.Pooling import Attention_Pooling, Average_Pooling\n",
    "\n",
    "from models.Encoders.BERT import BERT_Encoder\n",
    "from models.Encoders.Pooling import *\n",
    "\n",
    "from models.ESM import ESM\n",
    "from models.TTMS import TTMS\n",
    " \n",
    "from models.Modules.Attention import MultiheadAttention, get_attn_mask, XSoftmax\n",
    "torch.set_printoptions(threshold=100000)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "source": [
    "a = torch.rand((1,3),requires_grad=True)\n",
    "b = F.softmax(a,dim=-1)\n",
    "b.retain_grad()\n",
    "loss = (b**2).sum()\n",
    "loss.backward()\n",
    "c = a.grad.clone()\n",
    "\n",
    "softmax_back(2*b, b),c"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/tmp/ipykernel_342943/2847159591.py:4: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  p = F.softmax(z)\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(tensor([[-0.0452, -0.0274,  0.0726]], grad_fn=<ViewBackward>),\n",
       " tensor([[-0.0446, -0.0319,  0.0764]]))"
      ]
     },
     "metadata": {},
     "execution_count": 28
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def softmax_back(da, z):\n",
    "    # z, da shapes - (m, n)\n",
    "    m, n = z.shape\n",
    "    p = F.softmax(z, dim=-1)\n",
    "    # First we create for each example feature vector, it's outer product with itself\n",
    "    # ( p1^2  p1*p2  p1*p3 .... )\n",
    "    # ( p2*p1 p2^2   p2*p3 .... )\n",
    "    # ( ...                     )\n",
    "    tensor1 = torch.einsum('ij,ik->ijk', p, p)  # (m, n, n)\n",
    "    # Second we need to create an (n,n) identity of the feature vector\n",
    "    # ( p1  0  0  ...  )\n",
    "    # ( 0   p2 0  ...  )\n",
    "    # ( ...            )\n",
    "    tensor2 = torch.einsum('ij,jk->ijk', p, torch.eye(n, n))  # (m, n, n)\n",
    "    # Then we need to subtract the first tensor from the second\n",
    "    # ( p1 - p1^2   -p1*p2   -p1*p3  ... )\n",
    "    # ( -p1*p2     p2 - p2^2   -p2*p3 ...)\n",
    "    # ( ...                              )\n",
    "    dSoftmax = tensor2 - tensor1\n",
    "    # Finally, we multiply the dSoftmax (da/dz) by da (dL/da) to get the gradient w.r.t. Z\n",
    "    dz = torch.einsum('ijk,ik->ij', dSoftmax, da)  # (m, n)\n",
    "    return dz"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "a = torch.rand((1,3),requires_grad=True)\n",
    "loss = (a**2).sum()\n",
    "loss.backward()\n",
    "a.grad, 2*a"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(tensor([[0.2950, 1.8553, 1.8755]]),\n",
       " tensor([[0.2950, 1.8553, 1.8755]], grad_fn=<MulBackward0>))"
      ]
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "# config.reducer = 'entity'\n",
    "# config.embedding = 'deberta'\n",
    "# config.bert = 'microsoft/deberta-base'\n",
    "# config.device = 0\n",
    "\n",
    "manager = Manager(config)\n",
    "loaders = prepare(manager)\n",
    "X1 = list(loaders[0])\n",
    "X2 = list(loaders[1])\n",
    "x1 = X1[0]\n",
    "x2 = X2[0]"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[2021-09-12 13:08:37,354] INFO (utils.utils) Hyper Parameters are \n",
      "{\n",
      "    \"scale\": \"demo\",\n",
      "    \"mode\": \"tune\",\n",
      "    \"batch_size\": 5,\n",
      "    \"k\": 5,\n",
      "    \"threshold\": -Infinity,\n",
      "    \"abs_length\": 40,\n",
      "    \"signal_length\": 100,\n",
      "    \"his_size\": 50,\n",
      "    \"cdd_size\": 5,\n",
      "    \"impr_size\": 10,\n",
      "    \"dropout_p\": 0.2,\n",
      "    \"lr\": 0.0001,\n",
      "    \"bert_lr\": 3e-05,\n",
      "    \"embedding\": \"bert\",\n",
      "    \"encoderN\": \"cnn\",\n",
      "    \"encoderU\": \"rnn\",\n",
      "    \"selector\": \"sfi\",\n",
      "    \"reducer\": \"matching\",\n",
      "    \"ranker\": \"onepass\",\n",
      "    \"embedding_dim\": 768,\n",
      "    \"hidden_dim\": 384,\n",
      "    \"world_size\": 0,\n",
      "    \"seeds\": 42,\n",
      "    \"granularity\": \"avg\",\n",
      "    \"full_attn\": true,\n",
      "    \"ascend_history\": false,\n",
      "    \"save_pos\": false,\n",
      "    \"sep_his\": false,\n",
      "    \"diversify\": false,\n",
      "    \"no_dedup\": false,\n",
      "    \"no_order_embed\": false,\n",
      "    \"no_rm_punc\": false,\n",
      "    \"no_debias\": false,\n",
      "    \"scheduler\": \"linear\",\n",
      "    \"warmup\": 100,\n",
      "    \"shuffle\": false,\n",
      "    \"bert\": \"bert-base-uncased\",\n",
      "    \"tb\": false\n",
      "}\n",
      "[2021-09-12 13:08:37,355] INFO (utils.utils) preparing dataset...\n",
      "[2021-09-12 13:08:37,360] INFO (utils.MIND) process NO.0 loading cached user behavior from data/cache/bert/MINDdemo_train/10/behaviors..pkl\n",
      "[2021-09-12 13:08:37,375] INFO (utils.MIND) process NO.0 loading cached news tokenization from data/cache/bert/MINDdemo_train/news.pkl\n",
      "[2021-09-12 13:08:38,208] INFO (utils.utils) deduplicating...\n",
      "[2021-09-12 13:08:39,916] INFO (utils.MIND) process NO.0 loading cached user behavior from data/cache/bert/MINDdemo_dev/10/behaviors..pkl\n",
      "[2021-09-12 13:08:39,924] INFO (utils.MIND) process NO.0 loading cached news tokenization from data/cache/bert/MINDdemo_dev/news.pkl\n",
      "[2021-09-12 13:08:40,745] INFO (utils.utils) deduplicating...\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "embedding = BERT_Embedding(manager)\n",
    "\n",
    "encoderN = CNN_Encoder(manager)\n",
    "# encoderN = RNN_Encoder(manager)\n",
    "# encoderN = MHA_Encoder(manager)\n",
    "\n",
    "# encoderU = CNN_User_Encoder(manager)\n",
    "encoderU = RNN_User_Encoder(manager)\n",
    "# encoderU = MHA_User_Encoder(manager)\n",
    "# encoderU = Attention_Pooling(manager)\n",
    "# encoderU = Average_Pooling(manager)\n",
    "\n",
    "reducer = Matching_Reducer(manager)\n",
    "# reducer = Slicing_Reducer(manager)\n",
    "\n",
    "# ranker = CNN_Ranker(manager)\n",
    "# ranker = BERT_Onepass_Ranker(manager)\n",
    "# ranker = BERT_Original_Ranker(manager)\n",
    "\n",
    "# model = TTMS(manager, embedding, encoderN, encoderU, reducer).to(manager.device)\n",
    "# model = ESM(manager, embedding, encoderN, encoderU, reducer, ranker).to(manager.device)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "class BertSelfAttention(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        \"\"\"\n",
    "        one-pass bert, where other candidate news except itself are masked\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        self.num_attention_heads = config.num_attention_heads\n",
    "        self.attention_head_size = int(config.hidden_size / config.num_attention_heads)\n",
    "        self.all_head_size = self.num_attention_heads * self.attention_head_size\n",
    "\n",
    "        self.query = nn.Linear(config.hidden_size, self.all_head_size)\n",
    "        self.key = nn.Linear(config.hidden_size, self.all_head_size)\n",
    "        self.value = nn.Linear(config.hidden_size, self.all_head_size)\n",
    "\n",
    "        self.dropout = nn.Dropout(config.attention_probs_dropout_prob)\n",
    "\n",
    "        self.signal_length = config.signal_length\n",
    "        self.all_length = config.cdd_size * self.signal_length\n",
    "        self.term_num = config.term_num\n",
    "        self.full_attn = config.full_attn\n",
    "\n",
    "        # default to term_num = his_size * k + 1\n",
    "        self.register_buffer('one_pass_attn_mask_train', torch.cat([torch.eye(config.cdd_size).repeat_interleave(repeats=self.signal_length, dim=-1).repeat_interleave(repeats=self.signal_length, dim=0), torch.ones(config.cdd_size * self.signal_length, config.term_num)], dim=-1).unsqueeze(0).unsqueeze(0), persistent=False)\n",
    "        self.register_buffer('one_pass_attn_mask_eval', torch.eye(config.impr_size).repeat_interleave(repeats=self.signal_length, dim=-1), persistent=False)\n",
    "        self.register_buffer('ps_term_mask', torch.ones(1,self.term_num), persistent=False)\n",
    "\n",
    "    def transpose_for_scores(self, x):\n",
    "        \"\"\"\n",
    "        transpose the head_num dimension, to make every head operates in parallel\n",
    "        \"\"\"\n",
    "        new_x_shape = x.size()[:-1] + (self.num_attention_heads, self.attention_head_size)\n",
    "        x = x.view(*new_x_shape)\n",
    "        return x.permute(0, 2, 1, 3)\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        hidden_states,\n",
    "        attention_mask=None,\n",
    "        head_mask=None,\n",
    "        encoder_hidden_states=None,\n",
    "        encoder_attention_mask=None,\n",
    "        past_key_value=None,\n",
    "        output_attentions=False,\n",
    "    ):\n",
    "        \"\"\" customized bert self attention, attending to the references\n",
    "\n",
    "        Args:\n",
    "            hidden_states: normally encoded candidate news, [batch_size, signal_length, hidden_dim]\n",
    "            references: normally personalized terms, [batch_size, term_num, hidden_dim]\n",
    "        \"\"\"\n",
    "        # [CLS] + signal_length\n",
    "        if self.training:\n",
    "            one_pass_mask = self.one_pass_attn_mask_train\n",
    "        else:\n",
    "            attn_field_length = hidden_states.size(1) - self.term_num\n",
    "            cdd_size = attn_field_length // self.signal_length\n",
    "            one_pass_mask = torch.cat([(self.one_pass_attn_mask_eval[:cdd_size, :cdd_size * self.signal_length]).repeat_interleave(repeats=self.signal_length, dim=0), self.ps_term_mask.expand(attn_field_length, self.term_num)], dim=-1).unsqueeze(0).unsqueeze(0)\n",
    "\n",
    "        attn_field = hidden_states[:, :-self.term_num]\n",
    "\n",
    "        # [batch_size, head_num, *, head_dim]\n",
    "        key_layer = self.transpose_for_scores(self.key(hidden_states))\n",
    "        value_layer = self.transpose_for_scores(self.value(hidden_states))\n",
    "        cdd_layer = self.transpose_for_scores(self.query(attn_field))\n",
    "        # Take the dot product between \"query\" and \"key\" to get the raw attention scores.\n",
    "        attention_scores = torch.matmul(cdd_layer, key_layer.transpose(-1, -2))\n",
    "        # [bs, hn, cdd_length, *]\n",
    "        attention_scores = (attention_scores / math.sqrt(self.attention_head_size))\n",
    "        attention_mask_query = one_pass_mask * attention_mask[:, :, :-self.term_num]\n",
    "        # Normalize the attention scores to probabilities.\n",
    "        attention_probs = XSoftmax.apply(attention_scores, attention_mask_query, -1)\n",
    "        print(attention_probs)\n",
    "        \n",
    "        attention_probs = self.dropout(attention_probs)\n",
    "\n",
    "        # full attention\n",
    "        if self.full_attn:\n",
    "            pst_layer = self.transpose_for_scores(self.query(hidden_states[:, -self.term_num:]))\n",
    "            attention_scores_pst = torch.matmul(pst_layer, pst_layer.transpose(-1, -2))\n",
    "            attention_scores_pst = attention_scores_pst / math.sqrt(self.attention_head_size)\n",
    "            attention_mask_pst = attention_mask[:, :, -self.term_num:, -self.term_num:]\n",
    "            attention_probs_pst = XSoftmax.apply(attention_scores_pst, attention_mask_pst, -1)\n",
    "            attention_probs_pst = self.dropout(attention_probs_pst)\n",
    "            context_layer = torch.cat([torch.matmul(attention_probs, value_layer), torch.matmul(attention_probs_pst, value_layer[:, :, -self.term_num:])], dim=-2)\n",
    "\n",
    "        # partial attention, where ps_terms do not interact with each other\n",
    "        else:\n",
    "            context_layer = torch.cat([torch.matmul(attention_probs, value_layer), value_layer[:, :, -self.term_num:]], dim=-2)\n",
    "\n",
    "        # [batch_size, signal_length, head_num, head_dim]\n",
    "        context_layer = context_layer.permute(0, 2, 1, 3).contiguous()\n",
    "        new_context_layer_shape = context_layer.size()[:-2] + (self.all_head_size,)\n",
    "        context_layer = context_layer.view(*new_context_layer_shape)\n",
    "\n",
    "        return (context_layer,)\n",
    "class BERT_Onepass_Ranker(nn.Module):\n",
    "    \"\"\"\n",
    "    one-pass bert:\n",
    "        cdd1 cdd2 ... cddn [SEP] pst1 pst2 ...\n",
    "    \"\"\"\n",
    "    def __init__(self, config):\n",
    "        # confirm the hidden dim to be 768\n",
    "        assert config.embedding_dim == 768\n",
    "        # confirm term_num + signal_length is less than 512\n",
    "        # assert config.k * config.his_size + config.his_size + config.signal_length < 512\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        self.name = 'onepass-bert'\n",
    "        self.signal_length = config.signal_length\n",
    "        self.term_num = config.term_num + 1\n",
    "        self.embedding_dim = config.embedding_dim\n",
    "        self.final_dim = self.embedding_dim\n",
    "\n",
    "        bert_config = BertConfig()\n",
    "        # primary bert\n",
    "        prim_bert = BertModel(bert_config).encoder\n",
    "        bert_config.signal_length = self.signal_length\n",
    "        bert_config.term_num = config.term_num + 1\n",
    "        bert_config.cdd_size = config.cdd_size\n",
    "        bert_config.impr_size = config.impr_size\n",
    "        bert_config.full_attn = config.full_attn\n",
    "        for l in prim_bert.layer:\n",
    "            l.attention.self = BertSelfAttention(bert_config)\n",
    "\n",
    "        bert = BertModel.from_pretrained(\n",
    "            config.bert,\n",
    "            cache_dir=config.path + 'bert_cache/'\n",
    "        )\n",
    "        prim_bert.load_state_dict(bert.encoder.state_dict())\n",
    "        self.bert = prim_bert\n",
    "\n",
    "        self.pooler = nn.Sequential(\n",
    "            nn.Linear(self.embedding_dim, self.final_dim),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "        nn.init.xavier_normal_(self.pooler[0].weight)\n",
    "\n",
    "        # [2, embedding_dim]\n",
    "        self.token_type_embedding = nn.Parameter(torch.randn(2, self.embedding_dim))\n",
    "        nn.init.xavier_normal_(self.token_type_embedding)\n",
    "\n",
    "        # [SEP] token\n",
    "        if config.embedding == 'bert':\n",
    "            self.sep_embedding = nn.Parameter(bert.embeddings.word_embeddings(torch.tensor([102])).clone().detach().requires_grad_(True).view(1,1,self.embedding_dim))\n",
    "        elif config.embedding == 'deberta':\n",
    "            self.sep_embedding = nn.Parameter(bert.embeddings.word_embeddings(torch.tensor([2])).clone().detach().requires_grad_(True).view(1,1,self.embedding_dim))\n",
    "        else:\n",
    "            self.sep_embedding = nn.Parameter(torch.randn(1,1,self.embedding_dim))\n",
    "            nn.init.xavier_normal_(self.sep_embedding)\n",
    "\n",
    "        self.register_buffer('sep_attn_mask', torch.ones(1, 1), persistent=False)\n",
    "\n",
    "    def forward(self, cdd_news_embedding, ps_terms, cdd_attn_mask, ps_term_mask):\n",
    "        \"\"\"\n",
    "        calculate interaction tensor and reduce it to a vector\n",
    "\n",
    "        Args:\n",
    "            cdd_news_embedding: word-level representation of candidate news, [batch_size, cdd_size, signal_length, embedding_dim]\n",
    "            ps_terms: concatenated historical news or personalized terms, [batch_size, term_num, embedding_dim]\n",
    "            cdd_attn_mask: attention mask of the candidate news, [batch_size, cdd_size, signal_length]\n",
    "            ps_term_mask: attention mask of the personalized terms, [batch_size, term_num]\n",
    "\n",
    "        Returns:\n",
    "            reduced_tensor: output tensor after CNN2d, [batch_size, cdd_size, final_dim]\n",
    "        \"\"\"\n",
    "        batch_size = cdd_news_embedding.size(0)\n",
    "        cdd_size = cdd_news_embedding.size(1)\n",
    "\n",
    "        # [bs,tn,hd]\n",
    "        ps_terms += self.token_type_embedding[1]\n",
    "\n",
    "        # [bs, cs*sl, hd]\n",
    "        cdd_news_embedding = cdd_news_embedding.view(batch_size, -1, self.embedding_dim)\n",
    "\n",
    "        bert_input = torch.cat([cdd_news_embedding, self.sep_embedding.expand(batch_size, 1, self.embedding_dim), ps_terms], dim=-2)\n",
    "        bert_input[:, :cdd_news_embedding.size(1) + 1] += self.token_type_embedding[0]\n",
    "\n",
    "        # [bs, cs*sl]\n",
    "        attn_mask = cdd_attn_mask.view(batch_size, -1)\n",
    "        cdd_length = attn_mask.size(-1)\n",
    "\n",
    "        attn_mask = torch.cat([attn_mask, self.sep_attn_mask.expand(batch_size, 1), ps_term_mask], dim=-1)\n",
    "        attn_mask = get_attn_mask(attn_mask)\n",
    "\n",
    "        bert_output = self.bert(bert_input, attention_mask=attn_mask).last_hidden_state[:, 0 : cdd_size * (self.signal_length) : self.signal_length].view(batch_size, cdd_size, self.embedding_dim)\n",
    "        bert_output = self.pooler(bert_output)\n",
    "\n",
    "        return bert_output\n",
    "\n",
    "ranker = BERT_Onepass_Ranker(manager)\n",
    "model = ESM(manager, embedding, encoderN, encoderU, reducer, ranker).to(manager.device)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "# model.eval()\n",
    "# a,b = model(x2)\n",
    "\n",
    "a,b = model(x1)"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_310176/1746876337.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# a,b = model(x2)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([0.3333, 0.0000, 0.3333, 0.3333])"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.11",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.11 64-bit (conda)"
  },
  "interpreter": {
   "hash": "decb58d8582e8bebc2c9af4e5243ce054f2f8013c5b7e79ffbf7b8b9f3c0761b"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}