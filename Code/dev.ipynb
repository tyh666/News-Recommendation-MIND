{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "import re\n",
    "import logging\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "import time\n",
    "import pickle\n",
    "from collections import defaultdict\n",
    "from data.configs.demo import config\n",
    "from collections import defaultdict\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModel, BertModel, BertConfig, AutoModelForSequenceClassification\n",
    "from utils.Manager import Manager\n",
    "\n",
    "from models.Embeddings.BERT import BERT_Embedding\n",
    "from models.Encoders.CNN import CNN_Encoder,CNN_User_Encoder\n",
    "from models.Encoders.RNN import RNN_Encoder,RNN_User_Encoder\n",
    "from models.Encoders.MHA import MHA_Encoder, MHA_User_Encoder\n",
    "from models.Modules.DRM import Matching_Reducer, Identical_Reducer\n",
    "from models.Rankers.BERT import BERT_Onepass_Ranker, BERT_Original_Ranker\n",
    "from models.Rankers.CNN import CNN_Ranker\n",
    "from models.Encoders.Pooling import Attention_Pooling, Average_Pooling\n",
    "from models.UniLM.modeling import TuringNLRv3Model, TuringNLRv3ForSequenceClassification\n",
    "from models.UniLM.configuration_tnlrv3 import TuringNLRv3Config\n",
    "\n",
    "from models.BaseModel import BaseModel\n",
    "\n",
    "from models.Encoders.BERT import BERT_Encoder\n",
    "from models.Encoders.Pooling import *\n",
    "\n",
    "from models.ESM import ESM\n",
    "from models.TESRec import TESRec\n",
    " \n",
    "from models.Modules.Attention import MultiheadAttention, get_attn_mask, XSoftmax\n",
    "torch.set_printoptions(threshold=100000)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "# m = AutoModel.from_pretrained('bert-base-uncased',cache_dir=config.path + 'bert_cache/')\n",
    "m2 = AutoModel.from_pretrained('microsoft/deberta-base',cache_dir=config.path + 'bert_cache/')\n",
    "# m3 = TuringNLRv3ForSequenceClassification.from_pretrained(config.unilm_path, config=TuringNLRv3Config.from_pretrained(config.unilm_config_path))\n",
    "\n",
    "# t = AutoTokenizer.from_pretrained('bert-base-uncased', cache_dir=config.path + \"bert_cache/\")\n",
    "# t2 = AutoTokenizer.from_pretrained('microsoft/deberta-base', cache_dir=config.path + \"bert_cache/\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Some weights of the model checkpoint at microsoft/deberta-base were not used when initializing DebertaModel: ['lm_predictions.lm_head.dense.weight', 'config', 'lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.dense.bias', 'lm_predictions.lm_head.bias', 'lm_predictions.lm_head.LayerNorm.weight']\n",
      "- This IS expected if you are initializing DebertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "res = m2(**t2(\"I love you\",return_tensors='pt'))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "res[0]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[[ 3.2291e-02, -3.0468e-02, -7.3887e-02, -3.6202e-02,  2.0748e-02,\n",
       "           7.4711e-02, -1.0307e-01,  6.7794e-03,  1.2712e-01, -9.5647e-03,\n",
       "          -9.1559e-02,  3.7835e-02, -1.3358e-02, -6.4475e-03, -2.6843e-02,\n",
       "          -2.7349e-02,  3.1836e-02,  3.1301e-02,  4.8960e-02,  1.9734e-02,\n",
       "           5.9289e-02,  6.9324e-02,  1.6465e-02, -6.5859e-02,  2.8091e-02,\n",
       "           1.4949e-02,  3.7724e-02,  8.4763e-02,  2.3906e-02,  2.3752e-03,\n",
       "          -2.7981e-02,  4.1448e-02,  1.2630e-02, -1.3371e-02,  8.3813e-02,\n",
       "           5.0158e-02,  3.1099e-02, -2.8733e-02,  5.9805e-02,  6.1455e-02,\n",
       "          -7.6608e-03, -1.0536e-01, -3.1629e-02,  5.1225e-02, -2.4642e-02,\n",
       "           7.2206e-02,  3.1195e-02,  1.4184e-02,  5.8173e-02,  8.4283e-03,\n",
       "           2.6641e-02,  3.9767e-03,  3.0970e-02,  2.1092e-03,  2.9037e-02,\n",
       "           9.4432e-02, -2.2286e-02, -1.8314e-02,  6.4365e-02,  5.5747e-02,\n",
       "          -5.4382e-02,  7.4659e-02, -7.9415e-02,  7.9499e-03, -6.9032e-02,\n",
       "           1.4290e-02, -2.7142e-02, -4.2423e-02,  1.1238e-02,  6.1810e-02,\n",
       "          -9.4845e-03, -1.3447e-02,  6.9302e-02, -8.7353e-02,  2.9835e-03,\n",
       "           6.1171e-02,  5.7985e-03, -1.3293e-02, -6.9601e-02, -6.5800e-02,\n",
       "           2.0688e-03,  4.2659e-02, -6.3207e-02, -2.2220e-02, -8.7279e-02,\n",
       "          -5.7801e-03,  6.2918e-02, -6.4805e-03,  4.5858e-02, -7.0769e-02,\n",
       "           3.6968e-02, -2.4692e-03,  7.7626e-03, -4.5215e-03, -2.2426e-02,\n",
       "          -3.6472e-02,  6.3434e-03, -1.0172e+00,  1.7877e-02, -4.7483e-02,\n",
       "          -3.8946e-02, -1.0707e-01, -2.3549e-02,  7.1452e-02, -1.4866e-01,\n",
       "           5.9001e-02,  1.8714e-02,  3.3480e-02,  7.6852e-02, -4.9492e-02,\n",
       "           5.8518e-02, -5.2132e-02,  3.5678e-02,  3.9073e-02, -6.1022e-02,\n",
       "          -6.5558e-02, -6.5361e-02,  7.9207e-02, -3.1234e-03,  3.5587e-02,\n",
       "          -3.0249e-03,  6.6925e-02,  2.8292e-02, -2.2488e-02,  2.7256e-02,\n",
       "           1.5019e-02,  4.2174e-02,  9.0133e-03, -9.7384e-03,  5.4585e-02,\n",
       "           2.9489e-03,  3.1688e-02, -1.7316e-02, -2.2616e-02, -3.2685e-02,\n",
       "           7.7102e-02, -2.1578e-02, -4.1034e-02, -3.4037e-01, -8.2284e-03,\n",
       "           1.6232e-03,  3.3917e-02, -3.4743e-02,  1.8080e-02,  7.5395e-02,\n",
       "           2.0484e-02,  8.2522e-02,  3.6799e-02, -2.0538e-03, -1.4884e-02,\n",
       "           3.4665e-02, -8.9308e-02,  4.1212e-02,  3.8475e-02,  6.1557e-05,\n",
       "           6.2576e-02, -3.4823e-02,  1.0680e-01,  1.2681e-02, -1.2880e-01,\n",
       "           2.4965e-02,  4.2094e-02,  1.0362e-02, -1.3344e-02, -1.1400e-02,\n",
       "           1.0803e-02,  2.2820e-02, -1.2930e-02, -1.1414e-02, -3.8752e-02,\n",
       "           2.8777e-02, -1.1222e-02,  7.9291e-02,  7.3893e-02, -4.7795e-02,\n",
       "          -9.1988e-02,  1.8984e-02, -1.3475e-03,  2.5080e-02,  3.2349e-02,\n",
       "           8.0013e-03, -3.1786e-03, -5.5404e-02,  1.8854e-02,  1.2464e-02,\n",
       "           3.6533e-02,  4.5702e-02,  5.4797e-02, -6.5577e-02,  4.8387e-02,\n",
       "           5.2062e-02, -8.5135e-03, -1.1681e-01,  2.8376e-02,  6.3709e-02,\n",
       "           6.2529e-02, -1.9569e-02, -5.4515e-02,  4.9708e-02,  4.0251e-02,\n",
       "           6.1367e-02, -9.2404e-02,  1.8532e-02, -1.2305e-02,  1.7327e-02,\n",
       "           7.9734e-02, -2.4001e-02,  1.0467e-02,  9.8464e-03, -5.3847e-03,\n",
       "          -6.0758e-02,  3.1507e-03, -5.0945e-02, -4.4332e-02,  1.6747e-02,\n",
       "          -6.2742e-02, -6.3502e-02, -3.9431e-02,  2.9726e-02, -1.7176e-02,\n",
       "           3.2744e-02,  6.8133e-02, -4.2760e-02,  8.8979e-03, -2.2004e-02,\n",
       "          -3.8907e-02, -3.1213e-02, -2.7338e-02,  7.9527e-02,  3.4776e-02,\n",
       "          -8.6058e-03,  1.5082e-02,  3.9979e-02,  4.0495e-02, -1.1563e-02,\n",
       "           2.0626e-02,  1.9204e-02, -1.6359e-02, -6.4641e-02,  4.3548e-02,\n",
       "          -2.3042e-02,  6.1035e-02, -3.3902e-02,  3.4522e-03, -3.6130e-02,\n",
       "          -3.5315e-03,  5.7005e-02,  6.8772e-02, -7.9898e-02, -9.7663e-03,\n",
       "          -4.0682e-02,  5.7654e-03, -1.5836e-02, -7.8064e-03, -9.4592e-03,\n",
       "           6.1117e-02,  4.2996e-02, -5.2102e-02,  1.5678e-01, -7.4158e-02,\n",
       "           5.4729e-02,  2.5223e-02,  5.4240e-03, -5.6272e-02,  4.3334e-03,\n",
       "           7.9011e-03,  7.5399e-02,  2.0483e-02,  3.5609e-02,  2.3125e-02,\n",
       "          -3.6271e-03,  6.8097e-04,  1.7590e-02,  2.7358e-02, -4.8472e-02,\n",
       "          -1.3831e-02, -5.4841e-02,  5.5202e-02,  3.9988e-02,  8.0178e-03,\n",
       "           5.3070e-03,  8.6777e-03,  7.6104e+00,  2.8018e-02,  1.0932e-02,\n",
       "           8.5685e-02,  1.4685e-02,  1.1471e-01,  3.4223e-02,  1.5850e-02,\n",
       "           6.6998e-02, -4.4246e-02, -4.9481e-02,  8.5744e-03,  2.5919e-02,\n",
       "           3.8303e-02, -5.6214e-03, -1.7286e-02, -8.9187e-03, -7.2308e-02,\n",
       "          -2.4351e-02,  6.0701e-02, -8.3013e-02, -9.2696e-02,  1.6250e-02,\n",
       "           1.2176e-03,  5.8714e-02, -3.4820e-02, -9.4394e-02,  5.5517e-02,\n",
       "           1.4083e-02, -1.7526e-02, -1.2463e-02,  4.2523e-02, -3.7227e-02,\n",
       "          -9.5108e-02, -1.0118e-02,  1.2950e-02, -2.1650e-02, -1.8153e-02,\n",
       "           5.6586e-02, -1.0177e-02,  1.4730e-01,  5.1214e-02,  6.8289e-02,\n",
       "          -3.6289e-02,  7.0526e-02, -9.2126e-02,  8.9935e-02,  1.0002e-02,\n",
       "          -8.2121e-02, -9.6086e-04,  1.4822e-02, -2.9107e-03, -2.8299e-02,\n",
       "          -3.0898e-02, -2.6031e-02,  6.1320e-02,  3.5723e-02,  1.9784e-02,\n",
       "          -1.3855e-02, -7.1856e-02,  2.6986e-02,  5.9339e-02, -3.5951e-02,\n",
       "          -2.0850e-02, -9.7109e-02,  1.2971e-02,  1.5190e-02, -1.7746e-02,\n",
       "          -4.9119e-02,  3.5977e-02,  4.9093e-02, -1.0109e-01,  2.7696e-02,\n",
       "           6.0982e-02, -5.3475e-02, -1.4651e-02, -2.7612e-02,  2.4568e-02,\n",
       "           1.1172e-02,  5.5892e-02,  5.0601e-03,  2.0065e-02, -1.0040e-01,\n",
       "           4.3955e-02, -1.2543e-02, -6.3942e-03,  2.9398e-02,  2.7972e-02,\n",
       "          -1.2160e-02,  2.1634e-02,  4.5561e-02,  1.4505e-01, -2.3695e-02,\n",
       "          -4.8079e-02, -5.7675e-04, -2.6416e-02, -3.8961e-02, -2.5335e-02,\n",
       "          -2.3296e-02, -2.9452e-03,  3.6521e-02,  7.1522e-02,  1.9778e-02,\n",
       "           5.1786e-02,  1.0498e-01,  7.4521e-02,  1.4605e-03,  2.5398e-02,\n",
       "           4.5245e-02,  8.1600e-02, -1.9630e-02, -2.6982e-02,  2.7539e-02,\n",
       "           1.4298e-02,  1.7055e-01, -1.0714e-02, -7.6754e-02,  2.0602e-02,\n",
       "           8.8472e-02,  6.0435e-02,  4.5275e-02,  2.0529e-02, -7.7338e-02,\n",
       "           1.6029e-02, -8.1098e-02, -3.4050e-02, -1.1083e-01,  1.6849e-02,\n",
       "          -5.3714e-03, -1.3238e-01,  1.0423e-02,  3.5149e-03, -5.0896e-02,\n",
       "          -1.1037e-02, -1.6417e-02,  8.5065e-02,  4.3199e-02, -6.3565e-04,\n",
       "          -3.3454e-02, -2.8437e-03, -1.6936e-02, -3.0172e-02, -4.0360e-02,\n",
       "           4.5012e-02, -4.4762e-02,  8.8187e-02, -5.4002e-02,  5.8340e-03,\n",
       "          -4.7717e-03,  2.7382e-02, -7.8440e-03, -8.2805e-02, -5.5218e-03,\n",
       "           5.1196e-02, -4.3811e-02,  1.6340e-03, -8.5184e-03,  6.8702e-02,\n",
       "          -6.3522e-02,  7.5024e-02,  7.3463e-02,  4.6831e-02,  1.9411e-02,\n",
       "           5.8069e-02,  8.8150e-02,  1.0151e-02,  7.2234e-03,  2.2615e-02,\n",
       "           3.7413e-02, -9.9836e-03,  4.3578e-02, -7.6664e-02, -3.3356e-02,\n",
       "          -9.6508e-03, -4.9855e-02,  2.9399e-02,  3.0099e-02,  9.0865e-03,\n",
       "           5.1645e-02, -7.2015e-03, -1.1816e-02,  7.5882e-02,  3.3804e-02,\n",
       "          -6.3833e-02, -3.1038e-02,  2.8322e-02, -1.8863e-02, -2.5474e-02,\n",
       "          -2.8137e-02,  2.1048e-02, -2.1567e-02,  7.0049e-02,  1.3349e-02,\n",
       "           6.3209e-02, -1.7534e-02,  5.2000e-02, -8.7683e-02,  1.1403e-02,\n",
       "          -3.6318e-02,  1.2359e-01,  6.9944e-02, -7.0799e-02,  4.7754e-02,\n",
       "           5.0420e-02, -2.0419e-02,  2.0536e-02,  9.5482e-02,  2.2041e-02,\n",
       "           5.5893e-02,  5.8835e-02,  6.9432e-03, -7.8854e-02,  7.9327e-02,\n",
       "           2.8770e-02, -7.7635e-03,  3.8489e-02,  5.2999e-02, -9.7792e-02,\n",
       "          -3.1822e-02,  1.3507e-02, -2.8354e-02, -1.1991e-02,  3.1045e-02,\n",
       "          -5.5684e-02, -2.9801e-02, -7.3286e-02,  6.5607e-02, -1.8020e-02,\n",
       "           6.7929e-02, -2.3124e-02,  3.9101e-02,  7.9666e-02, -2.9574e-02,\n",
       "           3.4637e-02, -9.1209e-03, -8.0788e-02, -3.2217e-02, -6.8435e-02,\n",
       "           6.6537e-02, -3.3385e-02,  4.0564e-02,  1.0880e-02,  6.4465e-02,\n",
       "          -7.0970e-03,  7.7481e-02, -2.8721e-02,  1.0414e-01,  4.9946e-02,\n",
       "          -3.7396e-02, -1.6516e-02, -4.4795e-02,  7.7631e-02, -7.7226e-02,\n",
       "           1.1710e-02,  1.0218e-01,  3.4705e-02, -1.7379e-02,  2.1033e-03,\n",
       "           5.7095e-02, -3.9886e-02, -1.1229e-02,  9.0593e+00,  1.8028e-02,\n",
       "          -3.8044e-02,  3.5851e-02,  3.5400e-02, -7.4396e-02,  6.3088e-03,\n",
       "          -1.3533e-02, -8.2662e-02, -1.9128e-02,  9.3377e-02,  4.1174e-02,\n",
       "           4.2335e-02, -1.6957e-02, -2.7948e-02,  2.7426e-02, -1.0354e-02,\n",
       "          -6.0242e-02, -8.5138e-02,  6.3722e-02, -3.0623e-02,  7.5621e-03,\n",
       "           8.4973e-02, -2.9877e-02, -9.0087e-03, -2.4474e-02, -1.3311e-01,\n",
       "           2.0371e-02,  1.7534e-02, -5.8170e-03, -5.4574e-02,  1.5265e-02,\n",
       "          -5.4939e-03,  6.2999e-02, -8.2556e-02, -7.8847e-02, -4.9260e-02,\n",
       "          -9.3939e-02,  8.3962e-02,  1.3700e-02, -4.1309e-02, -2.0328e-02,\n",
       "          -2.6948e-03, -2.5702e-02,  5.4058e-02,  3.0833e-02, -4.0622e-02,\n",
       "           2.0444e-02,  2.0911e-02,  9.7615e-03,  1.6910e+00, -1.0463e-02,\n",
       "          -2.2134e-02,  2.0929e-03,  3.6071e-02,  2.4199e-02,  1.6747e-03,\n",
       "          -6.8477e-03,  8.1152e-02, -1.2334e-01, -1.1990e-02,  8.1521e-02,\n",
       "          -3.3164e-02,  4.1655e-02, -7.2286e-02,  2.3888e-04,  7.5466e-02,\n",
       "           2.4145e-02, -3.0422e-02, -2.2515e-02, -2.4628e-02, -2.6615e-02,\n",
       "           5.4132e-02, -8.0317e-02,  1.5250e-02, -4.4777e-02, -9.3617e-02,\n",
       "          -7.3290e-02, -8.3132e-03, -7.6936e-03,  1.8898e-03, -1.5583e-02,\n",
       "           8.5025e-02, -8.0685e-03, -3.8949e-02, -6.9994e-02, -9.0245e-02,\n",
       "           2.3548e-02,  6.8156e-02, -1.8933e-02,  2.3666e-03, -2.3585e-03,\n",
       "          -9.6289e-03,  5.1961e-02,  3.2723e-02,  1.9199e-02,  8.9206e-04,\n",
       "          -3.7612e-02, -3.3814e-02,  1.7763e-02, -4.0882e-02,  6.0542e-02,\n",
       "           1.8002e-02,  3.4565e-02, -1.5061e-03, -4.0533e-02,  3.6844e-02,\n",
       "          -4.7417e-01,  2.5605e-02, -5.3088e-02, -7.2432e-02, -1.2343e-02,\n",
       "           1.9779e-03,  7.4630e-02,  1.1644e-02, -1.6493e-02,  3.1026e-02,\n",
       "           1.5532e-02, -3.7170e-02,  1.0628e-02,  6.7154e-02, -2.8639e-02,\n",
       "          -3.7277e-02, -1.7513e-02, -1.2046e-01, -4.5277e-03, -4.3119e-02,\n",
       "           2.7001e-02,  2.2047e-02, -8.2500e-02,  6.2656e-02, -4.3167e-02,\n",
       "           1.1991e-02, -5.0600e-02, -5.5667e-02, -9.6308e-03,  3.2561e-03,\n",
       "           3.0086e-02,  2.2481e-02, -7.5802e-03, -7.9504e-02,  4.1963e-02,\n",
       "           4.6686e-02, -3.2104e-02, -1.0842e-01, -9.4412e-03,  1.0348e-02,\n",
       "           6.9436e-02,  8.8975e-02, -3.5743e-02,  4.3068e-02, -7.6294e-03,\n",
       "          -3.1974e-02, -1.0034e-02, -6.5185e-02,  4.5900e-02,  3.4547e-02,\n",
       "          -7.2371e-02, -8.4226e-02,  3.1944e-02, -3.0430e-02,  2.9394e-02,\n",
       "           1.2780e-02, -2.6881e-02,  1.8428e-02, -1.7850e-02,  4.6578e-02,\n",
       "          -9.9028e-02, -4.5038e-02,  2.3485e-02,  2.3037e-02,  5.2753e-02,\n",
       "          -9.0417e-02,  6.1493e-02,  9.8858e-02,  3.2113e-02, -5.2020e-02,\n",
       "           1.9380e-02, -2.8834e-02,  6.6268e-02,  7.3896e-02, -2.0896e-03,\n",
       "          -4.2705e-02,  4.8313e-01,  3.7539e-03, -6.1128e-02, -4.4845e-03,\n",
       "           1.2285e-02, -3.8994e-02, -4.6563e-02,  6.8442e-02, -4.8274e-02,\n",
       "          -1.2172e-01, -1.7052e-02,  8.7105e-03,  6.0201e-02,  5.2171e-03,\n",
       "          -4.4802e-02, -7.8033e-03, -1.1156e-01,  3.1699e-02, -4.2254e-02,\n",
       "           2.4988e-02,  2.4935e-02, -3.1719e-02,  1.4139e-02, -3.1676e-02,\n",
       "          -8.3768e-02,  3.9190e-02, -1.9350e-02,  4.6308e+00, -8.9500e+00,\n",
       "           1.2023e-02, -3.2312e-02, -8.8075e-03, -4.4400e-02, -4.0072e-02,\n",
       "           3.5859e-02, -1.3168e-02,  2.9709e-03,  7.1577e-02, -3.0921e-02,\n",
       "           9.9423e-03,  6.6328e-02, -7.1814e-02],\n",
       "         [-6.6780e-01, -7.0108e-01, -5.9571e-01,  2.2720e-01, -9.1682e-01,\n",
       "           4.5642e-01, -9.0040e-01, -1.0311e-01,  9.7147e-01,  1.0400e+00,\n",
       "          -3.7437e-01,  3.0137e-01,  3.1876e-01, -1.0029e-01,  7.6190e-01,\n",
       "          -5.1707e-02,  1.3160e-01, -4.1997e-01,  2.0498e-01,  8.5692e-01,\n",
       "          -4.5604e-01,  2.8084e-01, -1.0268e+00, -1.8003e+00, -8.2499e-01,\n",
       "           7.9548e-01, -6.8441e-01,  3.0702e-01, -1.2853e-02, -1.8134e-01,\n",
       "           5.2700e-01, -6.2389e-01, -9.2826e-01,  1.6660e-01,  1.2765e+00,\n",
       "           5.0917e-04,  2.1376e-01,  1.7519e-01,  4.6994e-01,  4.7838e-01,\n",
       "          -2.1928e-01, -3.8064e-02,  6.8907e-01, -5.3621e-01, -4.8406e-01,\n",
       "          -9.7921e-01, -2.4143e-01, -8.6389e-02, -1.3944e+00,  7.3285e-01,\n",
       "           5.6701e-01, -8.8067e-01,  1.0643e+00, -4.5617e-01, -7.0981e-01,\n",
       "           4.0996e-01, -6.6612e-01, -2.6364e-02, -4.9003e-01, -2.1482e-01,\n",
       "          -3.6978e-01, -4.8463e-01, -1.3127e-01, -1.5433e-01, -2.0335e-01,\n",
       "           2.3827e-01, -8.3156e-01,  1.0608e-01,  1.3330e-01,  7.3283e-01,\n",
       "           4.4813e-01,  1.8574e-01, -3.7192e-01,  4.5686e-02,  1.8202e-01,\n",
       "           5.8080e-01,  2.9695e-01, -1.8180e-01,  8.9413e-01, -9.2279e-01,\n",
       "           1.2659e+00,  1.0846e+00,  4.9964e-01,  8.6874e-01, -2.6728e-01,\n",
       "           3.1082e-01, -1.1033e+00,  5.8905e-01,  6.6156e-02, -1.3029e+00,\n",
       "           5.3156e-01,  2.3037e-01,  5.0717e-01,  1.1839e-01,  9.1538e-01,\n",
       "           4.3005e-01, -5.0142e-01,  1.3277e-01,  1.3778e-01,  1.5808e-01,\n",
       "          -1.7890e-02, -4.0136e-01, -5.9455e-01, -5.0869e-01, -1.0900e+00,\n",
       "           1.0701e+00,  1.0643e-01,  1.6386e-01, -1.9308e-01,  4.0134e-01,\n",
       "           2.1908e-01, -1.6723e+00,  7.6454e-03, -2.8017e-02, -5.0146e-01,\n",
       "           1.0131e+00, -5.3072e-01, -7.3517e-01, -5.7454e-01, -6.1639e-01,\n",
       "           4.8242e-01, -7.8772e-01,  4.4022e-01, -4.2364e-01,  7.4052e-01,\n",
       "          -5.5326e-01, -6.1652e-02, -3.2928e-01, -8.3101e-03,  2.2732e-01,\n",
       "           3.7639e-01,  5.5458e-02,  9.7423e-01, -1.0360e-01,  1.3252e+00,\n",
       "          -3.4109e-02,  3.6114e-02,  8.6059e-02, -5.8037e-01,  2.1165e-01,\n",
       "          -3.2414e-01, -3.9542e-01, -3.4941e-01, -5.3665e-01,  7.1007e-02,\n",
       "           7.1395e-01, -4.9685e-01, -2.6767e-01, -4.4522e-01, -1.6089e-01,\n",
       "          -3.6305e-02, -1.0057e+00, -1.1957e+00,  2.3774e-01,  4.5992e-01,\n",
       "          -3.8063e-01,  2.7057e-01,  4.1410e-01,  4.8178e-01, -1.7557e-03,\n",
       "          -4.2321e-01,  1.3618e-01,  6.2162e-01, -1.3256e-01, -4.3736e-01,\n",
       "           1.3264e+00,  1.3515e-01, -6.7091e-01,  1.0060e-01, -4.9852e-02,\n",
       "          -2.2210e-01, -2.0507e-01,  9.0595e-01,  7.3012e-01,  3.8631e-01,\n",
       "           5.9310e-01,  1.4405e+00, -1.6819e-01, -4.1902e-01, -1.1630e-01,\n",
       "          -1.0010e-01, -3.0019e-01,  2.2127e-02, -9.0745e-02,  6.6628e-02,\n",
       "           1.1649e+00, -5.7340e-01, -2.7455e-01,  8.9287e-01, -7.6110e-02,\n",
       "          -1.5402e-01, -8.4351e-01, -3.1737e-01, -1.4663e-01,  5.3585e-01,\n",
       "           7.6400e-01, -1.0164e-01,  8.7328e-01,  1.5401e+00,  9.3398e-02,\n",
       "           9.3643e-01, -5.2348e-01, -7.2781e-01,  7.5593e-01, -1.9792e-01,\n",
       "           4.2484e-01, -8.5114e+00,  4.3949e-01, -2.7644e-02,  5.5215e-01,\n",
       "          -3.6990e-01, -3.2210e-01, -4.4149e-02,  3.3126e-01,  3.5611e-01,\n",
       "          -1.0682e-01, -1.0456e-01,  3.7358e-01,  4.2044e-01, -9.8941e-02,\n",
       "          -4.4354e-01, -1.3941e-01,  7.9190e-01, -3.3337e-01,  2.1609e-01,\n",
       "           1.0665e+00, -2.2926e-01,  2.2884e-01,  3.4247e-01,  2.7304e-01,\n",
       "          -1.9702e-01, -3.5309e-01,  7.5752e-01, -1.6775e-01,  3.8149e-01,\n",
       "          -1.7593e+00,  8.4854e-01, -3.4447e-02,  3.8617e-01,  3.0693e-01,\n",
       "          -2.5004e-01,  9.2094e-01,  3.9057e-01,  3.9806e-01,  6.7573e-02,\n",
       "           1.8903e-01,  3.4859e-01,  8.0922e-01,  1.7316e-01, -2.7996e-01,\n",
       "          -1.3218e+00,  7.8172e-02,  8.3852e-01,  1.0652e+00, -7.4718e-01,\n",
       "          -1.0389e+00,  8.8961e-01,  2.7604e-01,  9.7642e-02, -4.1158e-01,\n",
       "           1.4057e-01, -3.4950e-01, -3.5806e-01, -3.1168e-01,  3.1695e-01,\n",
       "          -2.4871e-01, -3.4277e-01, -2.5614e-01,  8.0678e-02, -1.3197e+00,\n",
       "           3.0862e-01,  5.4587e-01,  3.6200e-01,  6.5365e-02, -5.4971e-01,\n",
       "          -1.2688e-01,  2.8073e-01,  8.2635e-02,  4.4031e-01,  1.1948e-01,\n",
       "          -3.7790e-01, -6.4061e-02,  5.1609e-01,  4.7544e-01,  3.8148e-02,\n",
       "          -9.8241e-02,  1.3950e+00, -1.0735e-01,  5.2862e-01, -7.5036e-01,\n",
       "          -3.7261e-02, -3.0759e-01,  2.4489e-01, -1.0200e+00,  5.2753e-01,\n",
       "           6.0598e-01,  2.1650e-02,  3.2556e-01,  1.0614e-01, -6.3411e-01,\n",
       "           3.4361e-01,  3.7819e-01, -6.9052e-01,  9.1239e-01, -1.0414e-01,\n",
       "          -3.0042e-01,  7.6129e-01, -9.1547e-02,  3.8473e-01, -1.4506e-01,\n",
       "          -2.0083e-01, -4.2669e-01,  3.7455e-01, -9.9254e-01, -3.6657e-01,\n",
       "           3.2728e-01, -6.0282e-01,  5.0980e-01, -7.6304e-01,  1.6407e-01,\n",
       "           8.2713e-02, -5.9427e-01,  3.6045e-01,  4.0034e-01, -6.9040e-01,\n",
       "           1.6108e-01, -1.9061e-01, -3.4048e-01,  8.0032e-01, -3.4282e-01,\n",
       "          -2.4227e-01,  4.9972e-01, -5.1947e-01, -4.4521e-02, -1.5792e-01,\n",
       "          -2.2774e-01,  1.4715e+00, -9.6744e-02, -1.0222e-01, -4.7758e-02,\n",
       "           1.9951e-01,  2.4873e-02,  6.3600e-01,  1.1487e-01, -6.3980e-01,\n",
       "           2.1202e-02,  3.2078e-01, -1.0308e+00,  2.6227e-01,  5.5958e-01,\n",
       "          -7.2436e-01,  3.7149e-01,  1.9303e+00,  7.8028e-02,  1.6591e-01,\n",
       "           9.7752e-01, -2.0711e-02, -8.8356e-01,  4.2626e-01,  6.5642e-01,\n",
       "           3.4325e-01,  5.7378e-02,  6.7957e-01,  1.0971e-01, -1.3656e+00,\n",
       "          -2.2083e-01,  9.2158e-01, -1.4824e-01,  5.4682e-02, -5.9529e-02,\n",
       "           3.4962e-01,  2.2833e-01, -2.2546e-02, -7.3763e-02,  2.8504e-01,\n",
       "           2.3607e-01,  5.3948e-01,  7.4151e-01,  6.0358e-01,  5.2983e-01,\n",
       "           1.6938e-01, -6.5996e-01, -9.1486e-01,  5.2342e-01,  2.0309e-01,\n",
       "          -4.0845e-01,  4.3364e-01, -1.3723e-01,  4.5793e-01, -2.9341e-01,\n",
       "          -3.8173e-01, -4.6296e-02,  7.7739e-01,  5.9378e-01,  2.9568e-01,\n",
       "          -1.7408e-02, -1.8369e-01,  2.1967e-01,  4.2864e-01, -7.9394e-02,\n",
       "          -1.1419e-01,  4.0972e-02,  4.6999e-01, -3.2590e-01, -4.5854e-01,\n",
       "          -1.5197e-01, -8.0148e-01,  5.2154e-01,  7.1608e-01,  1.4765e-01,\n",
       "          -2.2688e-01, -2.9097e-01, -8.5062e-01, -6.2752e-01,  5.9181e-01,\n",
       "          -2.1793e-01, -3.6768e-01, -1.8022e-01, -3.4230e-01,  4.3163e-01,\n",
       "           5.5812e-01, -1.6582e-01,  9.9112e-01,  8.1721e-01,  6.9293e-02,\n",
       "           1.9928e-01, -2.0150e-01, -1.2650e-01, -8.0419e-01, -7.3474e-04,\n",
       "          -1.9078e-01,  1.3405e+00, -1.6956e-01,  8.4876e-01, -4.5278e-01,\n",
       "           4.3201e-01, -6.0559e-01,  2.9983e-01,  3.7855e-01, -9.7467e-03,\n",
       "          -1.1603e+00, -7.8400e-01, -1.8007e-01,  1.1553e+00,  5.4720e-01,\n",
       "          -2.2873e-02,  9.0737e-03,  1.0143e+00,  5.7160e-01, -9.5797e-01,\n",
       "           8.0528e-01, -2.3040e-01, -2.5962e-01, -9.3836e-01,  4.9116e-01,\n",
       "          -4.9729e-02,  9.8987e-01,  1.1325e+00, -6.8394e-02,  2.1958e-01,\n",
       "           6.8728e-01,  3.6849e-01,  3.7829e-01, -1.5308e-02,  7.6340e-01,\n",
       "          -2.5485e-01, -3.4559e-01,  4.1827e-01,  2.6726e-01, -6.8763e-01,\n",
       "          -1.0257e-01, -4.3578e-01, -6.2776e-01, -3.7352e-01, -6.1968e-01,\n",
       "          -4.4388e-01, -3.8161e-01,  6.5555e-01,  1.0119e+00,  9.1217e-01,\n",
       "          -1.4690e+00,  5.3597e-01,  4.9585e-01,  1.3343e-01,  1.8457e-01,\n",
       "           1.1818e+00, -1.3359e+00, -6.0450e-01,  4.5349e-01,  4.7767e-01,\n",
       "           6.9440e-01, -4.4996e-01, -2.0579e-01, -6.8577e-01,  9.6587e-01,\n",
       "           1.6029e-02,  8.6464e-01,  3.1748e-01, -1.0338e+00,  1.0657e-02,\n",
       "           8.5244e-01, -9.8717e-02,  5.0926e-01,  2.4220e-01,  1.7439e-01,\n",
       "          -5.8065e-01, -3.0021e-01,  7.1428e-01, -5.5274e-03,  5.1110e-01,\n",
       "          -3.7065e-01,  3.4421e-02, -4.2445e-01, -2.9014e-01,  1.1920e+00,\n",
       "          -2.2593e-01,  4.2568e-01,  1.1140e-02, -8.6798e-01, -1.7545e+00,\n",
       "           6.4535e-01, -4.7839e-01,  1.5318e-01,  4.9629e-02,  6.2294e-01,\n",
       "           6.4395e-01, -2.0917e-01, -3.8634e-01, -4.8010e-01,  4.5468e-01,\n",
       "           3.6225e-01,  5.6969e-04, -2.3881e-01,  3.8076e-01, -3.8173e-01,\n",
       "          -5.5520e-01,  7.6356e-01, -3.6854e-01,  1.8138e-01,  4.3713e-01,\n",
       "          -1.2378e-01, -4.5483e-01, -1.2764e+00, -1.4656e-01,  2.2198e-01,\n",
       "          -4.1567e-01,  9.3490e-02, -7.5440e-01,  5.0492e-02, -4.5864e-01,\n",
       "           1.4107e+00, -7.2675e-01, -7.4105e-01, -2.2191e-01,  6.3162e-01,\n",
       "          -7.9767e-01,  9.8082e-02, -2.3340e-01,  4.3570e-01, -1.4178e+00,\n",
       "           1.0859e-01, -9.5400e-01, -4.8242e-01,  1.1226e-01,  3.7400e-01,\n",
       "           1.0801e+00,  4.2433e-01,  2.8430e-01,  4.0266e-01, -5.6535e+00,\n",
       "           7.5102e-01, -3.2224e-01, -2.2405e+00,  2.4799e-01, -7.4024e-02,\n",
       "          -2.7634e-01, -1.2519e-01,  1.3738e-01,  1.9944e-01,  4.3166e-01,\n",
       "          -3.1553e-01,  3.3500e-01, -4.2081e-02, -5.1312e-01,  1.5011e-01,\n",
       "           1.4372e-01,  1.0082e+00, -3.5698e-01,  4.7779e-01, -3.7907e-01,\n",
       "          -3.6057e-01,  4.9033e-01,  1.4460e-01, -1.0626e+00, -3.7762e-01,\n",
       "           3.6789e-02, -1.7116e-01,  2.8905e-01,  6.6862e-01,  7.9828e-01,\n",
       "           9.9332e-01,  6.1199e-01, -9.3119e-01, -7.0911e-01,  2.8337e-01,\n",
       "           5.3765e-01, -4.3349e-01, -2.2143e-02,  1.8335e-01,  1.1187e+00,\n",
       "          -2.3629e-01, -6.2144e-01, -8.6398e-01, -2.5757e-02, -6.7999e-02,\n",
       "           2.3139e-01, -1.8805e-01, -1.1191e-02, -5.4377e-01,  2.7532e-01,\n",
       "          -4.5987e-01,  1.0037e+00,  1.3702e-01, -3.2554e-01,  1.1755e+00,\n",
       "          -6.4127e-01,  1.0327e+00,  5.1161e-01,  3.4239e-01, -3.4116e-01,\n",
       "          -1.8789e+00, -1.0194e+00, -3.5178e-01,  5.6221e-01,  2.7520e-01,\n",
       "           7.8624e-01,  1.7558e+00,  1.7153e-01,  5.4094e-01, -1.3609e-01,\n",
       "           1.3254e-01,  1.5748e-01,  9.1096e-01,  2.9970e-01,  4.4327e-01,\n",
       "           1.4880e+00,  1.6665e-01, -1.0057e-01, -1.0958e+00,  1.7051e-01,\n",
       "          -1.3048e+00,  4.3442e-01,  1.0204e+00,  2.2523e-01, -9.9591e-01,\n",
       "          -3.8721e-02, -3.7749e-01, -6.3518e-01, -2.6681e-02, -3.5103e-03,\n",
       "           2.8247e-01, -1.0795e+00,  3.9213e-01,  5.4819e-01,  1.6543e+00,\n",
       "          -1.1486e+00, -2.5654e-01, -1.8728e-02,  4.8477e-01,  9.2933e-01,\n",
       "          -3.0932e-01,  3.2463e-01, -7.2596e-01,  3.9800e-01, -2.3298e-01,\n",
       "          -5.5407e-01, -6.7727e-01,  3.4179e-01, -3.4637e-01, -1.6238e-01,\n",
       "          -4.5461e-01,  1.2352e+00,  3.7181e-01,  5.8426e-01,  1.0141e+00,\n",
       "          -3.9117e-01,  5.8562e-01, -1.5717e-01, -5.3546e-01, -7.6144e-01,\n",
       "           8.5348e-01, -4.0479e-01,  1.0787e+00,  4.9696e-02, -1.0075e+00,\n",
       "           7.8838e-01, -3.9487e-01,  6.4553e-01,  6.6558e-01,  6.5797e-01,\n",
       "          -2.3583e-01,  3.2641e-03,  6.3311e-01, -8.2699e-01, -8.2045e-01,\n",
       "          -2.9397e-01, -4.6815e-01, -2.9565e-01,  8.4772e-01,  1.6747e-01,\n",
       "          -6.4905e-02, -3.3783e-01,  1.3916e-01, -1.2926e+00, -5.0274e-01,\n",
       "           2.3325e-01, -3.1618e-01,  6.5674e-01,  1.0959e-02, -1.7413e+00,\n",
       "          -4.5001e-01,  4.1559e-01,  7.9609e-01, -2.3990e-02, -3.9282e-01,\n",
       "          -8.8744e-01,  2.4043e+01, -3.7464e-02,  3.4544e-01,  2.8297e-02,\n",
       "           9.6864e-02,  9.6181e-01, -1.5648e-01,  4.3982e-01, -1.2489e+00,\n",
       "          -3.6426e-01,  3.6392e-01,  3.9323e-01,  3.0068e-01, -2.7934e-01,\n",
       "           6.9816e-01, -5.5011e-01, -6.7213e-01, -1.0161e+00,  2.1665e-01,\n",
       "          -4.4642e-01,  5.3385e-01, -1.7936e-01, -5.4401e-01,  5.3505e-01,\n",
       "          -4.1754e-01,  1.3324e-01, -7.1902e-01, -3.4278e-01, -2.4606e-01,\n",
       "          -3.7635e-01,  9.1809e-01,  1.5178e-01, -1.0193e+00,  1.0321e-01,\n",
       "          -1.2957e-01, -9.6510e-01,  2.8265e-01,  3.3285e-01,  3.5410e-01,\n",
       "           5.5350e-01, -1.7001e-01, -1.7567e-01],\n",
       "         [-8.1924e-01,  8.5970e-02, -5.8833e-01,  8.4591e-01,  3.1792e-01,\n",
       "           9.6943e-01, -1.4449e+00,  1.1290e-01,  7.5932e-01,  1.5107e-01,\n",
       "          -1.3900e+00, -7.3018e-01,  3.8566e-01, -1.0090e+00, -1.3355e-01,\n",
       "          -3.0957e-01, -2.6521e-01,  4.7621e-01, -4.7140e-01,  1.6191e+00,\n",
       "           2.6003e-01, -5.4391e-01, -1.1913e+00, -9.8788e-01,  1.8592e-01,\n",
       "           9.5952e-01, -4.5636e-01, -7.3920e-02, -2.5555e-02,  2.9181e-01,\n",
       "          -6.2595e-01, -6.1201e-01, -3.7857e-01, -8.1461e-02,  1.1691e+00,\n",
       "           1.9058e-01,  3.4068e-01, -1.5139e-01, -1.7055e-01,  3.7667e-01,\n",
       "          -1.9615e-01,  3.5167e-01,  4.3345e-01, -7.1054e-01, -3.4084e-01,\n",
       "          -1.3242e+00, -4.0380e-02,  5.3015e-01, -7.6579e-01,  6.3681e-01,\n",
       "           2.4784e-01, -5.1054e-01,  2.5526e-01, -1.3709e-01, -8.6154e-01,\n",
       "          -8.6364e-02, -1.4438e+00,  8.6487e-01, -7.8308e-02, -1.4664e-01,\n",
       "           4.1216e-01,  2.1902e-01,  4.9819e-01, -6.3723e-01,  1.5746e-01,\n",
       "           4.8354e-01, -1.2734e+00,  4.3098e-01, -5.4925e-01,  1.2793e+00,\n",
       "           4.4269e-01, -1.4444e+00, -4.0698e-01, -3.1415e-01,  9.8472e-01,\n",
       "          -1.0191e+00, -2.6810e-01,  6.3201e-02,  1.2355e+00, -7.0528e-01,\n",
       "           7.1483e-02,  1.4359e+00, -1.6821e-02,  1.0847e+00,  5.4215e-01,\n",
       "           1.2912e+00, -5.3642e-01,  1.0350e+00,  5.9982e-04, -1.0448e+00,\n",
       "          -2.7575e-01,  1.2805e-01,  1.8536e-01,  8.5124e-01,  4.6419e-01,\n",
       "           1.9353e-01,  2.4751e-01,  1.9866e-01,  5.7803e-02, -4.7070e-01,\n",
       "           3.9421e-02, -1.2543e+00, -8.9291e-01,  1.3240e+00, -1.1355e+00,\n",
       "           5.9982e-01,  5.0999e-01,  3.3912e-01,  4.4065e-01,  5.0621e-02,\n",
       "           7.0126e-01, -1.6541e+00, -3.9115e-01,  5.7781e-01, -9.8407e-02,\n",
       "          -6.9260e-02, -6.2868e-01, -1.9634e-01,  1.5532e-01,  1.3848e-02,\n",
       "          -7.6820e-01, -3.1026e-01, -3.0097e-01, -4.4548e-01,  1.6510e-01,\n",
       "           3.0431e-02,  1.2122e-01, -1.1285e-01, -6.0850e-01,  9.2992e-01,\n",
       "           6.3544e-01, -5.5342e-02,  8.8357e-01, -8.5320e-01,  1.0006e+00,\n",
       "           1.3307e+00,  1.6226e-01,  4.7330e-01, -1.2222e+00,  9.1078e-01,\n",
       "          -1.2993e+00, -5.1462e-01, -1.2649e-01, -7.4494e-01, -4.6837e-01,\n",
       "           4.9741e-02, -5.0427e-01,  2.2825e-01,  5.4449e-01, -3.0782e-01,\n",
       "          -2.4380e-01, -9.7831e-01,  3.3503e-01,  1.9442e-01,  4.6295e-02,\n",
       "          -1.1095e+00,  5.0543e-01,  2.7092e-01, -8.4697e-01, -2.2167e-01,\n",
       "          -8.5392e-01,  3.6726e-01,  5.7898e-01, -1.1546e+00, -3.9026e-01,\n",
       "           7.7406e-01,  1.6788e-02, -1.2917e-01,  6.1895e-01, -1.7723e-01,\n",
       "          -5.7947e-01,  5.3685e-01,  1.5159e-01,  4.7494e-01,  1.0305e+00,\n",
       "           8.7822e-01,  9.9907e-01,  4.1769e-01, -2.3315e-01,  1.1483e+00,\n",
       "          -2.7555e-02,  2.7404e-01,  1.3945e+00,  1.9392e-01, -5.0779e-01,\n",
       "           1.3295e+00, -1.2482e-01, -9.5248e-01,  4.6472e-01, -1.4898e+00,\n",
       "          -6.0348e-01, -4.7488e-01,  9.0484e-01,  9.5701e-01,  2.6500e-02,\n",
       "           1.2123e+00, -7.2591e-01, -2.8627e-01,  1.1412e+00,  3.4512e-01,\n",
       "          -1.3186e-01,  2.6664e-01, -4.2005e-01,  2.0521e-01,  2.0704e-01,\n",
       "          -3.5782e-01, -1.0183e+01,  4.7167e-01,  2.2732e-01,  1.1041e-01,\n",
       "           1.8743e-01, -7.0390e-01, -4.8594e-01,  2.7669e-01,  5.8029e-01,\n",
       "           4.7488e-01, -2.4552e-01, -2.9746e-01,  5.3808e-02, -8.6636e-01,\n",
       "          -3.7792e-01,  4.1067e-01,  1.9108e-01, -5.4350e-01, -7.2007e-01,\n",
       "          -1.8142e-01,  1.8499e-01, -2.8810e-01,  1.5786e+00,  1.1274e-02,\n",
       "          -9.2687e-01, -1.2854e-01,  5.5115e-01,  7.4000e-03, -6.0908e-01,\n",
       "           3.1343e-01,  1.0623e+00,  3.7238e-01,  9.7324e-01,  2.8569e-01,\n",
       "          -7.4723e-01,  1.4036e+00,  2.5322e-01,  6.9976e-01, -3.8620e-01,\n",
       "           1.5910e-01,  1.0246e+00,  6.9984e-01,  5.2014e-02,  1.8494e-01,\n",
       "          -1.7318e+00, -3.0319e-01,  3.3235e-01,  1.0918e+00, -2.4078e-01,\n",
       "           2.0067e-02, -5.1319e-02,  9.7997e-01,  3.0761e-01,  3.1905e-02,\n",
       "          -8.5657e-02,  1.0253e-01, -8.1902e-01,  9.0742e-02,  3.5632e-01,\n",
       "          -2.3867e-01, -7.9932e-01, -8.2374e-01, -2.9855e-01, -6.1309e-01,\n",
       "          -1.0240e+00, -2.8150e-01, -4.8628e-01, -2.1143e-01,  2.0213e-01,\n",
       "          -6.3440e-01,  8.1843e-01,  2.3184e-01,  1.4158e+00,  7.5535e-01,\n",
       "          -3.9191e-01,  4.5401e-01,  1.3843e-01,  4.1796e-02,  1.3811e-01,\n",
       "           1.3233e-01,  8.9911e-01, -1.1104e+00, -2.6961e-01, -1.1160e+00,\n",
       "           3.5011e-02, -1.0786e-02,  2.6952e-01,  7.3080e-01, -1.1971e-01,\n",
       "           5.8449e-01, -6.4694e-02, -2.8325e-01, -3.6406e-03, -3.9310e-01,\n",
       "          -4.1356e-01,  4.2900e-01, -5.9109e-01,  1.0594e+00, -4.6204e-01,\n",
       "           3.0280e-01, -3.7027e-01,  7.7809e-01, -3.5625e-01,  1.5339e-01,\n",
       "           6.3495e-02, -1.1091e-01,  3.0655e-01, -5.0043e-01,  1.6587e-01,\n",
       "           4.3555e-01, -1.0273e-01,  3.8119e-01,  3.6069e-01,  2.9990e-01,\n",
       "           7.0000e-01, -1.8474e-01,  4.6469e-01,  1.9790e-01,  5.5667e-02,\n",
       "           5.6977e-01, -4.0149e-01, -1.3825e+00,  7.5392e-01,  1.4942e+00,\n",
       "          -1.9318e-02,  2.8831e-01, -7.0756e-01,  4.4086e-01, -3.3694e-02,\n",
       "          -1.0265e-01,  2.6257e+00, -2.6097e-02, -1.5224e-01,  5.9278e-01,\n",
       "           2.9264e-01,  2.5830e-01,  4.7280e-01,  9.3329e-01, -1.6361e+00,\n",
       "           4.2102e-01, -7.4733e-02, -9.7082e-01, -5.6199e-01,  5.4566e-01,\n",
       "          -2.8868e-01, -6.4768e-01,  9.8743e-01,  7.4109e-01, -2.6937e-01,\n",
       "           1.9142e+00, -8.0516e-01, -2.9243e-01, -3.9526e-02,  1.1829e+00,\n",
       "           2.0154e-01, -1.1094e-01,  9.0513e-01, -9.4975e-01, -4.8203e-01,\n",
       "           5.2421e-01,  2.0678e-01, -3.4559e-01, -1.0269e-01, -3.3979e-01,\n",
       "           2.3794e-01,  5.5587e-01, -7.6192e-01,  4.1050e-01,  9.9441e-01,\n",
       "          -5.8535e-02,  1.5135e+00,  2.0337e-01,  7.9291e-01, -8.8261e-02,\n",
       "           7.9716e-01, -1.1166e+00, -9.4029e-01,  2.2044e-01,  7.8217e-02,\n",
       "          -1.9388e-01,  1.0197e+00,  8.4750e-02,  1.3487e-01,  1.9977e-01,\n",
       "          -1.0130e+00, -1.0946e+00,  4.5755e-01,  2.4133e-01,  1.3863e+00,\n",
       "           7.9271e-01, -1.7899e-01,  4.3850e-01,  2.2563e-01, -7.1488e-02,\n",
       "           7.5898e-01, -2.9057e-01,  4.5735e-01, -4.0301e-01, -4.5797e-01,\n",
       "          -1.5585e-01, -1.7666e-02,  9.9547e-01,  5.7756e-01, -9.3708e-01,\n",
       "           6.2246e-01, -1.0334e+00, -3.9237e-02, -1.5871e+00,  2.4356e-01,\n",
       "           4.1165e-02, -1.3889e-01, -1.0910e+00,  6.2925e-01,  8.3253e-02,\n",
       "          -5.0679e-01,  9.2503e-02, -4.1312e-01,  4.9545e-01, -5.5164e-01,\n",
       "           9.3856e-01,  1.2526e-02, -2.7484e-01, -1.1736e+00,  1.4884e-01,\n",
       "          -4.9011e-01,  1.2863e+00, -3.6731e-01,  5.9694e-01,  2.9232e-01,\n",
       "           8.3990e-01, -5.1628e-01,  9.5672e-02, -9.6024e-01,  4.6131e-01,\n",
       "          -6.1518e-01, -2.7331e-02, -4.7473e-01,  8.0115e-01, -3.5879e-01,\n",
       "          -1.8781e-01, -1.0575e+00,  1.1655e+00,  9.8771e-01,  7.2299e-02,\n",
       "          -3.8800e-01, -1.3567e+00,  1.7099e-01,  3.2631e-01,  6.4139e-01,\n",
       "           7.0247e-01,  7.1052e-01,  1.3963e+00, -1.6827e-01,  4.3338e-01,\n",
       "           4.0079e-01,  1.7179e-01,  7.7807e-01,  5.2281e-01,  3.7555e-01,\n",
       "          -2.8483e-01,  1.3418e-01, -4.6856e-01,  6.9360e-02, -2.4600e-01,\n",
       "           2.8786e-02, -8.4211e-01, -1.7308e-01,  7.3449e-01, -1.2318e+00,\n",
       "          -1.5700e+00, -2.4557e-01,  1.5026e-01,  8.8454e-02,  3.0024e-01,\n",
       "          -4.6146e-01,  5.4561e-01, -3.8837e-01, -3.4254e-01,  1.3016e+00,\n",
       "           1.8060e+00, -3.4197e-01, -2.5739e-01,  2.2069e-01, -3.1510e-01,\n",
       "          -3.2139e-01, -9.6190e-01, -1.1665e+00, -1.0733e+00,  3.2234e-01,\n",
       "           2.1241e-01,  3.3430e-01, -5.7508e-01, -9.3918e-01,  2.4969e-01,\n",
       "           8.9057e-01,  3.7535e-01, -4.8499e-01,  2.6091e-02,  2.0997e-02,\n",
       "           3.9049e-02,  6.8920e-03,  5.9980e-02,  2.4760e-02,  2.7246e-01,\n",
       "           1.3239e-01,  1.4905e-02, -1.9684e-01, -3.4635e-01,  1.1684e+00,\n",
       "          -1.8196e-02, -2.7121e-01,  1.9047e-01, -8.0358e-01, -7.9136e-01,\n",
       "           5.1112e-02, -2.1257e-01,  3.1132e-01, -9.5047e-02,  6.9779e-02,\n",
       "           9.2133e-01, -9.3202e-01,  1.9138e-01, -8.3289e-02,  6.9000e-01,\n",
       "           1.5302e-01,  3.2293e-01, -1.2471e+00,  9.5367e-01, -5.7436e-01,\n",
       "          -5.4478e-01,  5.0342e-01, -2.0586e+00, -7.5791e-02, -2.5683e-01,\n",
       "           1.1095e+00, -1.1201e-01,  2.2302e-01, -5.5358e-02, -1.2612e-01,\n",
       "          -8.6372e-01, -2.2717e-01, -7.2952e-01,  1.2480e-01,  2.3992e-01,\n",
       "           3.4500e-01, -4.3561e-01,  7.3815e-02, -9.1767e-01,  5.7567e-01,\n",
       "          -1.5800e-01,  6.6914e-03,  2.1690e-02,  2.0488e-01,  1.8663e-01,\n",
       "           4.9746e-01, -6.4566e-01,  3.3557e-02,  7.0871e-01,  6.4930e-01,\n",
       "           7.1744e-01,  4.5476e-02,  1.1486e-01, -5.8340e-01, -2.1788e+00,\n",
       "           1.6283e+00, -4.0833e-01, -1.0614e+00, -7.2494e-01, -2.6689e-01,\n",
       "          -7.1222e-01, -7.5657e-01, -2.9510e-01,  2.0072e-01, -4.5018e-01,\n",
       "           1.0306e-01, -5.4774e-01,  6.8943e-01, -1.4825e-01,  7.2660e-01,\n",
       "           3.2723e-01, -1.2660e-01,  1.5751e-01,  7.5058e-01, -4.8936e-03,\n",
       "           2.2479e-02,  1.3438e+00,  3.7947e-01, -1.8981e-01, -6.6622e-01,\n",
       "          -1.0641e+00, -7.8442e-01,  5.2385e-01, -1.2197e-01,  6.7347e-01,\n",
       "           6.7749e-01, -5.8396e-01, -6.3152e-01,  1.6808e-01,  1.6641e-01,\n",
       "           5.7173e-01, -8.2745e-01, -5.5797e-01, -1.7162e-01,  6.2706e-01,\n",
       "           4.0257e-01, -5.3844e-01, -1.9858e-01, -1.4472e-01, -5.8712e-01,\n",
       "           5.7739e-01,  5.0063e-02,  4.7218e-01, -2.5022e-01,  1.0447e+00,\n",
       "          -6.7461e-01,  3.0354e+00,  5.1931e-01,  4.5728e-01,  2.2698e-01,\n",
       "           5.2750e-01,  9.6343e-01, -5.4945e-01,  4.0171e-01, -7.1814e-01,\n",
       "          -1.5828e+00, -1.7804e+00, -6.2888e-01,  8.3520e-01, -2.1996e-01,\n",
       "           3.6687e-01,  1.7860e+00, -5.1469e-01,  4.7066e-01, -1.3708e-01,\n",
       "          -9.3578e-02,  4.2085e-02,  2.3545e+00, -9.5020e-02, -4.8720e-01,\n",
       "          -3.6542e-01, -4.5021e-01, -1.7424e-01, -7.2199e-01,  1.3185e-01,\n",
       "          -7.6063e-01,  7.6431e-01,  2.7410e-01,  7.4993e-01, -2.7306e-01,\n",
       "          -7.8693e-01, -6.8266e-01, -4.5369e-01, -8.5097e-01,  9.0251e-02,\n",
       "           2.5493e-01, -4.9104e-01,  1.8539e-01,  6.5354e-01,  6.7909e-01,\n",
       "          -1.3135e+00, -3.4232e-01,  4.6769e-01,  2.8054e-01,  4.4106e-01,\n",
       "           2.6077e-01, -1.6995e-02, -4.9927e-01,  9.3027e-01,  4.1672e-01,\n",
       "          -1.9536e-01, -1.5491e-01, -2.6905e-01, -5.7703e-01, -3.4102e-01,\n",
       "          -1.0635e-01,  7.6707e-01, -2.6251e-01, -8.9424e-02,  1.3810e+00,\n",
       "          -2.5458e-01,  6.8795e-01, -8.8747e-01, -5.2770e-01,  2.5982e-01,\n",
       "           5.4880e-01,  5.1916e-01,  1.7968e-01,  6.7158e-01, -1.6989e+00,\n",
       "           1.1809e-01,  3.0827e-01,  1.1500e+00,  1.0075e-01,  1.3283e+00,\n",
       "           2.6181e+00, -1.3816e-01, -2.8837e-01, -8.3662e-01, -6.0736e-01,\n",
       "          -3.8930e-01, -1.0824e-02,  1.1175e-01,  2.9151e-01,  6.5698e-01,\n",
       "          -9.5452e-02, -8.5267e-01, -3.3342e-01, -7.2279e-01, -6.5387e-02,\n",
       "           7.7275e-01, -8.3129e-01,  1.3498e+00,  6.6091e-01, -1.2336e+00,\n",
       "           4.9136e-01,  6.3803e-01,  5.1819e-01,  2.1587e-01,  6.5280e-01,\n",
       "          -1.0599e+00,  1.9867e+01,  5.6609e-02,  6.9022e-02, -8.1327e-01,\n",
       "          -3.6641e-01,  1.3425e+00,  2.1286e-01,  1.1809e+00, -1.3820e+00,\n",
       "          -3.8999e-01, -1.1421e+00,  8.7639e-01,  8.3076e-01, -1.1736e-01,\n",
       "          -4.6304e-01, -6.0871e-01, -7.5656e-01, -1.3053e+00,  2.4585e-01,\n",
       "           6.6211e-01,  5.2504e-01, -5.1445e-01, -1.3552e-01,  1.2458e-01,\n",
       "          -5.7249e-03, -2.2986e-01, -3.3300e-01,  4.8213e-02, -3.2363e-01,\n",
       "          -4.1143e-01,  2.4101e-01,  1.1243e-02, -1.0728e+00,  3.7289e-01,\n",
       "          -1.6453e-01, -5.0981e-01,  1.0096e+00,  9.1008e-01,  2.7104e-01,\n",
       "           6.7066e-01, -5.0094e-01, -1.9858e-01],\n",
       "         [-9.2293e-01,  1.5515e-01, -1.6094e-01, -2.2576e-01,  7.3701e-01,\n",
       "           1.3013e+00, -1.2295e-01,  1.0608e-01,  7.4747e-01,  9.7614e-01,\n",
       "          -3.9175e-02, -1.0049e+00,  3.4298e-01, -4.2822e-01,  3.5820e-02,\n",
       "           1.0476e-02, -2.6675e-01, -4.6081e-01, -4.3182e-01,  9.6898e-01,\n",
       "           5.1236e-01,  8.4535e-01, -2.3343e-01,  9.5843e-01,  1.9280e-01,\n",
       "           8.3009e-01, -6.9941e-01,  1.6199e-01,  4.9630e-01, -1.5716e-01,\n",
       "           5.5172e-03, -8.4759e-02, -6.8149e-01,  7.8824e-01,  4.7269e-01,\n",
       "          -1.0044e-01,  2.5183e-01, -9.6101e-02,  1.4648e+00, -5.4331e-02,\n",
       "          -1.2686e+00, -1.3557e-01,  1.6772e-01, -4.9192e-01,  2.3563e-01,\n",
       "          -5.5779e-02,  6.5060e-02,  3.2846e-01, -7.7241e-01,  1.3593e+00,\n",
       "          -7.8975e-02, -9.8686e-01,  1.4456e-01, -3.4596e-01, -1.3881e+00,\n",
       "           8.0394e-02, -6.3215e-01, -2.2742e-01,  8.6402e-01, -2.8201e-01,\n",
       "           4.5819e-01,  3.0878e-01, -2.7280e-01,  3.8538e-01, -6.9831e-01,\n",
       "           3.7168e-01, -3.9416e-01,  1.3519e-01, -1.0532e-01,  1.0535e+00,\n",
       "           3.5653e-01, -8.9971e-01,  5.7795e-01, -7.9052e-01,  5.3349e-01,\n",
       "          -1.8012e-01, -3.5389e-01, -2.6248e-02, -3.8908e-02, -7.3405e-01,\n",
       "           6.0166e-01,  7.2051e-01,  5.2213e-01,  1.6480e+00,  4.8491e-01,\n",
       "           9.0368e-01,  2.5268e-01,  9.3860e-01, -3.4310e-01, -5.9152e-01,\n",
       "           1.1355e-01,  1.7882e-01,  5.8204e-01,  9.8224e-02,  8.1396e-01,\n",
       "           6.3344e-01, -5.0292e-01,  5.8375e-01,  2.2422e-01, -4.8732e-01,\n",
       "          -4.1254e-01, -6.6582e-01, -7.5414e-01,  1.9102e-01, -1.9163e+00,\n",
       "           3.3277e-01, -1.5150e-01,  7.5052e-02, -3.5261e-01,  8.4067e-01,\n",
       "           4.1218e-01, -4.0351e-01, -6.6677e-01,  3.9599e-01, -3.3686e-01,\n",
       "          -7.0847e-02, -4.7703e-01, -4.7293e-01, -5.0703e-01, -5.3066e-01,\n",
       "          -8.0163e-02, -3.7473e-02, -2.4885e-01, -8.8340e-01, -6.4794e-01,\n",
       "          -1.3780e+00,  7.0275e-01,  5.6200e-02, -6.1113e-01,  1.3903e+00,\n",
       "           2.7013e-01,  8.2836e-01,  1.4857e-01, -3.7509e-01,  3.8194e-01,\n",
       "           1.5642e+00,  1.2461e-03, -6.5376e-01, -4.7153e-01,  2.0232e-02,\n",
       "          -3.0884e-01, -3.3963e-01,  6.3393e-01, -9.9484e-02,  3.1858e-01,\n",
       "           1.7120e-01, -7.5561e-01, -2.7651e-01, -3.7316e-01, -3.2437e-02,\n",
       "           6.2175e-01, -1.3446e+00,  8.1837e-01,  6.4893e-01, -2.4749e-02,\n",
       "           5.2576e-01,  2.0548e-01,  1.3689e-01, -3.9268e-01, -8.2690e-01,\n",
       "          -5.4898e-01, -7.4736e-01, -1.5648e-01, -2.4341e-01, -1.2839e-01,\n",
       "           1.0752e+00, -1.0083e+00,  6.4270e-01,  3.0551e-01, -3.5446e-01,\n",
       "          -1.3073e+00, -5.6576e-01,  6.6445e-01, -1.0176e-01,  9.1649e-01,\n",
       "           8.1427e-01,  1.8918e+00,  4.2660e-01,  4.1539e-01,  4.7858e-01,\n",
       "           2.3403e-01, -9.3626e-01,  4.4882e-01,  9.1502e-02, -9.8664e-01,\n",
       "           4.6096e-01,  4.8565e-01, -5.9254e-01,  5.5110e-01,  7.2580e-01,\n",
       "           6.6358e-02, -1.1827e+00,  9.3124e-02,  2.5662e-02,  3.6384e-01,\n",
       "           1.2562e+00,  5.4490e-01, -7.6299e-02,  1.1442e+00, -7.6556e-03,\n",
       "           3.5420e-01, -5.0027e-01, -4.4257e-01, -1.2143e-01,  5.9726e-01,\n",
       "           5.1264e-01, -8.8951e+00,  5.7848e-01, -4.0024e-01,  2.1952e-02,\n",
       "           7.3946e-01,  3.9725e-01,  5.5015e-01,  1.9651e-01, -2.0161e-01,\n",
       "           4.2748e-01, -5.9585e-01, -1.3615e-02,  1.1738e+00, -7.8105e-01,\n",
       "           6.0615e-01,  5.2863e-02,  1.0932e-01,  5.0164e-01, -8.5652e-01,\n",
       "          -5.7616e-01,  6.3161e-01, -1.9052e-01,  5.3404e-01, -4.6334e-01,\n",
       "           4.6742e-02, -5.7755e-01,  5.0745e-01, -1.4860e-01,  1.3554e+00,\n",
       "          -6.9347e-02,  7.8699e-01,  8.5950e-01, -1.0620e-02,  2.4946e-01,\n",
       "          -1.4966e+00,  5.1507e-01,  3.8771e-01, -5.0443e-01, -6.8441e-01,\n",
       "           2.1353e-01,  1.5346e+00,  4.7941e-01,  4.9347e-01, -4.2649e-01,\n",
       "          -1.9946e+00,  3.0743e-01,  2.8191e-01,  1.1309e+00,  3.0492e-01,\n",
       "           8.5117e-01,  2.2020e-02,  4.8388e-01, -3.1969e-01, -2.1049e-01,\n",
       "          -7.7384e-02,  1.7277e-01, -9.2978e-01,  2.6928e-01, -3.5816e-01,\n",
       "          -4.7537e-01, -1.4928e+00, -1.0401e-01,  6.1657e-01, -1.3405e+00,\n",
       "          -1.1741e+00, -5.5682e-01, -5.3035e-01, -1.0144e+00, -7.8499e-01,\n",
       "          -3.4530e-01,  2.7000e-01, -2.3535e-01,  1.0469e+00,  2.5936e-01,\n",
       "           1.0115e+00,  7.6928e-01,  5.1619e-02, -1.9621e-01,  1.0908e-01,\n",
       "           5.1380e-01,  9.0235e-01, -1.5759e-01,  4.4667e-01, -7.9879e-01,\n",
       "          -8.0461e-01,  1.3311e-01,  4.3301e-01, -1.3471e-01, -3.0983e-01,\n",
       "           3.8860e-01, -3.6428e-01, -3.7802e-01, -2.4279e-01,  5.1997e-01,\n",
       "          -5.9525e-01,  1.1801e+00, -5.6178e-01, -2.1004e-01, -6.4012e-01,\n",
       "           7.9628e-01, -1.0750e-01,  4.9570e-01, -8.7678e-01, -4.5225e-01,\n",
       "          -1.5760e-01,  1.7543e-01,  1.5128e+00, -1.3465e+00, -3.3053e-02,\n",
       "          -2.2937e-01, -1.4402e-01, -1.3231e-01, -9.1180e-01, -3.5405e-01,\n",
       "           1.3885e+00,  7.8429e-01,  6.9072e-01,  2.7319e-01, -9.4615e-02,\n",
       "           1.4124e+00, -2.4767e-01, -9.6029e-01, -1.9494e-01,  1.1304e-01,\n",
       "           8.4029e-01, -4.5746e-01, -5.1395e-01,  3.0399e-01, -2.3072e-01,\n",
       "          -5.1294e-01,  3.5621e-01,  4.4264e-01, -5.4326e-01,  9.1429e-01,\n",
       "           6.5217e-01,  3.0380e-01,  4.5912e-01,  4.0293e-01, -1.2151e+00,\n",
       "           4.2730e-01,  2.9119e-01, -4.6455e-01, -6.8733e-01, -1.1955e-01,\n",
       "           1.1677e-01, -1.1048e+00,  1.1688e+00,  7.8787e-01, -3.6001e-01,\n",
       "           5.2712e-01,  2.3545e-01, -4.6437e-01, -3.7666e-03,  1.2692e+00,\n",
       "           7.6599e-02, -1.1886e+00,  2.2923e-01, -5.1186e-01, -1.4243e+00,\n",
       "           3.6684e-01,  6.1804e-01, -6.3127e-01,  7.2074e-01, -2.9562e-01,\n",
       "           2.1394e-01,  8.3107e-02, -6.6354e-01, -1.2572e-01,  4.3410e-01,\n",
       "          -8.4385e-02,  9.2947e-01, -5.0548e-02,  1.4697e+00, -1.7244e-02,\n",
       "           6.4942e-01, -1.2446e+00, -4.9540e-01,  1.3841e-01,  6.6656e-01,\n",
       "          -5.0804e-01,  4.7590e-01, -4.7052e-01,  7.2627e-01,  1.0289e+00,\n",
       "           6.0123e-01,  3.8062e-01,  4.5223e-01,  1.2480e+00, -1.7352e-01,\n",
       "          -3.9195e-01,  5.8199e-01,  8.4656e-02,  8.2822e-01, -1.0910e-01,\n",
       "           3.7849e-01,  4.4107e-01,  7.6574e-01, -6.3431e-01, -6.9095e-01,\n",
       "           5.9374e-01, -5.8409e-02,  6.6622e-01,  1.2853e+00, -5.3288e-01,\n",
       "           8.3433e-02,  1.4309e-02, -4.7276e-01, -5.3263e-01,  6.6312e-01,\n",
       "           7.6315e-01, -6.0376e-01,  2.0663e-01,  3.4568e-02,  9.3499e-01,\n",
       "          -7.5975e-01,  4.9055e-01, -2.3846e-01,  5.3702e-01,  2.4859e-01,\n",
       "           1.0403e+00, -2.2446e-01, -5.0243e-01, -5.8767e-01, -4.9504e-02,\n",
       "          -6.7096e-01,  5.2993e-01, -6.8283e-01, -5.5203e-01,  9.1192e-01,\n",
       "          -4.9243e-01, -1.0014e+00, -5.0805e-01, -9.5965e-01, -3.1772e-01,\n",
       "          -2.3110e-01,  2.5585e-01, -3.8968e-01,  9.0182e-01, -6.6484e-01,\n",
       "           1.2748e-01, -1.0564e+00,  1.0820e+00,  1.6591e+00,  3.0387e-01,\n",
       "          -2.7679e-01, -3.1965e-01, -2.9297e-01, -2.3044e-01,  3.3528e-01,\n",
       "          -5.3086e-01,  1.0761e-01,  9.9325e-01, -2.8388e-01, -2.7019e-01,\n",
       "           7.3504e-04, -1.3085e-01,  2.4375e-01,  2.4323e-01, -2.6053e-01,\n",
       "           1.6531e+00, -6.1274e-01, -1.2603e-01,  2.9000e-01, -8.4084e-01,\n",
       "           5.1754e-01, -4.9681e-01,  2.4142e-01,  2.8638e-01, -3.0242e-01,\n",
       "          -5.0326e-01, -8.6788e-01,  1.1197e+00,  4.2385e-02,  1.1012e-01,\n",
       "          -2.2715e+00,  5.7633e-01,  6.6252e-01,  8.7006e-01,  1.3108e+00,\n",
       "           1.7473e+00, -2.6852e-01, -2.7291e-01,  4.3745e-01,  3.2676e-01,\n",
       "           1.4992e-01, -4.9153e-01,  2.2810e-01, -1.0830e+00,  4.3446e-01,\n",
       "          -5.6517e-01,  4.5386e-01, -3.9679e-01, -7.5238e-01, -1.5839e-01,\n",
       "          -7.7622e-02,  5.4837e-01,  3.5597e-01,  5.8738e-01,  6.8946e-01,\n",
       "          -1.0692e+00,  1.0677e-01,  1.9449e-01, -4.4688e-02, -2.0466e-02,\n",
       "           4.1517e-01,  6.0862e-01, -3.0702e-01,  3.8016e-01,  6.7975e-01,\n",
       "           3.8952e-01, -3.6404e-01, -2.4941e-01, -4.3550e-01, -9.4373e-01,\n",
       "           6.8882e-02, -1.3979e-02, -3.2392e-02, -4.6239e-01,  2.6822e-01,\n",
       "           4.9156e-01, -6.0678e-01,  1.1175e+00,  1.3140e+00, -5.9021e-01,\n",
       "           6.3643e-01, -1.5023e-01, -1.2345e-01,  1.3568e+00, -2.9445e-02,\n",
       "          -8.8028e-01,  6.7240e-01, -5.6198e-01,  1.1294e-01,  3.9709e-01,\n",
       "          -6.4866e-01, -1.0752e+00, -7.4776e-01,  3.0965e-01, -3.1658e-01,\n",
       "           2.4095e-02,  6.6080e-01, -1.1372e+00,  9.5905e-02,  3.7880e-01,\n",
       "           4.8688e-01, -1.2094e+00,  2.9937e-01, -4.7375e-01, -1.5757e-01,\n",
       "          -1.8015e-01, -1.2271e-01,  4.6381e-01,  5.6133e-01, -1.4016e-01,\n",
       "           3.4555e-01, -5.1293e-01, -6.0581e-02,  7.4987e-01,  5.5948e-01,\n",
       "           1.5100e+00,  6.0421e-01,  8.6814e-01,  3.1989e-01, -3.5985e+00,\n",
       "           1.6053e+00,  4.0593e-01, -1.0945e+00, -2.0001e-01,  1.2258e-01,\n",
       "          -1.0471e+00, -1.5042e+00, -1.6582e-01,  4.3127e-01, -7.2758e-01,\n",
       "          -8.2401e-01, -1.3433e+00,  9.0641e-01, -5.5262e-01, -1.7981e-01,\n",
       "           2.4961e-01, -3.3473e-01,  1.5725e-01,  1.0440e-01,  9.9248e-01,\n",
       "          -5.3085e-01,  1.6412e-01,  1.7782e-01,  2.7526e-01, -7.7489e-01,\n",
       "           7.5754e-01, -9.2278e-01, -3.3316e-01, -3.0635e-01, -8.1964e-04,\n",
       "           1.6001e-02,  5.8410e-01, -6.9088e-01,  3.2784e-02,  1.3789e-01,\n",
       "          -4.7212e-02, -9.0587e-02, -2.4702e-01,  3.2451e-01,  5.7550e-01,\n",
       "           2.9966e-01,  4.3313e-01, -1.4509e+00, -9.0912e-01, -3.9347e-01,\n",
       "           6.2839e-01, -8.5866e-01,  4.0444e-01,  5.1418e-01, -1.0022e+00,\n",
       "          -1.2137e+00,  2.4722e+00,  1.0077e+00,  1.3166e-01,  8.7234e-01,\n",
       "           3.1467e-01, -8.7704e-01, -3.6236e-01, -4.0871e-01,  2.1716e-01,\n",
       "          -2.1061e+00, -2.1730e+00, -1.5199e-01,  8.3154e-02, -1.8096e-01,\n",
       "          -6.8848e-01,  4.4252e-01,  1.2544e-01,  7.4998e-01,  8.9909e-01,\n",
       "          -6.5928e-02, -1.2615e-01,  1.0521e+00,  2.1771e-01,  1.8829e-01,\n",
       "          -2.1804e-02, -3.0373e-01, -1.0936e-01, -1.6383e+00,  6.7915e-02,\n",
       "          -1.0772e+00,  3.9584e-01, -4.2099e-01, -1.0523e-02, -7.9750e-01,\n",
       "          -6.7986e-01, -2.4062e-01, -1.0593e+00, -6.0506e-01, -1.6570e-01,\n",
       "           4.8421e-01, -1.5490e+00,  3.0784e-01,  7.6951e-01,  3.2041e-01,\n",
       "          -7.2680e-01,  1.0066e+00, -2.5999e-01, -2.5424e-01,  1.8906e-01,\n",
       "           3.4966e-01,  7.4789e-01, -1.8068e-01,  1.0697e-01, -7.9143e-01,\n",
       "           3.4902e-02, -5.2208e-01, -2.5226e-01, -2.5033e-01, -8.6734e-01,\n",
       "          -7.0607e-01, -4.7860e-02,  1.3146e+00,  1.6883e-01,  5.0753e-01,\n",
       "          -1.1138e-01,  1.3110e+00, -4.6439e-01, -4.6600e-01, -5.7917e-02,\n",
       "          -6.0304e-01,  6.0831e-01,  3.6578e-02,  1.0298e+00, -1.6333e+00,\n",
       "           2.0211e-01,  6.7987e-01, -2.0392e-02, -9.8211e-01,  3.4295e-01,\n",
       "           8.4097e-01, -2.8155e-01,  4.5450e-01, -6.8064e-01, -4.5718e-01,\n",
       "          -3.5003e-01,  2.1752e-01,  5.6611e-01,  7.2883e-01,  8.8985e-01,\n",
       "          -1.8045e-01, -9.9155e-01,  4.3491e-01, -3.1189e-02,  8.7327e-02,\n",
       "           5.7669e-01, -1.1506e+00,  3.6801e-01,  4.2089e-01, -1.7129e+00,\n",
       "           4.0767e-01,  2.3915e-01,  8.0355e-01, -3.1303e-02, -5.4685e-01,\n",
       "           1.5098e-01,  2.1400e+01,  7.3718e-02, -2.9055e-01, -3.5103e-01,\n",
       "          -4.6453e-01,  8.6847e-01,  5.4194e-01,  1.2112e+00, -8.0257e-01,\n",
       "          -1.1955e+00, -1.9129e-01,  8.5260e-01,  8.2911e-01,  3.4539e-01,\n",
       "          -7.0641e-01, -7.1017e-01, -1.2320e+00, -4.5097e-01, -3.8525e-01,\n",
       "           4.0302e-01, -1.2528e-01, -1.6047e-01, -3.2473e-02,  9.2006e-01,\n",
       "           5.9522e-02, -5.4950e-01, -6.4011e-02,  1.4983e-01,  3.7073e-01,\n",
       "           3.3359e-01,  6.6748e-02,  4.9561e-01, -1.1579e+00,  1.3182e+00,\n",
       "          -1.5516e-01,  9.0459e-01,  1.4570e+00,  3.2304e-01, -1.8776e-01,\n",
       "           1.1191e+00, -5.5778e-01,  1.9273e-01],\n",
       "         [ 1.6458e-01,  5.1025e-02, -1.1613e-01, -4.1169e-02,  1.5911e-01,\n",
       "           9.6188e-02, -3.5125e-02,  4.4823e-02,  5.9389e-03,  7.3040e-03,\n",
       "           3.7727e-02,  9.3823e-02,  1.2504e-01, -9.0663e-02,  2.9970e-02,\n",
       "           5.6155e-02, -2.4263e-01,  9.2613e-02,  6.0744e-02,  6.0792e-02,\n",
       "           6.0020e-02,  1.4151e-02, -1.0941e-02, -4.9424e-02, -3.2271e-02,\n",
       "          -1.9805e-02,  1.0126e-01, -1.8830e-02, -9.1124e-02,  1.4839e-01,\n",
       "           3.2340e-02,  1.5245e-01, -1.5264e-01,  1.2892e-02,  8.4955e-02,\n",
       "           9.3843e-02,  6.3733e-02, -4.2970e-02,  3.7063e-02,  2.4122e-03,\n",
       "          -3.4345e-02,  6.8129e-03, -8.7594e-02,  1.1141e-01, -1.7772e-02,\n",
       "           8.8283e-02, -1.6461e-02,  2.8290e-01,  4.4043e-02, -1.4967e-01,\n",
       "           3.5536e-02,  1.2552e-01,  2.2299e-02, -1.2474e-02,  1.2525e-01,\n",
       "           8.8365e-02, -2.6147e-02,  1.2562e-02,  2.9198e-02, -3.5341e-02,\n",
       "          -1.8703e-02,  1.0989e-01, -8.8106e-02, -6.4322e-03, -3.7335e-02,\n",
       "          -1.2727e-01, -8.3686e-02, -3.3464e-02, -6.2694e-02,  6.5076e-02,\n",
       "          -7.4901e-02, -1.1184e-01, -3.3531e-03, -1.0453e-01,  1.0865e-01,\n",
       "          -5.6085e-02, -1.3961e-02, -6.0113e-02, -9.2701e-02,  2.1699e-02,\n",
       "           1.0699e-01,  8.6240e-02, -8.2884e-02, -1.4805e-01,  6.7204e-02,\n",
       "           1.6829e-01, -2.8064e-02,  1.0727e-02, -5.4982e-02,  1.0901e-01,\n",
       "          -6.5197e-03, -1.2416e-01, -2.2625e-02,  2.4443e-02, -1.2704e-01,\n",
       "          -1.7759e-02, -3.6663e-02,  5.1464e-02,  1.7005e-01, -1.7408e-01,\n",
       "           4.0703e-02, -1.9669e-01, -1.0288e-01,  1.0757e-01, -7.3583e-02,\n",
       "           1.7024e-01,  2.3276e-01, -1.0508e-01,  9.8241e-02,  1.3756e-02,\n",
       "           9.9977e-02,  6.2216e-02,  1.3940e-01, -8.7462e-02, -1.9064e-01,\n",
       "          -1.5086e-01, -3.5659e-03,  8.7448e-02, -5.4903e-02, -1.3787e-01,\n",
       "           1.0115e-01,  2.9307e-01, -6.7831e-02, -1.5697e-02,  3.9620e-02,\n",
       "           1.1929e-01,  1.4556e-01,  4.4870e-02,  1.8011e-01, -5.2827e-02,\n",
       "           3.9831e-02, -2.7629e-02, -5.0060e-02, -2.0089e-02, -4.4604e-02,\n",
       "           1.9876e-01, -1.2270e-02, -6.8312e-02, -1.1287e+00,  8.4178e-02,\n",
       "          -5.9446e-02,  7.6750e-02, -1.2248e-01,  1.9060e-02,  2.3919e-02,\n",
       "          -3.1362e-02,  2.1574e-03,  2.1548e-03, -2.7102e-02, -4.6638e-02,\n",
       "           3.7656e-02, -1.5846e-01, -8.6530e-02,  3.8247e-02,  2.0273e-02,\n",
       "           1.2009e-01,  1.1455e-01,  1.2054e-01,  7.2722e-02,  4.9141e-02,\n",
       "           1.7080e-02,  1.5734e-01, -1.8301e-02, -8.2682e-02,  1.0351e-01,\n",
       "           2.1721e-02,  1.3394e-01,  4.5825e-02, -6.5931e-02,  3.0164e-02,\n",
       "          -1.7194e-02,  2.7456e-02,  7.2664e-03,  6.1607e-02,  3.1552e-02,\n",
       "           1.4591e-02,  1.7607e-02, -7.2234e-02,  6.2876e-02,  9.0833e-02,\n",
       "           1.5973e-01, -1.3120e-01, -5.4996e-02, -1.3761e-01,  1.4737e-01,\n",
       "           4.5799e-02, -6.3497e-02,  1.7031e-01, -1.1361e-01,  8.0123e-02,\n",
       "          -5.6311e-02, -7.0793e-02, -3.7018e-02, -1.7496e-01, -9.7793e-02,\n",
       "           9.3899e-02,  3.8706e-02, -3.0274e-02, -6.1815e-02,  7.4960e-02,\n",
       "           8.9843e-02,  3.2946e-02, -3.5577e-02,  1.9946e-02,  2.1444e-01,\n",
       "          -1.9556e-02,  7.9318e-02,  5.0939e-03, -5.6723e-02,  4.8987e-02,\n",
       "          -1.9216e-01, -1.1613e-01, -1.0509e-01, -5.9198e-02,  4.8051e-03,\n",
       "           5.0178e-02,  2.2803e-02, -7.3042e-02, -3.6109e-02,  2.3478e-02,\n",
       "           2.7989e-02,  1.3060e-01, -1.0864e-01, -5.8702e-03, -1.0157e-01,\n",
       "           3.9163e-02, -1.0900e-01, -5.6788e-02,  1.8773e-02,  5.6714e-02,\n",
       "          -5.9742e-02,  1.7798e-01,  2.5153e-02, -1.2310e-01, -2.6081e-02,\n",
       "          -4.5801e-02,  2.1103e-02, -1.4485e-01,  1.3935e-02,  8.9885e-02,\n",
       "          -6.2526e-02,  5.3066e-02, -8.8071e-03, -1.1140e-01, -1.0503e-02,\n",
       "           1.3645e-01,  2.2274e-02, -1.1552e-02, -1.0264e-01, -1.3144e-01,\n",
       "           1.0305e-02,  3.9106e-02,  2.8157e-02, -9.4614e-02,  4.2078e-02,\n",
       "           1.3177e-02,  1.4713e-01,  5.1841e-02, -2.7208e-02, -3.7057e-02,\n",
       "           1.0908e-01,  8.3896e-02, -4.4978e-02, -2.8220e-02,  2.7770e-02,\n",
       "           6.7647e-02,  5.0373e-03, -1.0981e-01,  1.6605e-01,  3.7589e-02,\n",
       "           1.0334e-01,  6.9344e-02, -1.1565e-01, -1.9940e-02, -1.2386e-01,\n",
       "           3.3030e-02,  1.4770e-01,  1.2743e-02, -5.8724e-02,  1.0606e-01,\n",
       "          -7.8556e-02,  1.3295e-02, -4.8992e-02,  1.3261e-01, -7.9619e-02,\n",
       "          -3.3971e-03,  1.5119e-01,  1.7264e-01,  1.2424e-01, -1.9292e-02,\n",
       "          -8.4786e-02,  1.6385e-02,  4.8041e-02, -1.6285e-01,  1.0727e-01,\n",
       "           1.1851e-01, -1.5908e-01, -6.9844e-02, -2.3491e-03, -7.3024e-02,\n",
       "           4.5689e-02,  1.9037e-03, -1.0006e-01, -7.8414e-02,  7.9328e-02,\n",
       "           1.2971e-01,  3.8451e-02, -2.0996e-01, -2.1989e-01,  4.6549e-02,\n",
       "          -3.8524e-02,  3.0815e-01,  2.5555e-02, -1.7059e-02, -1.1483e-01,\n",
       "          -5.9356e-02, -8.7429e-02, -1.3375e-01, -1.9150e-01, -2.0559e-01,\n",
       "           6.1072e-03, -1.1087e-01,  5.3936e-02,  2.9715e-02, -2.3224e-02,\n",
       "          -2.4971e-02, -6.9694e-02, -3.4949e-02,  1.0589e-01, -9.4642e-02,\n",
       "          -1.2430e-01,  4.5707e-02,  5.8447e-02,  4.1788e-02, -9.4321e-02,\n",
       "          -1.1177e-01, -3.1807e-02,  4.0324e-02, -4.6635e-02, -3.0056e-02,\n",
       "          -8.9081e-02, -1.0555e-01, -2.1320e-02, -6.3564e-02, -8.1087e-02,\n",
       "           5.9815e-02, -4.4134e-02, -7.4521e-02,  7.5848e-02, -6.9265e-02,\n",
       "          -6.0364e-02, -1.3839e-01,  2.7729e-02,  7.2176e-02, -1.3306e-01,\n",
       "           9.4610e-02, -4.4801e-02,  4.7923e-02, -3.5728e-02, -1.8175e-02,\n",
       "           1.4258e-02, -4.9122e-02, -4.2573e-02,  9.6893e-02, -5.5786e-02,\n",
       "          -1.3503e-01, -1.5026e-01,  4.4749e-02,  8.9638e-02,  5.5166e-02,\n",
       "          -1.3856e-02, -4.6123e-02, -3.0831e-02, -7.0240e-02,  4.5553e-02,\n",
       "          -4.2991e-02, -1.1300e-01, -6.8973e-02, -4.4565e-02, -5.0509e-02,\n",
       "           1.5171e-01,  1.1049e-01,  2.1133e-02, -1.0329e-01, -1.4117e-01,\n",
       "           1.5226e-01,  8.8708e-02, -2.6372e-02, -1.7566e-01, -8.5903e-02,\n",
       "          -1.4443e-02,  7.3647e-02, -1.2179e-01, -7.1346e-02,  1.0615e-01,\n",
       "          -5.5540e-02,  1.6705e-01,  1.6172e-02,  9.5723e-03,  6.2288e-02,\n",
       "          -7.7518e-02,  1.1387e-03,  5.4071e-02, -4.5052e-02, -1.9743e-01,\n",
       "          -1.3993e-01, -1.5369e-01, -3.9525e-06, -8.0508e-02, -1.2153e-01,\n",
       "           7.1669e-02,  1.5172e-03,  1.2709e-01, -8.5148e-02, -7.8879e-02,\n",
       "           1.6460e-01, -8.6118e-02,  4.4291e-02,  1.0603e-01,  1.6330e-01,\n",
       "          -8.6869e-02, -2.1889e-01, -4.9678e-02, -9.0578e-02,  2.2643e-02,\n",
       "          -5.4487e-02, -7.9557e-02,  6.7021e-02, -1.4269e-02,  6.4421e-02,\n",
       "          -5.6419e-02,  1.4236e-04,  3.9647e-03, -7.6146e-02, -4.0178e-02,\n",
       "           9.0960e-02, -2.0416e-01,  3.2607e-02, -3.1575e-02,  2.5326e-01,\n",
       "           2.3939e-03,  2.2956e-01, -1.0679e-01, -1.6088e-01,  1.6846e-01,\n",
       "          -2.0359e-02, -1.3543e-01, -3.9360e-02, -3.8966e-03,  2.4750e-02,\n",
       "          -1.3550e-01, -3.6313e-02, -9.8027e-02, -5.7213e-02, -1.7462e-01,\n",
       "           1.0052e-01, -1.1225e-01,  2.5412e-02,  2.4904e-02,  1.1503e-01,\n",
       "           2.9571e-02,  8.9019e-02, -1.2225e-01,  1.6651e-01,  1.2012e-01,\n",
       "           1.8346e-01, -7.8584e-02,  4.0362e-02,  2.1881e-02,  7.4364e-02,\n",
       "          -2.2711e-01,  5.6600e-02, -8.7411e-02,  1.1401e-01,  3.3039e-02,\n",
       "          -1.5958e-02,  6.9153e-02, -8.3710e-02, -1.9460e-02,  9.7874e-03,\n",
       "          -1.7840e-01,  9.0148e-02, -1.0541e-01, -6.4477e-02, -1.2895e-01,\n",
       "           3.6644e-02,  9.5874e-03,  6.2525e-02,  1.5751e-01,  1.0570e-01,\n",
       "          -6.9001e-03,  8.8570e-02, -3.9173e-04, -7.6153e-02, -3.1564e-02,\n",
       "           3.5200e-02, -9.0113e-02,  5.3168e-02, -2.0011e-02, -6.2470e-02,\n",
       "          -1.0671e-01,  1.6728e-01, -1.1695e-02, -6.8128e-02,  1.3539e-02,\n",
       "           1.9343e-02, -5.2920e-02, -7.1392e-02,  1.0946e-01, -1.0230e-03,\n",
       "           1.6704e-01, -7.9892e-02, -1.0468e-01,  1.6878e-02, -9.5287e-02,\n",
       "          -5.0223e-02, -5.5768e-03, -1.2799e-01, -1.3190e-01,  1.0381e-01,\n",
       "           2.7186e-02, -6.6473e-02, -5.5674e-02, -4.5633e-02, -4.8221e-02,\n",
       "          -3.9066e-02, -3.2379e-02, -2.0787e-02,  1.0078e-01, -3.9757e-02,\n",
       "           5.8255e-02,  4.4269e-02,  6.0119e-02,  1.2230e-01, -1.2374e-02,\n",
       "           4.3587e-04,  1.0616e-01,  1.8803e-01, -4.6686e-02,  9.4480e-02,\n",
       "          -8.0259e-02, -1.2643e-01,  2.9889e-02, -3.2328e-02,  3.9850e-02,\n",
       "          -1.7585e-01, -8.5740e-02, -5.8488e-02, -1.0053e-01, -1.0294e-01,\n",
       "           2.5340e-02, -1.8467e-01, -4.0814e-02, -2.6476e-02,  1.2267e-01,\n",
       "           2.0628e-01, -8.8619e-02, -1.0138e-01, -7.9533e-02,  6.7439e-02,\n",
       "          -7.5036e-02,  7.2886e-02,  1.0475e-02, -8.4386e-03, -2.6726e-02,\n",
       "          -4.2840e-03,  7.0835e-02, -9.0567e-02, -2.2915e-01,  2.6584e-02,\n",
       "          -5.8459e-02,  3.0294e-02, -1.3350e-01, -1.0074e-01, -5.5452e-02,\n",
       "           1.5436e-01, -1.6117e-01,  2.8391e-02, -8.6624e-02,  4.7623e-02,\n",
       "          -1.0408e-01,  1.4886e-02, -4.1580e-02,  2.0985e-02,  5.8200e-02,\n",
       "           7.2842e-02,  4.3436e-02,  1.1806e-01,  6.2805e-02,  3.4003e-04,\n",
       "          -7.8746e-01,  4.3911e-02,  8.2148e-04, -2.6893e-01,  2.0131e-01,\n",
       "          -2.4420e-02,  7.4602e-02,  3.6580e-02,  5.2881e-02,  8.0901e-02,\n",
       "          -1.5987e-02, -1.3508e-01, -1.2631e-01,  1.0686e-01, -3.9913e-02,\n",
       "          -1.6667e-02,  2.8384e-02, -6.7027e-04, -6.1802e-02, -8.0263e-02,\n",
       "          -2.8192e-02, -1.0700e-01, -1.9126e-02, -8.0625e-02,  1.6532e-02,\n",
       "           1.2844e-01, -2.4148e-01, -7.6682e-02,  1.5323e-02, -3.7653e-02,\n",
       "          -1.0473e-01,  6.5134e-02,  1.4663e-01, -8.2393e-02,  1.3426e-01,\n",
       "           1.2283e-01, -9.2187e-02,  1.8443e-02, -1.8359e-01,  4.0323e-02,\n",
       "           6.3390e-02,  9.7702e-02,  1.9030e-01,  9.7127e-02, -8.7818e-02,\n",
       "           1.7446e-01,  2.6021e-02,  3.2699e-02,  7.3668e-02,  1.9169e-01,\n",
       "          -1.3753e-02, -2.3799e-02,  1.6043e-01, -1.0032e-01, -3.5343e-02,\n",
       "           2.3097e-02,  2.1009e-01,  8.3913e-02, -1.7966e-02,  2.6154e-02,\n",
       "           1.2997e+01, -8.4637e-02, -1.8326e-01, -2.5597e-02, -5.1118e-02,\n",
       "           8.0395e-02, -2.0436e-02,  3.0579e-02,  1.4724e-01, -7.5615e-02,\n",
       "           1.1187e-01, -1.9740e-02,  3.3897e-02,  8.3700e-02, -2.7868e-02,\n",
       "           4.5620e-02, -7.2705e-02, -1.6975e-01, -2.9456e-02, -1.4573e-01,\n",
       "           6.0947e-02, -6.5369e-02, -2.2116e-01,  7.2397e-02, -2.0581e-01,\n",
       "           5.6751e-02, -1.6682e-01, -8.8383e-02,  3.3869e-03, -1.8832e-01,\n",
       "          -1.0757e-01, -1.9298e-01, -4.1294e-02, -1.9424e-01,  7.9616e-03,\n",
       "           3.2799e-02, -1.4974e-01, -2.5731e-01, -7.9522e-02,  7.6559e-02,\n",
       "           3.0212e-02,  3.9234e-02, -9.1422e-02,  1.7908e-01,  1.3914e-01,\n",
       "           7.0415e-02,  6.6222e-02, -6.8340e-03,  1.0099e-01,  2.0568e-01,\n",
       "          -8.5522e-02, -1.0027e-01, -1.8439e-01,  1.9525e-02,  4.3081e-02,\n",
       "           3.1037e-02,  1.1213e-02,  4.1922e-02, -1.2706e-01, -1.5376e-01,\n",
       "           1.6540e-02,  5.8031e-02,  2.0028e-02,  3.4647e-02, -1.0622e-01,\n",
       "          -3.6744e-02,  1.1760e-01,  8.9019e-02, -1.7699e-02, -9.1948e-02,\n",
       "          -1.2320e-01,  3.6422e-03,  1.2375e-01, -7.6910e-02, -1.2058e-01,\n",
       "          -1.4917e-01,  1.4002e+00,  1.5818e-01,  3.5032e-02, -8.6024e-02,\n",
       "          -4.5613e-02, -4.6758e-02, -3.6502e-02, -4.3098e-02, -1.1364e-01,\n",
       "          -1.6611e-01,  1.8101e-01, -4.8345e-02, -6.4830e-02, -6.4025e-02,\n",
       "          -6.0450e-02, -7.3061e-03, -9.9233e-02,  2.2053e-01,  4.4103e-02,\n",
       "          -5.5239e-02, -2.2624e-02, -6.9264e-02, -2.4296e-02, -1.0174e-02,\n",
       "          -5.8651e-03, -4.9182e-02,  1.5562e-01, -7.4045e-02,  3.8066e-02,\n",
       "           9.0499e-03, -1.7084e-01, -1.0187e-01,  9.4314e-02, -2.3529e-02,\n",
       "          -1.6283e-01,  5.3533e-03, -7.4492e-02,  1.4091e-01, -1.6511e-01,\n",
       "           4.6864e-02,  1.7627e-01,  2.8836e-02]]], grad_fn=<AddBackward0>)"
      ]
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "inputs = t(\"I love you\", return_tensors='pt')\n",
    "res = m3(**inputs)\n",
    "res2 = m(**inputs)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "len(res2), len(res)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(2, 3)"
      ]
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "res2[1].shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([1, 768])"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "res[2].shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([1, 768])"
      ]
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "# config.reducer = 'entity'\n",
    "# config.embedding = 'deberta'\n",
    "# config.bert = 'microsoft/deberta-base'\n",
    "# config.device = 0\n",
    "config.seed = None\n",
    "manager = Manager(config)\n",
    "loaders = manager.prepare()\n",
    "X1 = list(loaders[0])\n",
    "X2 = list(loaders[1])\n",
    "x1 = X1[0]\n",
    "x2 = X2[0]"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[2021-10-14 14:03:49,589] INFO (utils.Manager) Hyper Parameters are \n",
      "{\n",
      "    \"scale\": \"demo\",\n",
      "    \"mode\": \"train\",\n",
      "    \"batch_size\": 5,\n",
      "    \"batch_size_news\": 100,\n",
      "    \"batch_size_history\": 100,\n",
      "    \"k\": 5,\n",
      "    \"threshold\": -Infinity,\n",
      "    \"abs_length\": 40,\n",
      "    \"signal_length\": 100,\n",
      "    \"his_size\": 50,\n",
      "    \"cdd_size\": 5,\n",
      "    \"impr_size\": 10,\n",
      "    \"dropout_p\": 0.2,\n",
      "    \"lr\": 0.0001,\n",
      "    \"bert_lr\": 3e-05,\n",
      "    \"embedding\": \"bert\",\n",
      "    \"encoderN\": \"cnn\",\n",
      "    \"encoderU\": \"rnn\",\n",
      "    \"selector\": \"sfi\",\n",
      "    \"reducer\": \"matching\",\n",
      "    \"ranker\": \"onepass\",\n",
      "    \"pooler\": \"attn\",\n",
      "    \"embedding_dim\": 768,\n",
      "    \"hidden_dim\": 384,\n",
      "    \"base_rank\": 0,\n",
      "    \"world_size\": 0,\n",
      "    \"seed\": null,\n",
      "    \"granularity\": \"avg\",\n",
      "    \"debias\": true,\n",
      "    \"full_attn\": true,\n",
      "    \"descend_history\": false,\n",
      "    \"shuffle_pos\": false,\n",
      "    \"save_pos\": false,\n",
      "    \"sep_his\": false,\n",
      "    \"diversify\": false,\n",
      "    \"no_dedup\": false,\n",
      "    \"no_order_embed\": false,\n",
      "    \"no_rm_punc\": false,\n",
      "    \"fast\": false,\n",
      "    \"scheduler\": \"linear\",\n",
      "    \"warmup\": 100,\n",
      "    \"shuffle\": false,\n",
      "    \"bert\": \"bert\",\n",
      "    \"tb\": false\n",
      "}\n",
      "[2021-10-14 14:03:49,590] INFO (utils.Manager) preparing dataset...\n",
      "[2021-10-14 14:03:49,591] INFO (utils.MIND) process NO.0 loading cached user behavior from data/cache/bert/MINDdemo_train/behaviors.pkl\n",
      "[2021-10-14 14:03:49,604] INFO (utils.MIND) process NO.0 loading cached news tokenization from data/cache/bert/MINDdemo_train/news.pkl\n",
      "[2021-10-14 14:03:50,401] INFO (utils.utils) deduplicating...\n",
      "[2021-10-14 14:03:51,937] INFO (utils.MIND) process NO.0 loading cached user behavior from data/cache/bert/MINDdemo_dev/10/behaviors.pkl\n",
      "[2021-10-14 14:03:51,944] INFO (utils.MIND) process NO.0 loading cached news tokenization from data/cache/bert/MINDdemo_dev/news.pkl\n",
      "[2021-10-14 14:03:52,589] INFO (utils.utils) deduplicating...\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "class TESRec(BaseModel):\n",
    "    \"\"\"\n",
    "    Tow tower model with selection\n",
    "\n",
    "    1. encode candidate news with bert\n",
    "    2. encode ps terms with the same bert, using [CLS] embedding as user representation\n",
    "    3. predict by scaled dot product\n",
    "    \"\"\"\n",
    "    def __init__(self, manager, embedding, encoderN, encoderU, reducer, aggregator=None):\n",
    "        super().__init__(manager)\n",
    "\n",
    "        self.embedding = embedding\n",
    "        self.encoderN = encoderN\n",
    "        self.encoderU = encoderU\n",
    "        self.reducer = reducer\n",
    "        self.aggregator = aggregator\n",
    "        self.bert = BERT_Encoder(manager)\n",
    "\n",
    "        self.newsUserProject = nn.Sequential(\n",
    "            nn.Linear(self.bert.hidden_dim, self.bert.hidden_dim),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "        if manager.debias:\n",
    "            self.userBias = nn.Parameter(torch.randn(1,self.bert.hidden_dim))\n",
    "            nn.init.xavier_normal_(self.userBias)\n",
    "\n",
    "        self.hidden_dim = self.bert.hidden_dim\n",
    "\n",
    "        self.granularity = manager.granularity\n",
    "        if self.granularity != 'token':\n",
    "            self.register_buffer('cdd_dest', torch.zeros((self.batch_size, self.impr_size, self.signal_length * self.signal_length)), persistent=False)\n",
    "            if manager.reducer in [\"bm25\", \"entity\", \"first\"]:\n",
    "                self.register_buffer('his_dest', torch.zeros((self.batch_size, self.his_size, (manager.k + 2) * (manager.k + 2))), persistent=False)\n",
    "            else:\n",
    "                self.register_buffer('his_dest', torch.zeros((self.batch_size, self.his_size, self.signal_length * self.signal_length)), persistent=False)\n",
    "\n",
    "\n",
    "        manager.name = '__'.join(['tesrec', manager.bert, manager.encoderN, manager.encoderU, manager.reducer, manager.granularity])\n",
    "        self.name = manager.name\n",
    "\n",
    "\n",
    "    def clickPredictor(self, cdd_news_repr, user_repr):\n",
    "        \"\"\" calculate batch of click probabolity\n",
    "\n",
    "        Args:\n",
    "            cdd_news_repr: news-level representation, [batch_size, cdd_size, hidden_dim]\n",
    "            user_repr: user representation, [batch_size, 1, hidden_dim]\n",
    "\n",
    "        Returns:\n",
    "            score of each candidate news, [batch_size, cdd_size]\n",
    "        \"\"\"\n",
    "        score = cdd_news_repr.matmul(user_repr.transpose(-2,-1)).squeeze(-1)/math.sqrt(cdd_news_repr.size(-1))\n",
    "        return score\n",
    "\n",
    "\n",
    "    def _forward(self,x):\n",
    "        # destroy encoding and embedding outside of the model\n",
    "\n",
    "        if self.granularity != 'token':\n",
    "            batch_size = x['cdd_subword_index'].size(0)\n",
    "            cdd_size = x['cdd_subword_index'].size(1)\n",
    "\n",
    "            if self.training:\n",
    "                cdd_dest = self.cdd_dest[:batch_size, :cdd_size]\n",
    "                his_dest = self.his_dest[:batch_size]\n",
    "\n",
    "            # batch_size always equals 1 when evaluating\n",
    "            else:\n",
    "                cdd_dest = self.cdd_dest[[0], :cdd_size]\n",
    "                his_dest = self.his_dest[[0]]\n",
    "\n",
    "            cdd_subword_index = x['cdd_subword_index'].to(self.device)\n",
    "            his_subword_index = x['his_subword_index'].to(self.device)\n",
    "            his_signal_length = his_subword_index.size(-2)\n",
    "            cdd_subword_index = cdd_subword_index[:, :, :, 0] * self.signal_length + cdd_subword_index[:, :, :, 1]\n",
    "            his_subword_index = his_subword_index[:, :, :, 0] * his_signal_length + his_subword_index[:, :, :, 1]\n",
    "\n",
    "            if self.training:\n",
    "                # * cdd_mask to filter out padded cdd news\n",
    "                cdd_subword_prefix = cdd_dest.scatter(dim=-1, index=cdd_subword_index, value=1) * x[\"cdd_mask\"].to(self.device)\n",
    "            else:\n",
    "                cdd_subword_prefix = cdd_dest.scatter(dim=-1, index=cdd_subword_index, value=1)\n",
    "\n",
    "            cdd_subword_prefix = cdd_subword_prefix.view(batch_size, cdd_size, self.signal_length, self.signal_length)\n",
    "            his_subword_prefix = his_dest.scatter(dim=-1, index=his_subword_index, value=1) * x[\"his_mask\"].to(self.device)\n",
    "            his_subword_prefix = his_subword_prefix.view(batch_size, self.his_size, his_signal_length, his_signal_length)\n",
    "\n",
    "            if self.granularity == 'avg':\n",
    "                # average subword embeddings as the word embedding\n",
    "                cdd_subword_prefix = F.normalize(cdd_subword_prefix, p=1, dim=-1)\n",
    "                his_subword_prefix = F.normalize(his_subword_prefix, p=1, dim=-1)\n",
    "\n",
    "            cdd_attn_mask = cdd_subword_prefix.matmul(x['cdd_attn_mask'].to(self.device).float().unsqueeze(-1)).squeeze(-1)\n",
    "            his_attn_mask = his_subword_prefix.matmul(x[\"his_attn_mask\"].to(self.device).float().unsqueeze(-1)).squeeze(-1)\n",
    "            his_refined_mask = None\n",
    "            if 'his_refined_mask' in x:\n",
    "                his_refined_mask = his_subword_prefix.matmul(x[\"his_refined_mask\"].to(self.device).float().unsqueeze(-1)).squeeze(-1)\n",
    "\n",
    "        else:\n",
    "            cdd_subword_prefix = None\n",
    "            his_subword_prefix = None\n",
    "            cdd_attn_mask = x['cdd_attn_mask'].to(self.device)\n",
    "            his_attn_mask = x[\"his_attn_mask\"].to(self.device)\n",
    "            his_refined_mask = None\n",
    "            if 'his_refined_mask' in x:\n",
    "                his_refined_mask = x[\"his_refined_mask\"].to(self.device)\n",
    "\n",
    "        cdd_news = x[\"cdd_encoded_index\"].to(self.device)\n",
    "        _, cdd_news_repr = self.bert(\n",
    "            self.embedding(cdd_news, cdd_subword_prefix), cdd_attn_mask\n",
    "        )\n",
    "        cdd_news_repr = self.newsUserProject(cdd_news_repr)\n",
    "\n",
    "        his_news = x[\"his_encoded_index\"].to(self.device)\n",
    "\n",
    "        his_news_embedding = self.embedding(his_news, his_subword_prefix)\n",
    "        his_news_encoded_embedding, his_news_repr = self.encoderN(\n",
    "            his_news_embedding, his_attn_mask\n",
    "        )\n",
    "        # no need to calculate this if ps_terms are fixed in advance\n",
    "        if self.reducer.name == 'matching':\n",
    "            user_repr = self.encoderU(his_news_repr, his_mask=x['his_mask'].to(self.device), user_index=x[\"user_id\"].to(self.device))\n",
    "        else:\n",
    "            user_repr = None\n",
    "\n",
    "        ps_terms, ps_term_mask, kid = self.reducer(his_news_encoded_embedding, his_news_embedding, user_repr, his_news_repr, his_attn_mask, his_refined_mask)\n",
    "\n",
    "        _, user_cls = self.bert(ps_terms, ps_term_mask, ps_term_input=True)\n",
    "\n",
    "        if self.aggregator is not None:\n",
    "            user_repr = self.aggregator(user_cls)\n",
    "        else:\n",
    "            user_repr = self.newsUserProject(user_cls)\n",
    "\n",
    "        if hasattr(self, 'userBias'):\n",
    "            user_repr = user_repr + self.userBias\n",
    "\n",
    "        return self.clickPredictor(cdd_news_repr, user_repr), kid\n",
    "\n",
    "\n",
    "    def forward(self,x):\n",
    "        \"\"\"\n",
    "        Decoupled function, score is unormalized click score\n",
    "        \"\"\"\n",
    "        score, kid = self._forward(x)\n",
    "\n",
    "        if self.training:\n",
    "            prob = nn.functional.log_softmax(score, dim=1)\n",
    "        else:\n",
    "            prob = torch.sigmoid(score)\n",
    "\n",
    "        return prob, kid\n",
    "\n",
    "\n",
    "    def encode_news(self, x):\n",
    "        \"\"\"\n",
    "        encode news of loader_news\n",
    "        \"\"\"\n",
    "        # encode news with MIND_news\n",
    "        if self.granularity != 'token':\n",
    "            batch_size = x['cdd_subword_index'].size(0)\n",
    "            cdd_dest = self.cdd_dest[:batch_size]\n",
    "            cdd_subword_index = x['cdd_subword_index'].to(self.device)\n",
    "            cdd_subword_index = cdd_subword_index[:, :, 0] * self.signal_length + cdd_subword_index[:, :, 1]\n",
    "\n",
    "            cdd_subword_prefix = cdd_dest.scatter(dim=-1, index=cdd_subword_index, value=1)\n",
    "            cdd_subword_prefix = cdd_subword_prefix.view(batch_size, self.signal_length, self.signal_length)\n",
    "\n",
    "            if self.granularity == 'avg':\n",
    "                # average subword embeddings as the word embedding\n",
    "                cdd_subword_prefix = F.normalize(cdd_subword_prefix, p=1, dim=-1)\n",
    "            cdd_attn_mask = cdd_subword_prefix.matmul(x['cdd_attn_mask'].to(self.device).float().unsqueeze(-1)).squeeze(-1)\n",
    "\n",
    "        else:\n",
    "            cdd_subword_prefix = None\n",
    "            cdd_attn_mask = x['cdd_attn_mask'].to(self.device)\n",
    "\n",
    "        cdd_news = x[\"cdd_encoded_index\"].to(self.device)\n",
    "        _, cdd_news_repr = self.bert(\n",
    "            self.embedding(cdd_news, cdd_subword_prefix), cdd_attn_mask\n",
    "        )\n",
    "        cdd_news_repr = self.newsUserProject(cdd_news_repr.squeeze(1))\n",
    "\n",
    "        return cdd_news_repr\n",
    "\n",
    "\n",
    "    def predict_fast(self, x):\n",
    "        \"\"\"\n",
    "        1. encode user\n",
    "        2. look up candidate representation in the embedding matrix\n",
    "        3. compute click probability\n",
    "        \"\"\"\n",
    "        if self.granularity != 'token':\n",
    "            batch_size = x['his_encoded_index'].size(0)\n",
    "            his_dest = self.his_dest[:batch_size]\n",
    "\n",
    "            his_subword_index = x['his_subword_index'].to(self.device)\n",
    "            his_signal_length = his_subword_index.size(-2)\n",
    "            his_subword_index = his_subword_index[:, :, :, 0] * his_signal_length + his_subword_index[:, :, :, 1]\n",
    "\n",
    "            his_subword_prefix = his_dest.scatter(dim=-1, index=his_subword_index, value=1) * x[\"his_mask\"].to(self.device)\n",
    "            his_subword_prefix = his_subword_prefix.view(batch_size, self.his_size, his_signal_length, his_signal_length)\n",
    "\n",
    "            if self.granularity == 'avg':\n",
    "                # average subword embeddings as the word embedding\n",
    "                his_subword_prefix = F.normalize(his_subword_prefix, p=1, dim=-1)\n",
    "\n",
    "            his_attn_mask = his_subword_prefix.matmul(x[\"his_attn_mask\"].to(self.device).float().unsqueeze(-1)).squeeze(-1)\n",
    "            his_refined_mask = None\n",
    "            if 'his_refined_mask' in x:\n",
    "                his_refined_mask = his_subword_prefix.matmul(x[\"his_refined_mask\"].to(self.device).float().unsqueeze(-1)).squeeze(-1)\n",
    "\n",
    "        else:\n",
    "            his_subword_prefix = None\n",
    "            his_attn_mask = x[\"his_attn_mask\"].to(self.device)\n",
    "            his_refined_mask = None\n",
    "            if 'his_refined_mask' in x:\n",
    "                his_refined_mask = x[\"his_refined_mask\"].to(self.device)\n",
    "\n",
    "        his_news = x[\"his_encoded_index\"].to(self.device)\n",
    "        his_news_embedding = self.embedding(his_news, his_subword_prefix)\n",
    "        his_news_encoded_embedding, his_news_repr = self.encoderN(\n",
    "            his_news_embedding, his_attn_mask\n",
    "        )\n",
    "        # no need to calculate this if ps_terms are fixed in advance\n",
    "        if self.reducer.name == 'matching':\n",
    "            user_repr = self.encoderU(his_news_repr, his_mask=x['his_mask'].to(self.device), user_index=x['user_id'].to(self.device))\n",
    "        else:\n",
    "            user_repr = None\n",
    "\n",
    "        ps_terms, ps_term_mask, _ = self.reducer(his_news_encoded_embedding, his_news_embedding, user_repr, his_news_repr, his_attn_mask, his_refined_mask)\n",
    "\n",
    "        _, user_cls = self.bert(ps_terms, ps_term_mask)\n",
    "        user_repr = self.newsUserProject(user_cls)\n",
    "        if hasattr(self, 'userBias'):\n",
    "            user_repr = user_repr + self.userBias\n",
    "\n",
    "        # [bs, cs, hd]\n",
    "        news_repr = self.news_reprs(x['cdd_id'].to(self.device))\n",
    "\n",
    "        scores = news_repr.matmul(user_repr.transpose(-1, -2)).squeeze(-1)/math.sqrt(news_repr.size(-1))\n",
    "        logits = torch.sigmoid(scores)\n",
    "        return logits\n",
    "\n",
    "def scaled_dp_attention(query, key, value, attn_mask=None, log=False):\n",
    "    \"\"\" calculate scaled attended output of values\n",
    "\n",
    "    Args:\n",
    "        query: tensor of [batch_size, *, query_num, key_dim]\n",
    "        key: tensor of [batch_size, *, key_num, key_dim]\n",
    "        value: tensor of [batch_size, *, key_num, value_dim]\n",
    "        attn_mask: tensor of [batch_size, *, query_num, key_num]\n",
    "\n",
    "    Returns:\n",
    "        attn_output: tensor of [batch_size, *, query_num, value_dim]\n",
    "    \"\"\"\n",
    "\n",
    "    # make sure dimension matches\n",
    "    assert query.shape[-1] == key.shape[-1]\n",
    "    key = key.transpose(-2, -1)\n",
    "\n",
    "    attn_score = torch.matmul(query, key)/math.sqrt(query.shape[-1])\n",
    "\n",
    "    if attn_mask is not None:\n",
    "        attn_prob = XSoftmax.apply(attn_score, attn_mask, -1)\n",
    "    else:\n",
    "        attn_prob = torch.softmax(attn_score, -1)\n",
    "    if log:\n",
    "        print(attn_score[0:2], attn_mask[0:2], attn_prob[0:2])\n",
    "\n",
    "    attn_output = torch.matmul(attn_prob, value)\n",
    "    return attn_output\n",
    "\n",
    "\n",
    "class BERT_Encoder(nn.Module):\n",
    "    \"\"\"\n",
    "        1. for news input, encode it with BERT and output news- and word-level representations\n",
    "        2. for ps_term input, insert [CLS] token at the head and insert [SEP] token at the end\n",
    "        3. add position embedding to the sequence, starting from 0 pos\n",
    "    \"\"\"\n",
    "    def __init__(self, manager):\n",
    "        super().__init__()\n",
    "\n",
    "        # dimension for the final output embedding/representation\n",
    "        self.hidden_dim = 768\n",
    "        self.signal_length = manager.signal_length\n",
    "\n",
    "        self.pooler = manager.pooler\n",
    "\n",
    "        if manager.bert == 'unilm':\n",
    "            config = TuringNLRv3Config.from_pretrained(manager.unilm_config_path)\n",
    "            config.pooler = None\n",
    "            bert = TuringNLRv3ForSequenceClassification.from_pretrained(manager.unilm_path, config=config).bert\n",
    "\n",
    "            self.rel_pos_bins = config.rel_pos_bins\n",
    "            self.max_rel_pos = config.max_rel_pos\n",
    "            # unique in UniLM\n",
    "            self.rel_pos_bias = bert.rel_pos_bias\n",
    "\n",
    "        else:\n",
    "            bert = AutoModel.from_pretrained(\n",
    "                manager.get_bert_for_load(),\n",
    "                cache_dir=manager.path + 'bert_cache/'\n",
    "            )\n",
    "\n",
    "        self.bert = bert.encoder\n",
    "\n",
    "        if manager.bert == 'deberta':\n",
    "            self.extend_attn_mask = True\n",
    "        else:\n",
    "            self.extend_attn_mask = False\n",
    "\n",
    "        word_embedding = bert.embeddings.word_embeddings\n",
    "\n",
    "        if manager.reducer != 'none':\n",
    "            self.bert_cls_embedding = nn.Parameter(word_embedding.weight[manager.get_special_token_id('[CLS]')].view(1,1,self.hidden_dim))\n",
    "            self.bert_sep_embedding = nn.Parameter(word_embedding.weight[manager.get_special_token_id('[SEP]')].view(1,1,self.hidden_dim))\n",
    "\n",
    "        self.query = nn.Parameter(torch.randn(1, self.hidden_dim))\n",
    "        nn.init.xavier_normal_(self.query)\n",
    "\n",
    "        try:\n",
    "            self.bert_pos_embedding = nn.Parameter(bert.embeddings.position_embeddings.weight)\n",
    "        except:\n",
    "            self.bert_pos_embedding = None\n",
    "\n",
    "        # try:\n",
    "        #     self.bert_token_type_embedding = nn.Parameter(bert.embeddings.token_type_embeddings.weight)\n",
    "        # except:\n",
    "        #     self.bert_token_type_embedding = None\n",
    "\n",
    "        self.register_buffer('extra_attn_mask', torch.ones(1, 1), persistent=False)\n",
    "\n",
    "    def forward(self, news_embedding, attn_mask, ps_term_input=False):\n",
    "        \"\"\" encode news with bert\n",
    "\n",
    "        Args:\n",
    "            news_embedding: [batch_size, *, signal_length, embedding_dim]\n",
    "            attn_mask: [batch_size, *, signal_length]\n",
    "\n",
    "        Returns:\n",
    "            news_encoded_embedding: hidden vector of each token in news, of size [batch_size, *, signal_length, emedding_dim]\n",
    "            news_repr: news representation, of size [batch_size, *, embedding_dim]\n",
    "        \"\"\"\n",
    "        batch_size = news_embedding.size(0)\n",
    "        signal_length = news_embedding.size(-2)\n",
    "\n",
    "        # insert [CLS] and [SEP] token\n",
    "        bert_input = news_embedding.view(-1, signal_length, self.hidden_dim)\n",
    "        bs = bert_input.size(0)\n",
    "\n",
    "        attn_mask = attn_mask.view(-1, signal_length)\n",
    "\n",
    "        # concatenated ps_terms\n",
    "        if ps_term_input:\n",
    "            # add [CLS] and [SEP] to ps_terms\n",
    "            bert_input = torch.cat([self.bert_cls_embedding.expand(bs, 1, self.hidden_dim), bert_input, self.bert_sep_embedding.expand(bs, 1, self.hidden_dim)], dim=-2)\n",
    "            attn_mask = torch.cat([self.extra_attn_mask.expand(bs, 1), attn_mask, self.extra_attn_mask.expand(bs, 1)], dim=-1)\n",
    "            signal_length += 2\n",
    "\n",
    "        #     if self.bert_token_type_embedding is not None:\n",
    "        #         bert_input += self.bert_token_type_embedding[1]\n",
    "\n",
    "        # else:\n",
    "        #     if self.bert_token_type_embedding is not None:\n",
    "        #         bert_input += self.bert_token_type_embedding[0]\n",
    "\n",
    "        if self.bert_pos_embedding is not None:\n",
    "            bert_input += self.bert_pos_embedding[:bert_input.size(-2)]\n",
    "\n",
    "        if self.extend_attn_mask:\n",
    "            ext_attn_mask = attn_mask\n",
    "        else:\n",
    "            ext_attn_mask = (1.0 - attn_mask) * -10000.0\n",
    "            ext_attn_mask = attn_mask.view(bs, 1, 1, -1)\n",
    "\n",
    "        if hasattr(self, 'rel_pos_bias'):\n",
    "            position_ids = torch.arange(signal_length, dtype=torch.long, device=bert_input.device).unsqueeze(0).expand(bs, signal_length)\n",
    "            rel_pos_mat = position_ids.unsqueeze(-2) - position_ids.unsqueeze(-1)\n",
    "            rel_pos = relative_position_bucket(rel_pos_mat, num_buckets=self.rel_pos_bins, max_distance=self.max_rel_pos)\n",
    "            rel_pos = F.one_hot(rel_pos, num_classes=self.rel_pos_bins).float()\n",
    "            rel_pos = self.rel_pos_bias(rel_pos).permute(0, 3, 1, 2)\n",
    "            bert_output = self.bert(bert_input, attention_mask=ext_attn_mask, rel_pos=rel_pos)[0]\n",
    "\n",
    "        else:\n",
    "            # [bs, sl/term_num+2, hd]\n",
    "            bert_output = self.bert(bert_input, attention_mask=ext_attn_mask).last_hidden_state\n",
    "\n",
    "        if self.pooler == \"cls\":\n",
    "            news_repr = bert_output[:, 0].reshape(batch_size, -1, self.hidden_dim)\n",
    "        elif self.pooler == \"attn\":\n",
    "            news_repr = scaled_dp_attention(self.query, bert_output, bert_output, attn_mask=attn_mask.unsqueeze(1), log=ps_term_input).view(batch_size, -1, self.hidden_dim)\n",
    "        elif self.pooler == \"avg\":\n",
    "            news_repr = bert_output.mean(dim=-2).reshape(batch_size, -1, self.hidden_dim)\n",
    "\n",
    "        news_encoded_embedding = bert_output.view(batch_size, -1, bert_input.size(-2), self.hidden_dim)\n",
    "\n",
    "        return news_encoded_embedding, news_repr"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "embedding = BERT_Embedding(manager)\n",
    "\n",
    "encoderN = CNN_Encoder(manager)\n",
    "# encoderN = RNN_Encoder(manager)\n",
    "# encoderN = MHA_Encoder(manager)\n",
    "\n",
    "# encoderU = CNN_User_Encoder(manager)\n",
    "encoderU = RNN_User_Encoder(manager)\n",
    "# encoderU = MHA_User_Encoder(manager)\n",
    "# encoderU = Attention_Pooling(manager)\n",
    "# encoderU = Average_Pooling(manager)\n",
    "\n",
    "reducer = Matching_Reducer(manager)\n",
    "# reducer = Identical_Reducer(manager)\n",
    "\n",
    "# ranker = CNN_Ranker(manager)\n",
    "# ranker = BERT_Onepass_Ranker(manager)\n",
    "# ranker = BERT_Original_Ranker(manager)\n",
    "\n",
    "model = TESRec(manager, embedding, encoderN, encoderU, reducer).to(manager.device)\n",
    "# model = ESM(manager, embedding, encoderN, encoderU, reducer, ranker).to(manager.device)\n",
    "\n",
    "# manager.load(model, 589, strict=False)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "model(x1)"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "TypeError",
     "evalue": "view() got an unexpected keyword argument 'log'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_293633/3513459255.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/data/workspace/Peitian/nn/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_293633/461502903.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    144\u001b[0m         \u001b[0mDecoupled\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0munormalized\u001b[0m \u001b[0mclick\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m         \"\"\"\n\u001b[0;32m--> 146\u001b[0;31m         \u001b[0mscore\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_293633/461502903.py\u001b[0m in \u001b[0;36m_forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m         \u001b[0mcdd_news\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"cdd_encoded_index\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m         _, cdd_news_repr = self.bert(\n\u001b[0m\u001b[1;32m    111\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcdd_news\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcdd_subword_prefix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcdd_attn_mask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m         )\n",
      "\u001b[0;32m/data/workspace/Peitian/nn/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_293633/461502903.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, news_embedding, attn_mask, ps_term_input)\u001b[0m\n\u001b[1;32m    391\u001b[0m             \u001b[0mnews_repr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbert_output\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    392\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpooler\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"attn\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 393\u001b[0;31m             \u001b[0mnews_repr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscaled_dp_attention\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbert_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbert_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattn_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattn_mask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mps_term_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    394\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpooler\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"avg\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m             \u001b[0mnews_repr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbert_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: view() got an unexpected keyword argument 'log'"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "model.eval()\n",
    "a,b,c = model(x2)\n",
    "d = model.encode_news(xn)\n",
    "e = model.encode_user(xu)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "a"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "torch.sigmoid(torch.dot(e[0],d[28])/math.sqrt(768))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "manager.fast = True\n",
    "manager.mode = \"dev\"\n",
    "\n",
    "loaders = manager.prepare()\n",
    "xn = list(loaders[1])[413]\n",
    "xu = list(loaders[2])[0]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "xn['cdd_id'][28]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.11",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.11 64-bit (conda)"
  },
  "interpreter": {
   "hash": "decb58d8582e8bebc2c9af4e5243ce054f2f8013c5b7e79ffbf7b8b9f3c0761b"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}