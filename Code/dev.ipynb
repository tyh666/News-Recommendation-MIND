{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import re\n",
    "import logging\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "import pickle\n",
    "from collections import defaultdict\n",
    "from utils.utils import prepare\n",
    "from data.configs.demo import config\n",
    "from collections import defaultdict\n",
    "from transformers import BertTokenizer,BertModel\n",
    "from utils.Manager import Manager\n",
    "\n",
    "from models.Embeddings.BERT import BERT_Embedding\n",
    "from models.Encoders.CNN import CNN_Encoder,CNN_User_Encoder\n",
    "from models.Encoders.RNN import RNN_Encoder,RNN_User_Encoder\n",
    "from models.Encoders.MHA import MHA_Encoder, MHA_User_Encoder\n",
    "from models.Modules.DRM import Matching_Reducer, BM25_Reducer\n",
    "from models.Rankers.BERT import BERT_Onepass_Ranker, BERT_Original_Ranker\n",
    "from models.Rankers.CNN import CNN_Ranker\n",
    "\n",
    "from models.Encoders.BERT import BERT_Encoder\n",
    "from models.Encoders.Pooling import *\n",
    "\n",
    "from models.ESM import ESM\n",
    "from models.TTMS import TTMS\n",
    "\n",
    "from models.Modules.Attention import MultiheadAttention"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "manager = Manager(config)\n",
    "loaders = prepare(manager)\n",
    "\n",
    "record = list(loaders[0])[0]"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[2021-08-25 15:14:26,642] INFO (utils.utils) Hyper Parameters are \n",
      "scale:demo\n",
      "k:5\n",
      "threshold:-inf\n",
      "signal_length:100\n",
      "his_size:50\n",
      "impr_size:10\n",
      "lr:0.0001\n",
      "hidden_dim:384\n",
      "world_size:0\n",
      "step:0\n",
      "[2021-08-25 15:14:26,643] INFO (utils.utils) preparing dataset...\n",
      "[2021-08-25 15:14:26,649] INFO (utils.MIND) loading cached user behavior from data/cache/bert/MINDdemo_train/10/behaviors..pkl\n",
      "[2021-08-25 15:14:26,666] INFO (utils.MIND) loading cached news tokenization from data/cache/bert/MINDdemo_train/news.pkl\n",
      "[2021-08-25 15:14:27,226] INFO (utils.utils) deduplicating...\n",
      "[2021-08-25 15:14:28,816] INFO (utils.MIND) loading cached user behavior from data/cache/bert/MINDdemo_dev/10/behaviors..pkl\n",
      "[2021-08-25 15:14:28,819] INFO (utils.MIND) loading cached news tokenization from data/cache/bert/MINDdemo_dev/news.pkl\n",
      "[2021-08-25 15:14:29,249] INFO (utils.utils) deduplicating...\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "class TTMS(nn.Module):\n",
    "    def __init__(self, config, embedding, encoderN, encoderU):\n",
    "        super().__init__()\n",
    "\n",
    "        self.scale = config.scale\n",
    "        self.cdd_size = config.cdd_size\n",
    "        self.batch_size = config.batch_size\n",
    "        self.his_size = config.his_size\n",
    "        self.device = config.device\n",
    "\n",
    "        self.embedding = embedding\n",
    "        self.encoderN = encoderN\n",
    "        self.encoderU = encoderU\n",
    "\n",
    "        self.reducer = Matching_Reducer(config)\n",
    "        self.bert = BERT_Encoder(config)\n",
    "\n",
    "        config.hidden_dim = config.embedding_dim\n",
    "        self.aggregate = Attention_Pooling(config)\n",
    "\n",
    "        self.name = '__'.join(['ttms', self.encoderN.name, self.encoderU.name])\n",
    "        config.name = self.name\n",
    "\n",
    "    def clickPredictor(self, cdd_news_repr, user_repr):\n",
    "        \"\"\" calculate batch of click probabolity\n",
    "\n",
    "        Args:\n",
    "            cdd_news_repr: news-level representation, [batch_size, cdd_size, hidden_dim]\n",
    "            user_repr: user representation, [batch_size, 1, hidden_dim]\n",
    "\n",
    "        Returns:\n",
    "            score of each candidate news, [batch_size, cdd_size]\n",
    "        \"\"\"\n",
    "        print(user_repr[0])\n",
    "        print(cdd_news_repr[0][0])\n",
    "\n",
    "        score = cdd_news_repr.matmul(user_repr.transpose(-2,-1)).squeeze(-1)\n",
    "\n",
    "        return score\n",
    "\n",
    "    def _forward(self,x):\n",
    "        his_news = x[\"his_encoded_index\"].long().to(self.device)\n",
    "        his_news_embedding = self.embedding(his_news)\n",
    "        his_news_encoded_embedding, his_news_repr = self.encoderN(\n",
    "            his_news_embedding\n",
    "        )\n",
    "\n",
    "        user_repr = self.encoderU(his_news_repr)\n",
    "\n",
    "        ps_terms, ps_term_mask = self.reducer(his_news_encoded_embedding, his_news_embedding, user_repr, his_news_repr, x[\"his_attn_mask\"].to(self.device), x[\"his_attn_mask_k\"].to(self.device).bool())\n",
    "\n",
    "        # append CLS to each historical news, aggregate historical news representation to user repr\n",
    "        ps_terms = torch.cat([his_news_embedding[:, :, 0].unsqueeze(-2), ps_terms], dim=-2)\n",
    "        ps_term_mask = torch.cat([torch.ones(*ps_term_mask.shape[0:2], 1, device=ps_term_mask.device), ps_term_mask], dim=-1)\n",
    "        ps_terms, his_news_repr = self.bert(ps_terms, ps_term_mask)\n",
    "        user_repr = self.aggregate(his_news_repr)\n",
    "\n",
    "        # append CLS to the entire browsing history, directly deriving user repr\n",
    "        # batch_size = ps_terms.size(0)\n",
    "        # ps_terms = torch.cat([his_news_embedding[:, 0, 0].unsqueeze(1).unsqueeze(1), ps_terms.view(batch_size, 1, -1, ps_terms.size(-1))], dim=-2)\n",
    "        # ps_term_mask = torch.cat([torch.ones(batch_size, 1, 1, device=ps_term_mask.device), ps_term_mask.view(batch_size, 1, -1)], dim=-1)\n",
    "        # _, user_repr = self.bert(ps_terms, ps_term_mask)\n",
    "\n",
    "\n",
    "        cdd_news = x[\"cdd_encoded_index\"].long().to(self.device)\n",
    "        _, cdd_news_repr = self.bert(\n",
    "            self.embedding(cdd_news), x['cdd_attn_mask'].to(self.device)\n",
    "        )\n",
    "\n",
    "        return self.clickPredictor(cdd_news_repr, user_repr)\n",
    "\n",
    "    def forward(self,x):\n",
    "        \"\"\"\n",
    "        Decoupled function, score is unormalized click score\n",
    "        \"\"\"\n",
    "        score = self._forward(x)\n",
    "\n",
    "        if self.training:\n",
    "            prob = nn.functional.log_softmax(score, dim=1)\n",
    "        else:\n",
    "            prob = torch.sigmoid(score)\n",
    "\n",
    "        return prob"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "embedding = BERT_Embedding(manager)\n",
    "\n",
    "encoderN = CNN_Encoder(manager)\n",
    "# encoderN = RNN_Encoder(manager)\n",
    "# encoderN = MHA_Encoder(manager)\n",
    "\n",
    "# encoderU = CNN_User_Encoder(manager)\n",
    "encoderU = RNN_User_Encoder(manager)\n",
    "# encoderU = MHA_User_Encoder(manager)\n",
    "\n",
    "# docReducer = Matching_Reducer(manager)\n",
    "# docReducer = BM25_Reducer(manager)\n",
    "\n",
    "# ranker = CNN_Ranker(manager)\n",
    "# ranker = BERT_Onepass_Ranker(manager)\n",
    "# ranker = BERT_Original_Ranker(manager)\n",
    "\n",
    "model = TTMS(manager, embedding, encoderN, encoderU).to(manager.device)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "model(record)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([[ 3.9672e-02,  2.4889e-01, -3.2479e-01,  3.2325e-01,  4.9139e-01,\n",
      "         -3.2715e-01,  3.6095e-01,  3.7133e-01, -2.9406e-01, -3.1607e-01,\n",
      "          1.2882e-02, -2.6066e-01, -9.8634e-02,  1.0472e-01,  6.2066e-02,\n",
      "          8.5859e-02,  3.4953e-01, -5.8611e-02,  6.2024e-01,  5.8177e-03,\n",
      "          2.0220e-01, -4.7170e-01,  5.9268e-02,  2.0477e-01,  7.9676e-02,\n",
      "         -1.9533e-01,  1.6602e-01,  1.6525e-01, -3.4361e-01, -3.0317e-01,\n",
      "          3.3046e-01, -4.2683e-01, -1.2095e-01,  2.8960e-01,  5.0703e-02,\n",
      "         -1.1985e-01,  2.3184e-01, -5.4352e-01, -3.5424e-01,  2.5918e-02,\n",
      "         -2.4820e-01, -6.1629e-01, -2.4545e-01, -1.2437e-01,  3.0897e-01,\n",
      "         -2.8026e-01,  3.0536e-02,  7.3582e-02,  5.4243e-01,  3.3926e-02,\n",
      "         -1.6106e-01,  4.6877e-01,  2.2723e-01, -5.1455e-01,  2.1250e-01,\n",
      "          1.0438e+00, -3.5191e-01, -2.0370e-01, -1.7700e-02, -5.3558e-01,\n",
      "          3.6929e-01, -4.9108e-01,  5.4051e-01, -6.5740e-01,  6.7561e-01,\n",
      "         -2.8046e-02,  3.0360e-01,  1.3499e-01, -3.0817e-01, -6.9578e-01,\n",
      "         -4.6849e-01,  4.0962e-01,  1.3957e-01, -2.6200e-01,  3.1228e-02,\n",
      "          2.8806e-01, -3.6442e-01,  1.0281e-01, -1.1434e-03, -2.9776e-01,\n",
      "         -3.9979e-01,  3.8234e-01, -2.8911e-01,  9.9967e-01,  7.8053e-02,\n",
      "         -4.9580e-01,  2.9787e-01,  3.6967e-01, -1.8910e-01,  2.1228e-01,\n",
      "         -5.1687e-01,  2.7464e-02,  3.5281e-01, -3.6255e-01,  3.4241e-01,\n",
      "          3.0359e-01,  3.4304e-01,  2.4737e-01, -6.2250e-01,  6.0762e-02,\n",
      "          4.5552e-01, -1.9100e-03, -2.5857e-01, -1.7305e-01, -2.3320e-01,\n",
      "          7.9902e-02,  2.3864e-02, -4.0402e-01,  9.4728e-02,  4.1365e-01,\n",
      "         -1.7988e-01,  1.7690e-01, -4.3480e-01, -1.1156e-01, -5.3811e-02,\n",
      "          1.4753e-01,  3.4404e-01, -1.2065e-01, -5.1581e-01, -6.6210e-01,\n",
      "          4.4624e-01,  1.2480e-01,  3.4628e-01,  1.0839e+00,  3.3223e-01,\n",
      "         -1.4595e-01, -7.7669e-01,  1.2469e-01,  2.5616e-02,  5.9891e-02,\n",
      "          1.4040e-01,  2.4120e-01, -1.5654e-02,  2.0901e-01, -1.2649e-01,\n",
      "          3.7639e-02, -6.4369e-01,  1.1331e-01, -4.0271e-02,  1.8397e-01,\n",
      "         -3.6000e-01, -4.6263e-01,  5.4556e-01, -5.8650e-01,  9.2137e-02,\n",
      "         -1.7491e-02,  2.9677e-01,  8.6342e-02, -5.0379e-01,  4.1057e-02,\n",
      "          6.7828e-01,  1.1396e-01, -2.8303e-01, -4.0001e-01,  9.1599e-01,\n",
      "          1.2412e-01, -4.1616e-01,  1.5942e-01, -3.1621e-01, -6.3117e-02,\n",
      "          3.2031e-01, -1.2318e-01, -3.0409e-01,  1.5731e-01,  6.1589e-02,\n",
      "          2.9834e-01, -2.5384e-01,  1.1423e+00, -5.0787e-02,  6.0701e-01,\n",
      "         -1.3911e-01, -3.2010e-01,  7.3917e-01,  9.4879e-02, -9.7618e-03,\n",
      "          1.2634e-01,  3.6960e-01, -4.8532e-01,  2.1989e-01, -2.7030e-01,\n",
      "         -1.1365e+00,  3.8999e-01, -7.0189e-02, -1.8803e-01,  2.6736e-01,\n",
      "         -3.0802e-01,  1.9345e-01, -3.6272e-01,  3.2850e-01,  4.7750e-01,\n",
      "         -4.9673e-01, -4.5841e-01, -1.9409e-01,  2.7239e-02,  6.2569e-01,\n",
      "         -3.1511e-01,  3.4521e-01,  1.0292e-01, -4.8370e-01, -3.5032e-02,\n",
      "          1.6254e-01,  6.0985e-01, -4.8183e-01,  1.0951e-01, -6.8882e-01,\n",
      "         -2.4813e-01,  3.1288e-01, -2.1789e-01,  3.0551e-02, -4.5333e-01,\n",
      "         -3.0218e-01,  2.4441e-01, -1.8760e-01, -1.3617e-02,  1.6275e-01,\n",
      "         -2.1893e-01, -7.8375e-02, -7.8427e-02, -2.2036e-01,  1.4894e-01,\n",
      "         -4.6719e-01, -2.4221e-01, -5.1652e-01,  2.0981e-01,  4.9406e-01,\n",
      "          3.1327e-01, -3.1470e-01,  2.4644e-01,  3.6442e-02,  5.8046e-01,\n",
      "         -2.3622e-01, -8.9106e-01,  7.3793e-01, -3.0345e-02, -3.3671e-01,\n",
      "          2.0526e-01,  1.1393e-02, -3.9059e-01, -1.0396e-01, -8.7001e-01,\n",
      "         -1.5279e-01,  4.8883e-01,  3.7245e-03, -2.5726e-01,  2.5054e-01,\n",
      "         -3.7544e-02, -2.7478e-01,  1.2144e-01,  3.1892e-01,  1.0701e-01,\n",
      "         -4.9588e-01,  4.5888e-01,  3.7153e-02, -3.9043e-01, -2.0138e-02,\n",
      "         -5.0287e-01, -1.2893e-01, -1.9668e-02,  1.4193e-02,  2.6244e-02,\n",
      "          6.7329e-01,  2.4731e-01, -1.0762e-03,  2.7624e-02, -7.3080e-01,\n",
      "         -9.3539e-01, -7.3463e-01,  1.1262e-02,  3.8587e-01,  2.5091e-01,\n",
      "          6.7985e-02, -2.9144e-01, -4.7735e-01,  8.4952e-01, -3.5576e-01,\n",
      "         -1.7877e-01,  4.1558e-01, -3.1377e-01, -1.0890e-01, -5.4609e-01,\n",
      "         -6.7154e-01,  7.7931e-01, -2.8735e-02, -1.1419e-02, -1.3388e-01,\n",
      "         -1.0936e-02, -3.8051e-01, -1.4378e-01,  1.0886e-01, -6.0650e-01,\n",
      "         -1.3597e-01, -4.3986e-01,  1.0005e-01, -5.8592e-01,  7.0706e-02,\n",
      "         -4.2569e-01, -1.1274e-01,  4.9158e-01,  5.6142e-01,  1.0192e+00,\n",
      "         -5.1945e-01, -1.5547e-01,  3.3967e-02,  3.7294e-01,  2.1530e-01,\n",
      "          3.7059e-01,  1.3013e-01,  5.4409e-02, -1.9774e+00,  5.8345e-02,\n",
      "          1.6784e-01, -2.3819e-01,  1.1385e-01,  1.9929e-01, -3.4011e-01,\n",
      "         -3.9097e-01, -8.7332e-01,  9.0927e-02, -7.0043e-02, -3.4446e-01,\n",
      "          4.8640e-01,  4.7491e-01,  2.0052e-01, -2.7275e-01,  1.0907e-02,\n",
      "         -8.2265e-02, -1.3429e-01,  5.1356e-01,  2.6964e-01, -5.2358e-01,\n",
      "         -2.7805e-01, -1.3797e-01, -4.9147e-02,  1.3908e-01, -2.3311e-02,\n",
      "         -3.0077e-01, -7.4691e-01, -3.5218e-01,  4.0528e-01, -3.7452e-01,\n",
      "         -6.5377e-01,  7.5158e-02,  4.8752e-03,  2.5348e-01, -6.8428e-02,\n",
      "         -9.6941e-01,  1.7716e-02,  8.3353e-02, -3.3590e-01, -1.0109e+00,\n",
      "          2.4195e-01, -3.9935e-02,  6.9601e-01,  4.0077e-01,  6.0529e-01,\n",
      "          3.8965e-01, -4.2764e-01,  2.4895e-01,  3.6654e-01,  1.1945e-02,\n",
      "          5.1767e-01, -5.1982e-01, -4.5987e-02,  1.5374e-01,  5.5769e-01,\n",
      "         -1.7704e-01, -4.6738e-01, -5.4434e-01,  1.7155e-01,  1.8118e-01,\n",
      "         -1.2788e-01,  9.8377e-01, -1.5080e-01, -1.0933e+00, -5.7093e-01,\n",
      "          6.3320e-01,  1.1726e-03,  6.6405e-02, -7.2026e-01,  5.8380e-01,\n",
      "         -4.5143e-01, -6.2441e-01, -2.8036e-01, -8.1731e-01,  4.2419e-01,\n",
      "          5.5307e-02, -4.5984e-02, -2.7660e-01, -3.9184e-01,  3.8331e-01,\n",
      "          2.0324e-01,  2.9551e-02,  4.0166e-02,  1.8679e-01, -3.9177e-01,\n",
      "          3.4060e-01, -5.7222e-02, -8.8703e-03,  8.7238e-03, -1.8879e-01,\n",
      "          6.0312e-01,  5.4942e-02, -2.8462e-02,  1.3806e-01,  8.1994e-01,\n",
      "          6.9938e-01, -2.9745e-01, -3.9467e-01,  3.8041e-02,  4.4723e-02,\n",
      "          2.7639e-01,  2.0554e-01,  3.3600e-01,  4.0580e-01,  1.3333e-01,\n",
      "         -2.9366e-01,  2.8583e-01,  2.9599e-01, -1.7116e-01, -2.2585e-02,\n",
      "         -5.9156e-02, -4.7701e-01,  1.4192e-01, -4.1778e-01,  4.9780e-01,\n",
      "          6.9709e-01,  4.0865e-01, -3.4478e-01, -4.1722e-01,  2.1556e-01,\n",
      "         -2.6893e-01,  4.3712e-01, -1.7614e-01,  2.4063e-01, -2.8008e-01,\n",
      "         -9.3491e-02,  4.0125e-01, -3.1532e-01,  4.8470e-01,  4.6351e-02,\n",
      "          2.4870e-02, -5.7778e-02, -2.0731e-01,  6.6158e-02,  5.1467e-02,\n",
      "         -6.8166e-01, -6.9525e-01, -1.0230e-01,  2.1908e-01,  3.8816e-01,\n",
      "         -7.5140e-01, -9.2306e-02,  4.5172e-01,  7.2904e-01, -4.8949e-01,\n",
      "          5.6083e-02, -5.4996e-02,  2.2686e-01, -3.1383e-01,  3.0377e-01,\n",
      "         -3.3077e-02, -9.8861e-01,  6.3948e-01,  3.9905e-01,  1.6823e-01,\n",
      "          1.3292e-01,  1.6530e-01, -1.5734e-01,  5.9326e-02, -4.9539e-02,\n",
      "          1.2204e-01, -1.7615e-01, -3.0906e-01,  2.9682e-01,  1.3848e-01,\n",
      "         -6.8899e-02,  1.6931e-01,  1.6575e-01, -4.1759e-02, -5.3963e-01,\n",
      "          2.3704e-01, -5.5454e-01,  7.7981e-02,  2.9061e-01, -4.1938e-01,\n",
      "         -3.7140e-01, -2.3063e-01,  1.6069e-01, -1.5173e-01, -3.1602e-01,\n",
      "          9.2709e-02,  1.2150e-01,  3.8507e-01, -1.1341e-01, -2.5397e-02,\n",
      "          1.3507e-01, -2.0036e-01,  1.1301e-01, -3.7867e-01, -3.5252e-01,\n",
      "         -7.7196e-01, -1.8040e-01, -4.5035e-01, -2.3257e-01,  2.1806e-01,\n",
      "         -1.0876e+00,  1.1152e-01,  1.2083e-01, -3.1238e-01, -5.8675e-01,\n",
      "          2.5718e-01,  1.2019e-01,  6.2273e-01,  7.2652e-02,  1.7197e-01,\n",
      "          3.9289e-01, -3.1125e-01,  1.9721e-01, -3.4679e-01,  1.1253e-01,\n",
      "          1.8408e-01, -1.1441e-01,  4.0437e-01,  2.0757e-01, -1.0606e-01,\n",
      "          6.9727e-01, -1.4748e-01, -1.0532e-01, -8.5766e-01,  3.7653e-02,\n",
      "          3.0457e-01, -3.2975e-01, -1.0759e-01, -8.5252e-01, -2.2676e-01,\n",
      "          4.8671e-01,  5.3900e-02,  1.8614e-01, -5.2279e-01, -3.1076e-01,\n",
      "          2.7784e-01,  1.4511e-01,  2.4269e-01, -6.7558e-02, -2.5371e-01,\n",
      "         -2.7636e-01,  4.7444e-01, -4.7026e-01, -2.8677e-01,  2.7379e-02,\n",
      "          3.0560e-01,  2.0585e-01,  4.9498e-01, -1.3264e-01, -1.1515e-01,\n",
      "         -2.6215e-02,  2.3376e-01,  4.4665e-01, -2.2983e-01, -6.5221e-01,\n",
      "          1.4162e-01, -3.7379e-01, -1.3913e-01, -2.7520e-01, -1.2049e-01,\n",
      "         -2.8544e-01, -4.4869e-02,  1.0369e-01, -3.5516e-01,  1.4316e-01,\n",
      "         -1.7366e-01,  1.9913e-01,  8.4058e-01,  5.5476e-02,  3.6885e-01,\n",
      "         -3.4597e-01,  8.3361e-01, -5.4826e-01, -4.8746e-01,  1.5970e-01,\n",
      "         -6.2633e-02, -2.0475e-01,  5.5143e-01,  6.8934e-01,  4.2825e-01,\n",
      "         -7.3887e-01, -3.9463e-02, -1.8511e-01, -6.1835e-01, -3.0094e-01,\n",
      "         -4.0669e-01,  4.9375e-01,  5.3260e-01, -4.8949e-01,  9.5582e-02,\n",
      "          2.4711e-01, -5.9570e-01, -8.6689e-03, -3.2695e-01,  9.0091e-02,\n",
      "         -3.6416e-02, -6.6614e-01,  1.6674e-01,  9.1608e-02,  1.9600e-01,\n",
      "         -1.6542e-01, -9.3702e-01, -1.1820e-01,  4.9013e-01, -2.0766e-01,\n",
      "          9.9406e-02,  9.2013e-02, -2.7016e-01,  5.0747e-01, -4.7400e-01,\n",
      "         -6.2002e-01,  4.3701e-01,  9.0321e-01, -5.9881e-03, -7.3326e-02,\n",
      "         -5.5007e-02,  1.1202e-01, -5.0247e-01, -3.3129e-01, -1.0733e-01,\n",
      "          3.7000e-01,  5.8780e-01,  3.7902e-01, -6.3904e-02,  4.5400e-01,\n",
      "          5.0475e-01, -6.1081e-01,  6.2948e-02,  1.1208e-01,  6.0807e-01,\n",
      "         -5.3080e-01, -1.4130e-01,  5.6460e-01, -6.8911e-02,  1.9843e-01,\n",
      "          1.2081e-01,  2.7029e-01, -9.2751e-02, -1.3320e-01, -3.1787e-03,\n",
      "          1.4976e-01, -3.3867e-02,  1.3191e-01, -6.2770e-02, -3.0064e-01,\n",
      "          2.5999e-01,  6.7537e-01, -4.2196e-02,  7.4614e-01, -3.9360e-02,\n",
      "         -5.8742e-01, -5.1945e-03, -2.6491e-01,  5.2390e-01,  7.2443e-01,\n",
      "          5.8909e-02,  1.0661e-01, -3.3001e-01,  2.5979e-01, -4.6017e-02,\n",
      "         -5.9225e-01, -3.1159e-01,  6.8147e-01, -9.8388e-02,  1.0368e-01,\n",
      "          4.5903e-01, -4.5760e-01, -2.1426e-01, -1.1889e-03,  7.4514e-01,\n",
      "          2.8789e-01, -4.2939e-02,  1.6305e-01, -1.7222e-01,  7.6164e-01,\n",
      "         -1.1534e+00,  1.1518e-02,  2.6617e-01,  2.8110e-01,  1.3722e-01,\n",
      "          6.2023e-02, -1.0416e-02,  2.1956e-01,  5.3997e-01,  1.5294e-01,\n",
      "         -8.3116e-01, -2.6027e-01,  4.1535e-01,  7.1749e-02, -1.1294e-01,\n",
      "         -2.4800e-01,  2.2818e-01, -1.0279e-01,  6.8152e-02, -2.4654e-01,\n",
      "          3.1295e-01,  3.3333e-01, -1.8952e-01, -2.1379e-01,  3.2190e-01,\n",
      "          2.9732e-01,  4.7352e-01, -2.3387e-01,  3.4545e-01, -6.1370e-02,\n",
      "         -6.0462e-02,  1.7293e-01, -7.9415e-01, -1.4163e-02,  5.0515e-01,\n",
      "          4.1932e-01, -4.8301e-01, -4.3633e-01,  8.5492e-02,  9.5852e-01,\n",
      "         -6.0973e-01,  4.2542e-01, -5.9756e-01, -7.5503e-01,  3.1465e-01,\n",
      "          1.4094e-01, -1.5526e-01, -6.1651e-01, -1.3718e-01,  6.5403e-02,\n",
      "          1.0366e-02,  3.9800e-01, -2.9972e-01,  2.7940e-01, -4.5124e-01,\n",
      "          2.8432e-01, -1.2097e-01,  3.3465e-01, -8.5063e-01, -3.7337e-01,\n",
      "         -1.3520e-01,  1.0303e-01,  2.2437e-01, -9.8372e-02,  2.6651e-01,\n",
      "         -6.1867e-02, -2.4858e-01, -1.7573e-01,  3.6929e-01,  3.3101e-02,\n",
      "         -1.1612e-01, -4.1116e-01,  3.7783e-01, -9.4937e-03, -9.4964e-02,\n",
      "         -1.7571e-01,  8.3259e-02, -8.0239e-01, -2.1812e-01, -4.3685e-01,\n",
      "         -8.3805e-02, -2.8489e-01,  4.8512e-01, -6.7820e-01, -2.5053e-01,\n",
      "          3.4079e-01,  2.9211e-01, -8.7852e-02]], grad_fn=<SelectBackward>)\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[-3.3258e+01, -2.3292e+01, -3.0447e-01, -1.4518e+00, -3.5635e+00],\n",
       "        [-1.6287e+00, -7.1115e-01, -1.3718e+00, -8.3284e+00, -2.8328e+00],\n",
       "        [-2.4748e+01, -1.5640e+01, -1.5555e+01, -1.4681e+01, -7.1526e-07],\n",
       "        [-2.7020e+01, -1.9071e+01, -2.3484e+01, -2.7617e+01,  0.0000e+00],\n",
       "        [-3.7350e+01, -2.8984e+01, -3.9298e+01, -2.6822e+01,  0.0000e+00],\n",
       "        [-1.0016e+01, -1.0926e+01, -1.0405e+00, -4.2831e+00, -4.5748e-01],\n",
       "        [-6.2562e+00, -1.0601e+01, -4.3730e-01, -2.8990e+00, -1.2133e+00],\n",
       "        [-1.3679e-02, -7.7812e+00, -8.7475e+00, -5.3554e+00, -4.7931e+00],\n",
       "        [-1.7614e+01, -4.8645e+00, -1.0341e+01, -7.7940e-03, -1.1084e+01],\n",
       "        [-1.5301e+01, -2.2115e+01, -2.0745e+01, -1.5321e+01, -4.7684e-07]],\n",
       "       grad_fn=<LogSoftmaxBackward>)"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.11",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.11 64-bit (conda)"
  },
  "interpreter": {
   "hash": "decb58d8582e8bebc2c9af4e5243ce054f2f8013c5b7e79ffbf7b8b9f3c0761b"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}