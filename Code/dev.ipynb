{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "source": [
    "import re\n",
    "import logging\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "import pickle\n",
    "from collections import defaultdict\n",
    "from utils.utils import prepare\n",
    "from data.configs.demo import config\n",
    "from collections import defaultdict\n",
    "from transformers import BertTokenizer,BertModel\n",
    "from utils.Manager import Manager\n",
    "\n",
    "from models.Embeddings.BERT import BERT_Embedding\n",
    "from models.Encoders.CNN import CNN_Encoder,CNN_User_Encoder\n",
    "from models.Encoders.RNN import RNN_Encoder,RNN_User_Encoder\n",
    "from models.Encoders.MHA import MHA_Encoder, MHA_User_Encoder\n",
    "from models.Modules.DRM import Matching_Reducer, BM25_Reducer\n",
    "from models.Rankers.BERT import BERT_Onepass_Ranker, BERT_Original_Ranker\n",
    "from models.Rankers.CNN import CNN_Ranker\n",
    "\n",
    "from models.Encoders.BERT import BERT_Encoder\n",
    "from models.Encoders.Pooling import *\n",
    "\n",
    "from models.ESM import ESM\n",
    "from models.TTMS import TTMS\n",
    "\n",
    "from models.Modules.Attention import MultiheadAttention"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "manager = Manager(config)\n",
    "loaders = prepare(manager)\n",
    "\n",
    "record = list(loaders[0])[0]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "source": [
    "class Matching_Reducer(nn.Module):\n",
    "    \"\"\"\n",
    "    basic document reducer: topk of each historical article\n",
    "    \"\"\"\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "\n",
    "        self.name = \"matching\"\n",
    "\n",
    "        self.k = config.k\n",
    "        self.diversify = config.diversify\n",
    "\n",
    "        config.term_num = config.k * config.his_size\n",
    "\n",
    "        if self.diversify:\n",
    "            self.newsUserAlign = nn.Linear(config.hidden_dim * 2, config.hidden_dim)\n",
    "            nn.init.xavier_normal_(self.newsUserAlign.weight)\n",
    "\n",
    "        if config.threshold != -float('inf'):\n",
    "            threshold = torch.tensor([config.threshold])\n",
    "            self.register_buffer('threshold', threshold)\n",
    "\n",
    "    def forward(self, news_selection_embedding, news_embedding, user_repr, news_repr, his_attn_mask, his_attn_mask_k):\n",
    "        \"\"\"\n",
    "        Extract words from news text according to the overall user interest\n",
    "\n",
    "        Args:\n",
    "            news_selection_embedding: encoded word-level embedding, [batch_size, his_size, signal_length, hidden_dim]\n",
    "            news_embedding: word-level news embedding, [batch_size, his_size, signal_length, hidden_dim]\n",
    "            news_repr: news-level representation, [batch_size, his_size, hidden_dim]\n",
    "            user_repr: user representation, [batch_size, 1, hidden_dim]\n",
    "\n",
    "        Returns:\n",
    "            ps_terms: weighted embedding for personalized terms, [batch_size, his_size, k, hidden_dim]\n",
    "            ps_term_mask: attention mask of output terms, [batch_size, his_size, k]\n",
    "        \"\"\"\n",
    "        # strip off [CLS]\n",
    "        news_selection_embedding = news_selection_embedding[:, :, 1:]\n",
    "        news_embedding = news_embedding[:, :, 1:]\n",
    "        if self.diversify:\n",
    "            news_user_repr = torch.cat([user_repr.expand(news_repr.size()), news_repr], dim=-1)\n",
    "            selection_query = self.newsUserAlign(news_user_repr).unsqueeze(-1)\n",
    "        else:\n",
    "            selection_query = user_repr.expand(news_repr.size()).unsqueeze(-1)\n",
    "\n",
    "        # [bs, hs, sl - 1]\n",
    "        scores = F.normalize(news_selection_embedding, dim=-1).matmul(F.normalize(selection_query, dim=-1)).squeeze(-1)\n",
    "        # mask the padded term\n",
    "        scores = scores.masked_fill(~his_attn_mask_k[:, :, 1:], -float('inf'))\n",
    "\n",
    "        score_k, score_kid = scores.topk(dim=-1, k=self.k, sorted=False)\n",
    "\n",
    "        ps_terms = news_embedding.gather(dim=-2,index=score_kid.unsqueeze(-1).expand(score_kid.size() + (news_embedding.size(-1),)))\n",
    "        # [bs, hs, k]\n",
    "        ps_term_mask = his_attn_mask[:, :, 1:].gather(dim=-1, index=score_kid)\n",
    "\n",
    "        if hasattr(self, 'threshold'):\n",
    "            mask_pos = score_k < self.threshold\n",
    "            # ps_terms = personalized_terms * (nn.functional.softmax(score_k.masked_fill(score_k < self.threshold, 0), dim=-1).unsqueeze(-1))\n",
    "            ps_terms = ps_terms * (score_k.masked_fill(mask_pos, 0).unsqueeze(-1))\n",
    "            ps_term_mask = ps_term_mask * (~mask_pos)\n",
    "\n",
    "        else:\n",
    "            ps_terms = ps_terms * (F.softmax(score_k, dim=-1).unsqueeze(-1))\n",
    "            # ps_terms = ps_terms * (score_k.unsqueeze(-1))\n",
    "        return ps_terms, ps_term_mask, score_kid"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "source": [
    "class TTMS(nn.Module):\n",
    "    def __init__(self, config, embedding, encoderN, encoderU, reducer, aggregator=None):\n",
    "        super().__init__()\n",
    "\n",
    "        self.scale = config.scale\n",
    "        self.cdd_size = config.cdd_size\n",
    "        self.batch_size = config.batch_size\n",
    "        self.his_size = config.his_size\n",
    "        self.device = config.device\n",
    "\n",
    "        self.embedding = embedding\n",
    "        self.encoderN = encoderN\n",
    "        self.encoderU = encoderU\n",
    "\n",
    "        self.reducer = reducer\n",
    "        self.bert = BERT_Encoder(config)\n",
    "\n",
    "        self.aggregator = aggregator\n",
    "\n",
    "        if not aggregator:\n",
    "            self.userProject = nn.Sequential(\n",
    "                nn.Linear(self.bert.hidden_dim, self.bert.hidden_dim),\n",
    "                nn.Tanh()\n",
    "            )\n",
    "\n",
    "        self.name = '__'.join(['ttms', self.encoderN.name, self.encoderU.name, config.reducer])\n",
    "        config.name = self.name\n",
    "\n",
    "    def clickPredictor(self, cdd_news_repr, user_repr):\n",
    "        \"\"\" calculate batch of click probabolity\n",
    "\n",
    "        Args:\n",
    "            cdd_news_repr: news-level representation, [batch_size, cdd_size, hidden_dim]\n",
    "            user_repr: user representation, [batch_size, 1, hidden_dim]\n",
    "\n",
    "        Returns:\n",
    "            score of each candidate news, [batch_size, cdd_size]\n",
    "        \"\"\"\n",
    "        # print(user_repr.mean(), cdd_news_repr.mean(), user_repr.max(), cdd_news_repr.max(), user_repr.sum(), cdd_news_repr.sum())\n",
    "        score = cdd_news_repr.matmul(user_repr.transpose(-2,-1)).squeeze(-1)\n",
    "        return score\n",
    "\n",
    "    def _forward(self,x):\n",
    "        cdd_subword_prefix = F.normalize(x[\"cdd_subword_prefix\"].to(self.device), p=1, dim=-1)\n",
    "        his_subword_prefix = F.normalize(x[\"his_subword_prefix\"].to(self.device), p=1, dim=-1)\n",
    "        if self.reducer.name == 'matching':\n",
    "            his_news = x[\"his_encoded_index\"].long().to(self.device)\n",
    "            his_news_embedding = self.embedding(his_news, his_subword_prefix)\n",
    "            his_news_encoded_embedding, his_news_repr = self.encoderN(\n",
    "                his_news_embedding\n",
    "            )\n",
    "            user_repr = self.encoderU(his_news_repr)\n",
    "\n",
    "            # his_attn_mask = his_subword_prefix.matmul(x[\"his_attn_mask\"].to(self.device).float().unsqueeze(-1)).squeeze(-1)\n",
    "            # his_reduced_mask = his_subword_prefix.matmul(x[\"his_reduced_mask\"].to(self.device).float().unsqueeze(-1)).squeeze(-1)\n",
    "            ps_terms, ps_term_mask, kid = self.reducer(his_news_encoded_embedding, his_news_embedding, user_repr, his_news_repr, x[\"his_attn_mask\"].to(self.device), x[\"his_reduced_mask\"].to(self.device).bool())\n",
    "            \n",
    "        elif self.reducer.name == 'bow':\n",
    "            his_reduced_news = x[\"his_reduced_index\"].long().to(self.device)\n",
    "            his_news_embedding = self.embedding(his_reduced_news, bow=True)\n",
    "            his_reduced_encoded_embedding, his_reduced_repr = self.encoderN(his_news_embedding)\n",
    "            user_repr = self.encoderU(his_reduced_repr)\n",
    "            ps_terms, ps_term_mask, kid = self.reducer(his_reduced_encoded_embedding, his_news_embedding, user_repr, his_reduced_repr, x[\"his_attn_mask\"].to(self.device))\n",
    "            del user_repr, his_reduced_encoded_embedding, his_reduced_repr\n",
    "\n",
    "        elif self.reducer.name == 'bm25':\n",
    "            his_news = x[\"his_reduced_index\"].long().to(self.device)\n",
    "            his_news_embedding = self.embedding(his_news)\n",
    "            his_news_encoded_embedding, his_news_repr = self.encoderN(\n",
    "                his_news_embedding\n",
    "            )\n",
    "\n",
    "            kid = None\n",
    "            user_repr = None\n",
    "            ps_terms, ps_term_mask = self.reducer(his_news_encoded_embedding, his_news_embedding, user_repr, his_news_repr, x[\"his_reduced_mask\"].to(self.device))\n",
    "\n",
    "        # append CLS to each historical news, aggregator historical news representation to user repr\n",
    "        if self.aggregator:\n",
    "            ps_terms = torch.cat([his_news_embedding[:, :, 0].unsqueeze(-2), ps_terms], dim=-2)\n",
    "            ps_term_mask = torch.cat([torch.ones(*ps_term_mask.shape[0:2], 1, device=ps_term_mask.device), ps_term_mask], dim=-1)\n",
    "            ps_terms, his_news_repr = self.bert(ps_terms, ps_term_mask)\n",
    "            user_repr = self.aggregator(his_news_repr)\n",
    "\n",
    "        # append CLS to the entire browsing history, directly deriving user repr\n",
    "        else:\n",
    "            batch_size = ps_terms.size(0)\n",
    "            ps_terms = torch.cat([his_news_embedding[:, 0, 0].unsqueeze(1).unsqueeze(1), ps_terms.reshape(batch_size, 1, -1, ps_terms.size(-1))], dim=-2)\n",
    "            ps_term_mask = torch.cat([torch.ones(batch_size, 1, 1, device=ps_term_mask.device), ps_term_mask.reshape(batch_size, 1, -1)], dim=-1)\n",
    "            _, user_cls = self.bert(ps_terms, ps_term_mask)\n",
    "            user_repr = self.userProject(user_cls)\n",
    "\n",
    "        cdd_news = x[\"cdd_encoded_index\"].long().to(self.device)\n",
    "        _, cdd_news_repr = self.bert(\n",
    "            self.embedding(cdd_news, cdd_subword_prefix), x['cdd_attn_mask'].to(self.device)#cdd_subword_prefix.matmul(x['cdd_attn_mask'].to(self.device).float().unsqueeze(-1)).squeeze(-1)\n",
    "        )\n",
    "\n",
    "        return self.clickPredictor(cdd_news_repr, user_repr), kid\n",
    "\n",
    "    def forward(self,x):\n",
    "        \"\"\"\n",
    "        Decoupled function, score is unormalized click score\n",
    "        \"\"\"\n",
    "        score, kid = self._forward(x)\n",
    "\n",
    "        if self.training:\n",
    "            prob = nn.functional.log_softmax(score, dim=1)\n",
    "        else:\n",
    "            prob = torch.sigmoid(score)\n",
    "\n",
    "        return prob, kid"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "source": [
    "reducer = Matching_Reducer(manager)\n",
    "model = TTMS(manager, embedding, encoderN, encoderU, reducer).to(manager.device)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "source": [
    "model(record)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([[[[ 2.8471e-01,  4.7919e-02,  2.6784e-02,  ...,  0.0000e+00,\n",
      "            1.6809e-01,  3.6454e-01],\n",
      "          [ 0.0000e+00, -3.0080e-01, -3.4460e-01,  ..., -3.3522e-02,\n",
      "           -1.8364e-01, -1.5247e-02],\n",
      "          [-0.0000e+00, -9.3748e-02,  0.0000e+00,  ...,  6.2561e-02,\n",
      "           -0.0000e+00,  1.0163e-01],\n",
      "          [-0.0000e+00,  3.0413e-02,  7.0649e-02,  ...,  5.8038e-02,\n",
      "           -1.5277e-01,  0.0000e+00],\n",
      "          [ 1.0416e-01, -5.7094e-02,  8.2009e-03,  ..., -3.2584e-02,\n",
      "            0.0000e+00,  4.0886e-02]],\n",
      "\n",
      "         [[ 1.8386e-01,  4.0401e-01, -1.5275e-01,  ...,  2.5630e-01,\n",
      "            3.8620e-02, -2.3655e-01],\n",
      "          [-1.6229e-01, -2.4824e-02,  1.0714e-01,  ...,  3.1961e-01,\n",
      "           -2.6707e-01, -2.2870e-01],\n",
      "          [-0.0000e+00,  8.5058e-02,  6.0091e-02,  ..., -1.8317e-02,\n",
      "            0.0000e+00, -6.7271e-02],\n",
      "          [ 1.2432e-01, -1.9674e-02, -2.7509e-01,  ..., -6.3117e-02,\n",
      "           -2.3561e-02,  6.8449e-02],\n",
      "          [-1.1163e-01,  7.8947e-02, -2.5028e-02,  ...,  2.5502e-01,\n",
      "            0.0000e+00,  1.8270e-01]],\n",
      "\n",
      "         [[-0.0000e+00, -0.0000e+00, -5.5687e-02,  ...,  1.5917e-01,\n",
      "            0.0000e+00,  1.9642e-01],\n",
      "          [ 1.3845e-01, -5.6341e-02, -2.3261e-01,  ..., -1.2974e-01,\n",
      "            8.6663e-02, -7.9804e-02],\n",
      "          [-1.5092e-01,  0.0000e+00,  5.7478e-03,  ...,  2.8622e-01,\n",
      "            5.6361e-02,  3.6364e-01],\n",
      "          [-0.0000e+00,  5.7918e-02, -7.0040e-02,  ...,  2.6054e-02,\n",
      "           -1.4722e-02, -8.8012e-03],\n",
      "          [-1.5188e-01, -0.0000e+00, -4.8029e-02,  ...,  0.0000e+00,\n",
      "           -1.0375e-02,  2.2848e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0000e+00, -2.0070e-01, -0.0000e+00,  ...,  1.3425e-01,\n",
      "            7.7148e-02,  4.3060e-02],\n",
      "          [-5.6351e-03, -3.6330e-01, -1.2445e-01,  ...,  1.1827e-01,\n",
      "            3.7504e-02,  5.6021e-02],\n",
      "          [ 4.2743e-02, -0.0000e+00, -1.1648e-01,  ...,  3.8466e-02,\n",
      "            3.1241e-02,  9.6283e-02],\n",
      "          [ 3.4883e-02, -0.0000e+00, -1.2224e-01,  ...,  0.0000e+00,\n",
      "           -0.0000e+00,  6.2402e-02],\n",
      "          [ 2.0513e-02, -1.8150e-01, -3.5868e-02,  ...,  6.9955e-02,\n",
      "           -3.6696e-02,  7.0810e-02]],\n",
      "\n",
      "         [[ 7.8988e-02, -0.0000e+00, -9.4629e-02,  ...,  1.0876e-01,\n",
      "            6.2498e-02,  3.4883e-02],\n",
      "          [-0.0000e+00, -2.2021e-01, -7.5436e-02,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  3.3956e-02],\n",
      "          [ 0.0000e+00, -2.8544e-01, -1.3027e-01,  ...,  1.1241e-01,\n",
      "           -4.8369e-02,  6.6503e-02],\n",
      "          [ 7.5379e-02, -0.0000e+00, -0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  1.6980e-01],\n",
      "          [ 2.0542e-02, -1.8175e-01, -3.5919e-02,  ...,  7.0054e-02,\n",
      "           -3.6748e-02,  7.0910e-02]],\n",
      "\n",
      "         [[ 7.3269e-02, -1.5081e-01, -8.7777e-02,  ...,  1.0088e-01,\n",
      "            5.7972e-02,  3.2357e-02],\n",
      "          [-0.0000e+00, -2.5088e-01, -8.5945e-02,  ...,  0.0000e+00,\n",
      "            2.5900e-02,  3.8687e-02],\n",
      "          [ 9.3489e-02, -6.9873e-01, -2.5477e-01,  ...,  8.4133e-02,\n",
      "            6.8331e-02,  2.1059e-01],\n",
      "          [ 2.6775e-02, -2.0558e-01, -9.3827e-02,  ...,  8.0960e-02,\n",
      "           -3.4837e-02,  4.7897e-02],\n",
      "          [ 1.3660e-02, -1.2086e-01, -2.3886e-02,  ...,  4.6585e-02,\n",
      "           -2.4437e-02,  4.7154e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 1.5597e-02, -1.8401e-02,  8.7960e-02,  ..., -1.0726e-01,\n",
      "            1.0707e-01, -8.4548e-02],\n",
      "          [-5.1465e-02, -6.9126e-03, -0.0000e+00,  ...,  1.3684e-01,\n",
      "            1.8362e-01,  1.6887e-01],\n",
      "          [-3.2584e-02,  5.5076e-02,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           -9.8728e-02,  3.1017e-01],\n",
      "          [-6.5401e-01, -1.4894e-01, -2.4179e-02,  ...,  1.7563e-01,\n",
      "            5.5523e-01,  2.9850e-01],\n",
      "          [ 1.0778e-01, -9.2856e-02,  1.0057e-01,  ...,  4.2139e-03,\n",
      "            3.3814e-02,  1.0226e-01]],\n",
      "\n",
      "         [[-1.9944e-02,  6.4019e-03, -0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  1.3492e-01],\n",
      "          [-0.0000e+00,  2.6733e-01,  0.0000e+00,  ..., -0.0000e+00,\n",
      "           -3.0912e-01, -1.2393e-01],\n",
      "          [-1.3917e-01, -5.0999e-03, -5.0543e-02,  ...,  2.3636e-01,\n",
      "           -0.0000e+00,  3.3494e-01],\n",
      "          [-2.7835e-02, -0.0000e+00,  0.0000e+00,  ..., -1.0439e-01,\n",
      "            1.6229e-02, -0.0000e+00],\n",
      "          [-1.0939e-01,  5.4002e-02, -2.0804e-02,  ..., -0.0000e+00,\n",
      "            2.6482e-02,  3.3604e-02]],\n",
      "\n",
      "         [[-0.0000e+00,  8.9483e-02,  3.7574e-02,  ...,  2.4962e-01,\n",
      "            1.6520e-01, -3.7579e-01],\n",
      "          [ 1.6550e-01, -3.6275e-01,  1.6682e-01,  ..., -1.4983e-02,\n",
      "           -0.0000e+00,  1.2630e-01],\n",
      "          [ 5.6886e-01,  1.1121e-02, -2.2424e-01,  ..., -1.8484e-01,\n",
      "            1.6488e-01,  6.9577e-02],\n",
      "          [-9.3056e-02, -1.7997e-01,  1.6477e-01,  ..., -8.8434e-02,\n",
      "            5.0843e-02,  5.6504e-02],\n",
      "          [ 0.0000e+00, -2.1225e-02,  0.0000e+00,  ...,  1.6312e-01,\n",
      "            8.2659e-02,  1.1526e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 4.4861e-01,  0.0000e+00,  0.0000e+00,  ..., -3.7333e-01,\n",
      "            7.8420e-03, -1.7230e-01],\n",
      "          [-7.2390e-03,  5.1541e-02,  3.5861e-01,  ...,  3.7658e-03,\n",
      "            7.3393e-03, -4.1465e-01],\n",
      "          [-2.6815e-01, -3.6666e-01, -1.5266e-01,  ..., -9.2251e-02,\n",
      "            6.8021e-02,  5.7291e-02],\n",
      "          [-3.1649e-02, -0.0000e+00, -1.0246e-02,  ...,  0.0000e+00,\n",
      "            1.9052e-01,  1.9074e-01],\n",
      "          [-9.1217e-02, -8.6767e-02,  1.5048e-01,  ..., -6.7312e-02,\n",
      "            4.4130e-02,  0.0000e+00]],\n",
      "\n",
      "         [[-1.4356e-01,  1.2265e-01,  1.6216e-01,  ..., -0.0000e+00,\n",
      "            0.0000e+00,  2.4604e-01],\n",
      "          [-4.0969e-01, -0.0000e+00, -0.0000e+00,  ...,  0.0000e+00,\n",
      "           -2.7141e-01,  0.0000e+00],\n",
      "          [-0.0000e+00, -6.1836e-02, -1.9824e-01,  ...,  1.2890e-01,\n",
      "            0.0000e+00,  3.0659e-01],\n",
      "          [-1.0469e-01, -0.0000e+00,  5.9087e-02,  ...,  0.0000e+00,\n",
      "            2.3640e-01, -0.0000e+00],\n",
      "          [ 7.9803e-02,  3.3086e-03, -2.1984e-02,  ..., -2.6694e-02,\n",
      "           -1.1028e-01, -1.3263e-01]],\n",
      "\n",
      "         [[ 9.0179e-02,  3.9304e-02,  2.8699e-01,  ...,  7.9661e-02,\n",
      "           -1.7321e-01,  0.0000e+00],\n",
      "          [-0.0000e+00,  6.2910e-02, -4.6825e-02,  ..., -3.4665e-01,\n",
      "            2.6597e-01, -7.7928e-02],\n",
      "          [-1.2550e-02, -1.4707e-01,  7.2287e-02,  ..., -1.2954e-01,\n",
      "            8.6237e-02,  6.6797e-02],\n",
      "          [-1.2764e-01,  1.2064e-01,  6.5011e-02,  ..., -1.8234e-01,\n",
      "           -2.2969e-01, -1.5521e-01],\n",
      "          [-0.0000e+00,  1.0956e-01, -0.0000e+00,  ...,  1.5813e-01,\n",
      "            2.0001e-02, -1.6178e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 9.0178e-03, -2.7113e-01,  3.2200e-01,  ...,  2.7226e-01,\n",
      "            1.3328e-01, -1.8901e-02],\n",
      "          [-0.0000e+00,  0.0000e+00, -6.8564e-01,  ...,  3.3255e-01,\n",
      "            0.0000e+00,  1.8512e-01],\n",
      "          [-3.0922e-01,  1.1467e-02,  1.8211e-01,  ...,  9.0313e-02,\n",
      "           -2.4163e-01, -1.0733e-01],\n",
      "          [-1.3191e-01, -1.6591e-01,  1.1634e-01,  ...,  1.1356e-01,\n",
      "            1.9620e-01,  2.0265e-01],\n",
      "          [ 1.5602e-01,  2.2673e-02, -0.0000e+00,  ...,  4.4134e-02,\n",
      "            1.0998e-01,  1.2474e-01]],\n",
      "\n",
      "         [[ 9.7134e-02, -2.0009e-01,  6.5140e-02,  ...,  4.5133e-02,\n",
      "           -9.3308e-02,  1.6185e-01],\n",
      "          [-6.3530e-02,  0.0000e+00, -4.1782e-02,  ...,  2.0090e-01,\n",
      "           -0.0000e+00,  2.1736e-01],\n",
      "          [ 4.8916e-02, -0.0000e+00, -3.8002e-01,  ...,  2.9491e-01,\n",
      "            8.4085e-03,  2.1730e-01],\n",
      "          [ 1.5090e-01,  1.1326e-01,  2.6368e-03,  ...,  9.3104e-02,\n",
      "            2.5575e-01, -6.9583e-02],\n",
      "          [ 0.0000e+00,  1.0081e-02, -8.1021e-02,  ..., -2.5862e-01,\n",
      "           -7.9280e-02, -1.1455e-01]],\n",
      "\n",
      "         [[ 4.7951e-02, -4.0815e-01, -2.8154e-01,  ...,  2.1156e-01,\n",
      "           -2.0404e-01, -1.8213e-01],\n",
      "          [ 1.2288e-01, -1.1161e-01, -7.4438e-02,  ...,  3.5999e-01,\n",
      "            2.8974e-02, -2.6116e-01],\n",
      "          [-1.5827e-01,  9.2709e-02, -2.5480e-02,  ...,  2.8626e-01,\n",
      "            2.2225e-01,  2.8854e-01],\n",
      "          [-0.0000e+00,  1.5319e-02,  4.3808e-02,  ...,  1.5484e-02,\n",
      "            0.0000e+00,  2.2493e-02],\n",
      "          [-1.4451e-03, -7.9524e-02,  1.2799e-01,  ...,  5.3448e-02,\n",
      "            8.6330e-02,  1.9310e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 9.3951e-02, -1.9338e-01, -1.1255e-01,  ...,  1.2936e-01,\n",
      "            7.4337e-02,  0.0000e+00],\n",
      "          [-5.2228e-03, -0.0000e+00, -0.0000e+00,  ...,  1.0961e-01,\n",
      "            0.0000e+00,  5.1922e-02],\n",
      "          [ 3.9321e-02, -3.0191e-01, -1.3779e-01,  ...,  0.0000e+00,\n",
      "           -5.1161e-02,  0.0000e+00],\n",
      "          [ 4.1127e-02, -3.0738e-01, -1.1207e-01,  ...,  3.7011e-02,\n",
      "            3.0059e-02,  9.2642e-02],\n",
      "          [ 2.2808e-02, -2.0181e-01, -3.9882e-02,  ...,  0.0000e+00,\n",
      "           -4.0803e-02,  7.8734e-02]],\n",
      "\n",
      "         [[ 6.4092e-02, -1.3192e-01, -7.6782e-02,  ...,  8.8248e-02,\n",
      "            5.0711e-02,  2.8304e-02],\n",
      "          [-0.0000e+00, -2.9423e-01, -1.0079e-01,  ...,  0.0000e+00,\n",
      "            3.0374e-02,  4.5371e-02],\n",
      "          [ 3.4925e-02, -2.6815e-01, -1.2239e-01,  ...,  1.0560e-01,\n",
      "           -4.5440e-02,  6.2476e-02],\n",
      "          [ 7.8506e-02, -5.8675e-01, -2.1394e-01,  ...,  7.0650e-02,\n",
      "            5.7380e-02,  1.7684e-01],\n",
      "          [ 1.4823e-02, -1.3116e-01, -2.5920e-02,  ...,  5.0552e-02,\n",
      "           -2.6518e-02,  5.1170e-02]],\n",
      "\n",
      "         [[-0.0000e+00, -1.5805e-01, -5.4142e-02,  ...,  5.1450e-02,\n",
      "            1.6316e-02,  2.4371e-02],\n",
      "          [ 1.3213e-01, -2.7196e-01, -1.5829e-01,  ...,  0.0000e+00,\n",
      "            1.0454e-01,  5.8349e-02],\n",
      "          [ 7.9377e-02, -5.9326e-01, -0.0000e+00,  ...,  7.1433e-02,\n",
      "            5.8017e-02,  1.7881e-01],\n",
      "          [ 2.9652e-02, -2.6236e-01, -5.1849e-02,  ...,  1.0112e-01,\n",
      "           -5.3046e-02,  1.0236e-01],\n",
      "          [ 1.2212e-02, -9.3762e-02, -4.2793e-02,  ...,  0.0000e+00,\n",
      "           -1.5889e-02,  2.1845e-02]]],\n",
      "\n",
      "\n",
      "        [[[-5.0700e-02,  3.4274e-02, -2.3247e-02,  ...,  9.6603e-02,\n",
      "            1.9565e-01,  2.4595e-01],\n",
      "          [-1.7848e-01, -2.0591e-01,  7.9978e-02,  ...,  1.7302e-03,\n",
      "            3.2163e-01,  1.3191e-01],\n",
      "          [-4.5132e-02,  1.6038e-02,  0.0000e+00,  ...,  3.0045e-02,\n",
      "            3.9392e-01,  1.4360e-01],\n",
      "          [ 0.0000e+00, -0.0000e+00, -2.1858e-01,  ...,  9.6235e-02,\n",
      "            5.0011e-02, -1.6962e-01],\n",
      "          [-0.0000e+00,  5.3169e-02, -1.5986e-02,  ...,  0.0000e+00,\n",
      "           -9.1984e-02, -9.9400e-02]],\n",
      "\n",
      "         [[-1.2787e-01, -5.6059e-02,  2.5442e-01,  ...,  0.0000e+00,\n",
      "           -1.4003e-01, -3.3158e-01],\n",
      "          [ 0.0000e+00,  1.7670e-01, -1.9964e-02,  ...,  2.6680e-01,\n",
      "            2.9862e-01,  0.0000e+00],\n",
      "          [-2.0457e-01, -1.8463e-01, -1.8654e-01,  ..., -1.7543e-01,\n",
      "            1.9556e-04, -4.9224e-02],\n",
      "          [-1.4125e-01, -3.1750e-02, -1.5685e-01,  ...,  1.0843e-01,\n",
      "            1.4637e-01,  2.2395e-01],\n",
      "          [-1.0244e-01,  0.0000e+00, -7.1904e-02,  ...,  1.9580e-01,\n",
      "           -0.0000e+00,  1.9152e-01]],\n",
      "\n",
      "         [[ 0.0000e+00,  3.8158e-03,  0.0000e+00,  ...,  1.1240e-01,\n",
      "           -2.9934e-02,  1.5688e-01],\n",
      "          [ 3.4041e-01,  3.1954e-01,  2.5124e-02,  ...,  5.0762e-02,\n",
      "           -1.9024e-02,  2.6795e-01],\n",
      "          [ 4.1248e-02,  9.1964e-02,  2.6117e-02,  ...,  1.2479e-01,\n",
      "            8.7879e-04,  3.2353e-01],\n",
      "          [-2.5926e-01, -0.0000e+00,  1.7567e-03,  ...,  9.1202e-02,\n",
      "           -4.2194e-02, -9.4718e-02],\n",
      "          [ 3.2324e-02,  1.5841e-01, -0.0000e+00,  ..., -1.2400e-02,\n",
      "           -0.0000e+00, -9.1331e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 5.3943e-02, -1.1103e-01, -6.4624e-02,  ...,  7.4274e-02,\n",
      "            4.2681e-02,  2.3822e-02],\n",
      "          [-6.9975e-03, -4.5113e-01, -1.5454e-01,  ...,  0.0000e+00,\n",
      "            4.6572e-02,  6.9565e-02],\n",
      "          [ 3.1052e-02, -2.3842e-01, -1.0881e-01,  ...,  9.3890e-02,\n",
      "           -0.0000e+00,  5.5547e-02],\n",
      "          [ 6.0011e-02, -4.4852e-01, -1.6354e-01,  ...,  5.4006e-02,\n",
      "            0.0000e+00,  1.3518e-01],\n",
      "          [ 1.3281e-02, -1.1751e-01, -2.3223e-02,  ...,  4.5294e-02,\n",
      "           -2.3759e-02,  4.5847e-02]],\n",
      "\n",
      "         [[ 3.6475e-02, -0.0000e+00, -1.2782e-01,  ...,  1.1029e-01,\n",
      "           -0.0000e+00,  6.5249e-02],\n",
      "          [ 5.3876e-02, -4.0267e-01, -1.4682e-01,  ...,  4.8485e-02,\n",
      "            3.9378e-02,  1.2136e-01],\n",
      "          [ 4.7340e-02, -0.0000e+00, -8.2778e-02,  ...,  1.6145e-01,\n",
      "           -8.4689e-02,  1.6342e-01],\n",
      "          [ 8.6382e-02, -1.7780e-01, -1.0349e-01,  ...,  0.0000e+00,\n",
      "            6.8348e-02,  0.0000e+00],\n",
      "          [-1.9609e-03, -1.2642e-01, -4.3307e-02,  ...,  4.1154e-02,\n",
      "            1.3051e-02,  1.9494e-02]],\n",
      "\n",
      "         [[-4.3014e-03, -2.7731e-01, -9.4998e-02,  ...,  0.0000e+00,\n",
      "            2.8628e-02,  0.0000e+00],\n",
      "          [ 1.3174e-01, -0.0000e+00, -1.5783e-01,  ...,  1.8140e-01,\n",
      "            1.0424e-01,  5.8181e-02],\n",
      "          [ 4.8508e-02, -0.0000e+00, -1.6999e-01,  ...,  0.0000e+00,\n",
      "           -6.3114e-02,  0.0000e+00],\n",
      "          [ 4.2948e-02, -3.2099e-01, -1.1704e-01,  ...,  3.8650e-02,\n",
      "            3.1391e-02,  9.6745e-02],\n",
      "          [ 9.5835e-03, -8.4795e-02, -1.6757e-02,  ...,  3.2683e-02,\n",
      "           -0.0000e+00,  3.3082e-02]]],\n",
      "\n",
      "\n",
      "        [[[-6.6880e-02, -0.0000e+00,  2.6893e-03,  ...,  7.5231e-02,\n",
      "           -0.0000e+00,  1.4141e-01],\n",
      "          [-1.5492e-01,  0.0000e+00,  2.8136e-02,  ..., -2.0595e-01,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 2.6922e-01,  1.6263e-01, -9.2918e-02,  ..., -0.0000e+00,\n",
      "            1.6585e-01, -2.0519e-01],\n",
      "          [ 2.2108e-01, -0.0000e+00, -2.1983e-01,  ...,  4.2357e-03,\n",
      "            1.4444e-01, -6.3857e-02],\n",
      "          [ 0.0000e+00, -0.0000e+00,  6.0841e-04,  ...,  7.5839e-02,\n",
      "            7.4984e-02,  7.7357e-02]],\n",
      "\n",
      "         [[-9.5851e-02, -0.0000e+00,  2.8003e-02,  ...,  1.5701e-02,\n",
      "            2.4027e-01, -2.7056e-01],\n",
      "          [ 0.0000e+00, -6.4096e-02,  6.0711e-02,  ..., -3.5215e-02,\n",
      "            1.2312e-01,  1.6109e-01],\n",
      "          [-6.3747e-01,  7.2015e-02,  0.0000e+00,  ...,  6.6887e-01,\n",
      "            3.2607e-01,  5.7912e-01],\n",
      "          [ 5.7336e-02,  2.3789e-02, -0.0000e+00,  ...,  1.3191e-01,\n",
      "            2.2320e-02,  1.1822e-01],\n",
      "          [ 3.7131e-02,  0.0000e+00, -3.6151e-02,  ..., -7.1774e-02,\n",
      "            2.5778e-02,  0.0000e+00]],\n",
      "\n",
      "         [[ 2.6207e-01,  1.3239e-01, -3.1364e-02,  ..., -1.4551e-01,\n",
      "            2.9545e-02,  5.6738e-02],\n",
      "          [ 1.1359e-01, -0.0000e+00, -1.3781e-01,  ..., -1.5862e-01,\n",
      "           -2.2821e-01,  8.1749e-02],\n",
      "          [ 0.0000e+00,  5.3738e-02,  1.4706e-02,  ..., -3.0096e-01,\n",
      "           -0.0000e+00,  7.8921e-02],\n",
      "          [-3.3387e-01,  2.3738e-01, -2.3908e-01,  ...,  1.1054e-01,\n",
      "            2.3172e-01, -3.1010e-02],\n",
      "          [-0.0000e+00,  1.3010e-01, -9.2006e-03,  ...,  1.0074e-01,\n",
      "            0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 7.3334e-02, -1.5095e-01, -8.7855e-02,  ...,  0.0000e+00,\n",
      "            5.8024e-02,  3.2386e-02],\n",
      "          [-3.0573e-03, -1.9710e-01, -6.7521e-02,  ...,  6.4164e-02,\n",
      "            2.0348e-02,  3.0394e-02],\n",
      "          [ 7.4303e-02, -5.7050e-01, -2.6038e-01,  ...,  0.0000e+00,\n",
      "           -9.6674e-02,  1.3292e-01],\n",
      "          [ 0.0000e+00, -2.7984e-01, -1.0204e-01,  ...,  3.3696e-02,\n",
      "            2.7367e-02,  0.0000e+00],\n",
      "          [ 2.2230e-02, -1.9669e-01, -0.0000e+00,  ...,  7.5813e-02,\n",
      "           -3.9768e-02,  7.6738e-02]],\n",
      "\n",
      "         [[ 0.0000e+00, -1.4853e-01, -0.0000e+00,  ...,  9.9356e-02,\n",
      "            0.0000e+00,  3.1867e-02],\n",
      "          [-0.0000e+00, -0.0000e+00, -1.0772e-01,  ...,  1.0236e-01,\n",
      "            3.2462e-02,  0.0000e+00],\n",
      "          [ 4.1388e-02, -3.1778e-01, -1.4503e-01,  ...,  1.2514e-01,\n",
      "           -5.3850e-02,  7.4038e-02],\n",
      "          [ 4.6594e-02, -4.1227e-01, -0.0000e+00,  ...,  1.5890e-01,\n",
      "           -0.0000e+00,  0.0000e+00],\n",
      "          [ 2.0187e-02, -1.5087e-01, -5.5011e-02,  ...,  1.8167e-02,\n",
      "            1.4754e-02,  4.5473e-02]],\n",
      "\n",
      "         [[ 9.3954e-02, -1.9339e-01, -1.1256e-01,  ...,  1.2937e-01,\n",
      "            7.4339e-02,  4.1492e-02],\n",
      "          [-3.7291e-03, -0.0000e+00, -8.2357e-02,  ...,  7.8263e-02,\n",
      "            0.0000e+00,  3.7072e-02],\n",
      "          [ 6.2996e-02, -4.7082e-01, -1.7167e-01,  ...,  5.6691e-02,\n",
      "            4.6043e-02,  1.4190e-01],\n",
      "          [ 3.1730e-02, -0.0000e+00, -5.5483e-02,  ...,  1.0821e-01,\n",
      "           -5.6763e-02,  1.0953e-01],\n",
      "          [ 2.5425e-02, -1.9521e-01, -0.0000e+00,  ...,  0.0000e+00,\n",
      "           -3.3080e-02,  4.5481e-02]]]], grad_fn=<MulBackward0>) tensor([[[1, 1, 1, 1, 1],\n",
      "         [1, 1, 1, 1, 1],\n",
      "         [1, 1, 1, 1, 1],\n",
      "         ...,\n",
      "         [0, 0, 0, 0, 0],\n",
      "         [0, 0, 0, 0, 0],\n",
      "         [0, 0, 0, 0, 0]],\n",
      "\n",
      "        [[1, 1, 1, 1, 1],\n",
      "         [1, 1, 1, 1, 1],\n",
      "         [1, 1, 1, 1, 1],\n",
      "         ...,\n",
      "         [1, 1, 1, 1, 1],\n",
      "         [1, 1, 1, 1, 1],\n",
      "         [1, 1, 1, 1, 1]],\n",
      "\n",
      "        [[1, 1, 1, 1, 1],\n",
      "         [1, 1, 1, 1, 1],\n",
      "         [1, 1, 1, 1, 1],\n",
      "         ...,\n",
      "         [0, 0, 0, 0, 0],\n",
      "         [0, 0, 0, 0, 0],\n",
      "         [0, 0, 0, 0, 0]],\n",
      "\n",
      "        [[1, 1, 1, 1, 1],\n",
      "         [1, 1, 1, 1, 1],\n",
      "         [1, 1, 1, 1, 1],\n",
      "         ...,\n",
      "         [0, 0, 0, 0, 0],\n",
      "         [0, 0, 0, 0, 0],\n",
      "         [0, 0, 0, 0, 0]],\n",
      "\n",
      "        [[1, 1, 1, 1, 1],\n",
      "         [1, 1, 1, 1, 1],\n",
      "         [1, 1, 1, 1, 1],\n",
      "         ...,\n",
      "         [0, 0, 0, 0, 0],\n",
      "         [0, 0, 0, 0, 0],\n",
      "         [0, 0, 0, 0, 0]]])\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(tensor([[-0.1970, -1.9182, -5.6736, -4.7352, -3.9270],\n",
       "         [-1.4232, -1.6907, -1.0101, -1.7027, -3.5647],\n",
       "         [-3.5522, -1.8727, -2.6749, -0.3170, -3.8924],\n",
       "         [-0.8469, -1.1921, -1.5415, -2.9597, -6.3218],\n",
       "         [-2.1022, -4.6903, -6.2862, -0.7599, -0.9186]],\n",
       "        grad_fn=<LogSoftmaxBackward>),\n",
       " tensor([[[ 7,  5, 21, 29,  1],\n",
       "          [28, 47,  6, 19, 16],\n",
       "          [ 7, 64, 49, 55, 16],\n",
       "          ...,\n",
       "          [ 0,  1,  4,  2,  3],\n",
       "          [ 0,  1,  2,  4,  3],\n",
       "          [ 0,  1,  4,  2,  3]],\n",
       " \n",
       "         [[37,  7, 10, 26, 20],\n",
       "          [40, 14,  7, 23, 81],\n",
       "          [ 5, 47, 10, 17,  8],\n",
       "          ...,\n",
       "          [75, 63, 45, 32, 14],\n",
       "          [22, 20, 50, 47, 49],\n",
       "          [35, 28, 19, 34, 20]],\n",
       " \n",
       "         [[64,  0, 11, 26, 34],\n",
       "          [26,  8, 25, 10, 22],\n",
       "          [ 6,  0,  2, 37,  7],\n",
       "          ...,\n",
       "          [ 0,  1,  2,  4,  3],\n",
       "          [ 0,  1,  2,  4,  3],\n",
       "          [ 1,  0,  4,  3,  2]],\n",
       " \n",
       "         [[ 5, 10,  0,  7, 14],\n",
       "          [25,  0,  4, 20, 18],\n",
       "          [21, 49,  8,  5, 13],\n",
       "          ...,\n",
       "          [ 0,  1,  2,  4,  3],\n",
       "          [ 2,  4,  3,  0,  1],\n",
       "          [ 1,  0,  2,  4,  3]],\n",
       " \n",
       "         [[ 6,  8, 24,  0,  3],\n",
       "          [ 6,  7, 16,  3,  1],\n",
       "          [ 0, 34, 32,  3, 28],\n",
       "          ...,\n",
       "          [ 0,  1,  2,  4,  3],\n",
       "          [ 0,  1,  2,  3,  4],\n",
       "          [ 0,  1,  4,  3,  2]]]))"
      ]
     },
     "metadata": {},
     "execution_count": 39
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "embedding = BERT_Embedding(manager)\n",
    "\n",
    "encoderN = CNN_Encoder(manager)\n",
    "# encoderN = RNN_Encoder(manager)\n",
    "# encoderN = MHA_Encoder(manager)\n",
    "\n",
    "# encoderU = CNN_User_Encoder(manager)\n",
    "encoderU = RNN_User_Encoder(manager)\n",
    "# encoderU = MHA_User_Encoder(manager)\n",
    "\n",
    "reducer = Matching_Reducer(manager)\n",
    "# reducer = BM25_Reducer(manager)\n",
    "\n",
    "# ranker = CNN_Ranker(manager)\n",
    "# ranker = BERT_Onepass_Ranker(manager)\n",
    "# ranker = BERT_Original_Ranker(manager)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.11",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.11 64-bit (conda)"
  },
  "interpreter": {
   "hash": "decb58d8582e8bebc2c9af4e5243ce054f2f8013c5b7e79ffbf7b8b9f3c0761b"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}