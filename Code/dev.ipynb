{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "import re\n",
    "import logging\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "import time\n",
    "import pickle\n",
    "# from thop import profile\n",
    "from collections import defaultdict\n",
    "from data.configs.demo import config\n",
    "from collections import defaultdict\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModel, BertModel, BertConfig, AutoModelForSequenceClassification\n",
    "from utils.Manager import Manager\n",
    "\n",
    "from models.Embeddings.BERT import BERT_Embedding\n",
    "from models.Encoders.CNN import CNN_Encoder,CNN_User_Encoder\n",
    "from models.Encoders.RNN import RNN_Encoder,RNN_User_Encoder\n",
    "from models.Encoders.MHA import MHA_Encoder, MHA_User_Encoder\n",
    "from models.Modules.DRM import Matching_Reducer, Identical_Reducer\n",
    "from models.Rankers.BERT import BERT_Onepass_Ranker, BERT_Original_Ranker\n",
    "from models.Rankers.CNN import CNN_Ranker\n",
    "from models.Encoders.Pooling import Attention_Pooling, Average_Pooling\n",
    "from models.UniLM.modeling import TuringNLRv3Model, TuringNLRv3ForSequenceClassification, relative_position_bucket\n",
    "from models.UniLM.configuration_tnlrv3 import TuringNLRv3Config\n",
    "\n",
    "from models.TwoTowerBaseModel import TwoTowerBaseModel\n",
    "\n",
    "from models.Encoders.BERT import BERT_Encoder\n",
    "from models.Encoders.Pooling import *\n",
    "\n",
    "from models.TESRec import TESRec\n",
    "from models.XFormer import XFormer\n",
    " \n",
    "from models.Modules.Attention import MultiheadAttention, get_attn_mask, XSoftmax\n",
    "torch.set_printoptions(threshold=100000)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "with open(\"data/recall/inverted_index_bm25.pkl\", \"rb\") as f:\n",
    "                    inverted_index = pickle.load(f)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "source": [
    "[[]] * 10"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[[], [], [], [], [], [], [], [], [], []]"
      ]
     },
     "metadata": {},
     "execution_count": 28
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "source": [
    "len(t.vocab)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "30522"
      ]
     },
     "metadata": {},
     "execution_count": 27
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "source": [
    "72000 * 768 - (30000 * 100 * 2)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "49296000"
      ]
     },
     "metadata": {},
     "execution_count": 23
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "source": [
    "# m = AutoModel.from_pretrained('bert-base-uncased',cache_dir=config.path + 'bert_cache/')\n",
    "# m2 = AutoModel.from_pretrained('microsoft/deberta-base',cache_dir=config.path + 'bert_cache/')\n",
    "# m3 = TuringNLRv3ForSequenceClassification.from_pretrained(config.unilm_path, config=TuringNLRv3Config.from_pretrained(config.unilm_config_path))\n",
    "\n",
    "t = AutoTokenizer.from_pretrained('bert-base-uncased', cache_dir=config.path + \"bert_cache/\")\n",
    "# t2 = AutoTokenizer.from_pretrained('microsoft/deberta-base', cache_dir=config.path + \"bert_cache/\")\n",
    "# t3 = AutoTokenizer.from_pretrained('allenai/longformer-base-4096', cache_dir=config.path + \"bert_cache/\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# config.reducer = 'entity'\n",
    "# config.embedding = 'deberta'\n",
    "# config.bert = 'longformer'\n",
    "# config.seed = None\n",
    "config.mode = \"recall\"\n",
    "config.recall_type = \"s\"\n",
    "config.scale = \"large\"\n",
    "config.case = False\n",
    "\n",
    "manager = Manager(config)\n",
    "\n",
    "loaders = manager.prepare()\n",
    "X1 = list(loaders[0])\n",
    "# X2 = list(loaders[1])\n",
    "x1 = X1[0]\n",
    "# x2 = X2[0]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "embedding = BERT_Embedding(manager)\n",
    "\n",
    "encoderN = CNN_Encoder(manager)\n",
    "# encoderN = RNN_Encoder(manager)\n",
    "# encoderN = MHA_Encoder(manager)\n",
    "\n",
    "# encoderU = CNN_User_Encoder(manager)\n",
    "encoderU = RNN_User_Encoder(manager)\n",
    "# encoderU = MHA_User_Encoder(manager)\n",
    "# encoderU = Attention_Pooling(manager)\n",
    "# encoderU = Average_Pooling(manager)\n",
    "\n",
    "reducer = Matching_Reducer(manager)\n",
    "# reducer = Identical_Reducer(manager)\n",
    "\n",
    "# ranker = CNN_Ranker(manager)\n",
    "# ranker = BERT_Onepass_Ranker(manager)\n",
    "# ranker = BERT_Original_Ranker(manager)\n",
    "\n",
    "model = TESRec(manager, embedding, encoderN, encoderU, reducer).to(manager.device)\n",
    "# model = ESM(manager, embedding, encoderN, encoderU, reducer, ranker).to(manager.device)\n",
    "# model = XFormer(manager).to(manager.device)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "manager.load(model, 230000)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "a,b,c,d,e = model.encode_user(x1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "np.asarray(t.convert_ids_to_tokens(x1['his_encoded_index'][0,0])[1:])[[86,2,93]]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "e[0,3,35], e.shape"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "t.convert_ids_to_tokens(x1['his_encoded_index'][0,3,[36]])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(t.convert_ids_to_tokens(x1['his_encoded_index'][0,3]))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "e[0,3], e.shape, e.topk(dim=-1, k=3)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "recall = 0\n",
    "count = 0\n",
    "for x in tqdm(loaders[0], ncols=120, leave=True):\n",
    "    kid = model.encode_user(x)[1]\n",
    "    ps_terms = x['his_encoded_index'][:, :, 1:].to(manager.device).gather(index=kid, dim=-1).view(-1).tolist()\n",
    "    "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "embedding = 32*50*2*100*768\n",
    "ext_encoding = 32*50*(2*3*384*100 + 4*100*384) + 32*8*2*384*384*50\n",
    "reduction = (2*100*768 + 100*math.log2(100))*32*50*2+32*50*3\n",
    "bert_embedding = 32*150*768*2\n",
    "bert_project = 32*150*768*2*3\n",
    "bert_attn = 32*150*12*64*64*2 + 32*150*12*12*64*2\n",
    "bert_intm = 32*150*768*768*2 + 32*150*768*2 + 32*150*768*3072*4\n",
    "bert_pool = 32*150*768*4\n",
    "bert = (bert_project + bert_attn + bert_intm) * 12 + bert_pool\n",
    "\n",
    "total_isrec = embedding + ext_encoding + reduction + bert\n",
    "\n",
    "embedding = 32*50*2*100*768 + 32*50*100*768*2\n",
    "bert_project = 32*5000*768*2*3\n",
    "bert_attn = 32*5000*12*64*64*2 + 32*5000*12*12*64*2\n",
    "bert_intm = 32*5000*768*768*2 + 32*5000*768*2 + 32*5000*768*3072*4\n",
    "bert_pool = 32*5000*768*4\n",
    "bert = (bert_project + bert_attn + bert_intm) * 12 + bert_pool\n",
    "\n",
    "total =  embedding + bert + 32*8*2*768*768*50\n",
    "\n",
    "total_isrec, total"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.11",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.12 64-bit"
  },
  "interpreter": {
   "hash": "0f43efc2da5f33d61ae1bd929e6c7df9dd2aa7f250aadb5586d31de3e27bb6a5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}