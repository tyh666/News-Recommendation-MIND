{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "import re\n",
    "import logging\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "import pickle\n",
    "from collections import defaultdict\n",
    "from utils.utils import prepare, convert_tokens_to_words\n",
    "from data.configs.demo import config\n",
    "from collections import defaultdict\n",
    "from transformers import BertTokenizer,BertModel\n",
    "from utils.Manager import Manager\n",
    "\n",
    "from models.Embeddings.BERT import BERT_Embedding\n",
    "from models.Encoders.CNN import CNN_Encoder,CNN_User_Encoder\n",
    "from models.Encoders.RNN import RNN_Encoder,RNN_User_Encoder\n",
    "from models.Encoders.MHA import MHA_Encoder, MHA_User_Encoder\n",
    "from models.Modules.DRM import Matching_Reducer, BM25_Reducer\n",
    "from models.Rankers.BERT import BERT_Onepass_Ranker, BERT_Original_Ranker\n",
    "from models.Rankers.CNN import CNN_Ranker\n",
    "\n",
    "from models.Encoders.BERT import BERT_Encoder\n",
    "from models.Encoders.Pooling import *\n",
    "\n",
    "from models.ESM import ESM\n",
    "from models.TTMS import TTMS\n",
    "\n",
    "from models.Modules.Attention import MultiheadAttention"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "# config.reducer = 'bm25'\n",
    "manager = Manager(config)\n",
    "loaders = prepare(manager)\n",
    "\n",
    "record = list(loaders[1])[0]"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[2021-08-31 23:12:03,957] INFO (utils.utils) Hyper Parameters are \n",
      "scale:demo\n",
      "batch_size:5\n",
      "k:5\n",
      "threshold:-inf\n",
      "signal_length:100\n",
      "his_size:50\n",
      "impr_size:10\n",
      "lr:0.0001\n",
      "bert_lr:3e-05\n",
      "hidden_dim:384\n",
      "world_size:0\n",
      "step:0\n",
      "ascend_history:False\n",
      "no_dedup:False\n",
      "diversify:False\n",
      "granularity:avg\n",
      "[2021-08-31 23:12:03,959] INFO (utils.utils) preparing dataset...\n",
      "[2021-08-31 23:12:03,964] INFO (utils.MIND) process NO.0 loading cached user behavior from data/cache/bert/MINDdemo_train/10/behaviors..pkl\n",
      "[2021-08-31 23:12:03,979] INFO (utils.MIND) process NO.0 loading cached news tokenization from data/cache/bert/MINDdemo_train/news.pkl\n",
      "[2021-08-31 23:12:04,751] INFO (utils.MIND) reducing news of ../../../Data/MIND/MINDdemo_train/news.tsv...\n",
      "[2021-08-31 23:12:04,908] INFO (utils.utils) deduplicating...\n",
      "[2021-08-31 23:12:06,264] INFO (utils.MIND) process NO.0 loading cached user behavior from data/cache/bert/MINDdemo_dev/10/behaviors..pkl\n",
      "[2021-08-31 23:12:06,267] INFO (utils.MIND) process NO.0 loading cached news tokenization from data/cache/bert/MINDdemo_dev/news.pkl\n",
      "[2021-08-31 23:12:06,875] INFO (utils.MIND) reducing news of ../../../Data/MIND/MINDdemo_dev/news.tsv...\n",
      "[2021-08-31 23:12:07,006] INFO (utils.utils) deduplicating...\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "class TTMS(nn.Module):\n",
    "    def __init__(self, config, embedding, encoderN, encoderU, reducer, aggregator=None):\n",
    "        super().__init__()\n",
    "\n",
    "        self.scale = config.scale\n",
    "        self.cdd_size = config.cdd_size\n",
    "        self.batch_size = config.batch_size\n",
    "        self.his_size = config.his_size\n",
    "        self.signal_length = config.signal_length\n",
    "        self.device = config.device\n",
    "\n",
    "        self.embedding = embedding\n",
    "        self.encoderN = encoderN\n",
    "        self.encoderU = encoderU\n",
    "\n",
    "        self.reducer = reducer\n",
    "        self.bert = BERT_Encoder(config)\n",
    "\n",
    "        self.aggregator = aggregator\n",
    "\n",
    "        self.granularity = config.granularity\n",
    "        if self.granularity != 'token':\n",
    "            self.register_buffer('cdd_dest', torch.zeros((self.batch_size, config.impr_size, config.signal_length * config.signal_length)), persistent=False)\n",
    "            if self.reducer.name != 'bm25':\n",
    "                self.register_buffer('his_dest', torch.zeros((self.batch_size, self.his_size, config.signal_length * config.signal_length)), persistent=False)\n",
    "            else:\n",
    "                self.register_buffer('his_dest', torch.zeros((self.batch_size, self.his_size, (config.k + 1) * (config.k + 1))), persistent=False)\n",
    "\n",
    "        if not aggregator:\n",
    "            self.userProject = nn.Sequential(\n",
    "                nn.Linear(self.bert.hidden_dim, self.bert.hidden_dim),\n",
    "                nn.Tanh()\n",
    "            )\n",
    "\n",
    "        self.name = '__'.join(['ttms', self.encoderN.name, self.encoderU.name, config.reducer])\n",
    "        config.name = self.name\n",
    "\n",
    "    def clickPredictor(self, cdd_news_repr, user_repr):\n",
    "        \"\"\" calculate batch of click probabolity\n",
    "\n",
    "        Args:\n",
    "            cdd_news_repr: news-level representation, [batch_size, cdd_size, hidden_dim]\n",
    "            user_repr: user representation, [batch_size, 1, hidden_dim]\n",
    "\n",
    "        Returns:\n",
    "            score of each candidate news, [batch_size, cdd_size]\n",
    "        \"\"\"\n",
    "        # print(user_repr.mean(), cdd_news_repr.mean(), user_repr.max(), cdd_news_repr.max(), user_repr.sum(), cdd_news_repr.sum())\n",
    "        score = cdd_news_repr.matmul(user_repr.transpose(-2,-1)).squeeze(-1)\n",
    "        return score\n",
    "\n",
    "    def _forward(self,x):\n",
    "        if self.granularity != 'token':\n",
    "            batch_size = x['cdd_subword_index'].size(0)\n",
    "            cdd_size = x['cdd_subword_index'].size(1)\n",
    "\n",
    "            if self.training:\n",
    "                if batch_size != self.batch_size:\n",
    "                    cdd_dest = self.cdd_dest[:batch_size, :cdd_size]\n",
    "                    his_dest = self.his_dest[:batch_size]\n",
    "                else:\n",
    "                    cdd_dest = self.cdd_dest[:, :cdd_size]\n",
    "                    his_dest = self.his_dest\n",
    "\n",
    "            # batch_size always equals 1 when evaluating\n",
    "            else:\n",
    "                cdd_dest = self.cdd_dest[[0], :cdd_size]\n",
    "                his_dest = self.his_dest[[0]]\n",
    "\n",
    "            cdd_subword_index = x['cdd_subword_index'].to(self.device)\n",
    "            his_subword_index = x['his_subword_index'].to(self.device)\n",
    "            his_signal_length = his_subword_index.size(-2)\n",
    "            cdd_subword_index = cdd_subword_index[:, :, :, 0] * self.signal_length + cdd_subword_index[:, :, :, 1]\n",
    "            his_subword_index = his_subword_index[:, :, :, 0] * his_signal_length + his_subword_index[:, :, :, 1]\n",
    "\n",
    "            if self.training:\n",
    "                cdd_subword_prefix = cdd_dest.scatter(dim=-1, index=cdd_subword_index, value=1) * x[\"cdd_mask\"].to(self.device)\n",
    "            else:\n",
    "                cdd_subword_prefix = cdd_dest.scatter(dim=-1, index=cdd_subword_index, value=1)\n",
    "            cdd_subword_prefix = cdd_subword_prefix.view(batch_size, cdd_size, self.signal_length, self.signal_length)\n",
    "\n",
    "            his_subword_prefix = his_dest.scatter(dim=-1, index=his_subword_index, value=1) * x[\"his_mask\"].to(self.device)\n",
    "            his_subword_prefix = his_subword_prefix.view(batch_size, self.his_size, his_signal_length, his_signal_length)\n",
    "\n",
    "            if self.granularity == 'avg':\n",
    "                # average subword embeddings as the word embedding\n",
    "                cdd_subword_prefix = F.normalize(cdd_subword_prefix, p=1, dim=-1)\n",
    "                his_subword_prefix = F.normalize(his_subword_prefix, p=1, dim=-1)\n",
    "\n",
    "            cdd_attn_mask = cdd_subword_prefix.matmul(x['cdd_attn_mask'].to(self.device).float().unsqueeze(-1)).squeeze(-1)\n",
    "            his_attn_mask = his_subword_prefix.matmul(x[\"his_attn_mask\"].to(self.device).float().unsqueeze(-1)).squeeze(-1)\n",
    "            his_refined_mask = None\n",
    "            if 'his_refined_mask' in x:\n",
    "                his_refined_mask = his_subword_prefix.matmul(x[\"his_refined_mask\"].to(self.device).float().unsqueeze(-1)).squeeze(-1)\n",
    "\n",
    "        else:\n",
    "            cdd_subword_prefix = None\n",
    "            his_subword_prefix = None\n",
    "            cdd_attn_mask = x['cdd_attn_mask'].to(self.device)\n",
    "            his_attn_mask = x[\"his_attn_mask\"].to(self.device)\n",
    "            his_refined_mask = None\n",
    "            if 'his_refined_mask' in x:\n",
    "                his_refined_mask = x[\"his_refined_mask\"].to(self.device)\n",
    "\n",
    "\n",
    "        cdd_news = x[\"cdd_encoded_index\"].long().to(self.device)\n",
    "        _, cdd_news_repr = self.bert(\n",
    "            self.embedding(cdd_news, cdd_subword_prefix), cdd_attn_mask\n",
    "        )\n",
    "\n",
    "        his_news = x[\"his_encoded_index\"].long().to(self.device)\n",
    "        his_news_embedding = self.embedding(his_news, his_subword_prefix)\n",
    "        his_news_encoded_embedding, his_news_repr = self.encoderN(\n",
    "            his_news_embedding\n",
    "        )\n",
    "        user_repr = self.encoderU(his_news_repr)\n",
    "        print(his_refined_mask[0][3])\n",
    "        ps_terms, ps_term_mask, kid = self.reducer(his_news_encoded_embedding, his_news_embedding, user_repr, his_news_repr, his_attn_mask, his_refined_mask)\n",
    "        print(ps_terms)\n",
    "        # append CLS to each historical news, aggregator historical news representation to user repr\n",
    "        if self.aggregator:\n",
    "            ps_terms = torch.cat([his_news_embedding[:, :, 0].unsqueeze(-2), ps_terms], dim=-2)\n",
    "            ps_term_mask = torch.cat([torch.ones(*ps_term_mask.shape[0:2], 1, device=ps_term_mask.device), ps_term_mask], dim=-1)\n",
    "            ps_terms, his_news_repr = self.bert(ps_terms, ps_term_mask)\n",
    "            user_repr = self.aggregator(his_news_repr)\n",
    "\n",
    "        # append CLS to the entire browsing history, directly deriving user repr\n",
    "        else:\n",
    "            batch_size = ps_terms.size(0)\n",
    "            ps_terms = torch.cat([his_news_embedding[:, 0, 0].unsqueeze(1).unsqueeze(1), ps_terms.reshape(batch_size, 1, -1, ps_terms.size(-1))], dim=-2)\n",
    "            ps_term_mask = torch.cat([torch.ones(batch_size, 1, 1, device=ps_term_mask.device), ps_term_mask.reshape(batch_size, 1, -1)], dim=-1)\n",
    "            _, user_cls = self.bert(ps_terms, ps_term_mask)\n",
    "            user_repr = self.userProject(user_cls)\n",
    "\n",
    "        return self.clickPredictor(cdd_news_repr, user_repr), kid\n",
    "\n",
    "    def forward(self,x):\n",
    "        \"\"\"\n",
    "        Decoupled function, score is unormalized click score\n",
    "        \"\"\"\n",
    "        score, kid = self._forward(x)\n",
    "\n",
    "        if self.training:\n",
    "            prob = nn.functional.log_softmax(score, dim=1)\n",
    "        else:\n",
    "            prob = torch.sigmoid(score)\n",
    "\n",
    "        return prob, kid"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "embedding = BERT_Embedding(manager)\n",
    "\n",
    "encoderN = CNN_Encoder(manager)\n",
    "# encoderN = RNN_Encoder(manager)\n",
    "# encoderN = MHA_Encoder(manager)\n",
    "\n",
    "# encoderU = CNN_User_Encoder(manager)\n",
    "encoderU = RNN_User_Encoder(manager)\n",
    "# encoderU = MHA_User_Encoder(manager)\n",
    "\n",
    "reducer = Matching_Reducer(manager)\n",
    "# reducer = BM25_Reducer(manager)\n",
    "\n",
    "# ranker = CNN_Ranker(manager)\n",
    "# ranker = BERT_Onepass_Ranker(manager)\n",
    "# ranker = BERT_Original_Ranker(manager)\n",
    "\n",
    "model = TTMS(manager, embedding, encoderN, encoderU, reducer).to(manager.device)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "t = BertTokenizer.from_pretrained('bert-base-uncased')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "record['his_encoded_index'][0,3], record['his_refined_mask'][0,3]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(tensor([  101,  5606,  1997,  5190,  1997,  2111,  1999,  2662,  2024,  2091,\n",
       "         24352,  1997,  1037,  5477,  2008,  1005,  2071,  8246,  1005,  5606,\n",
       "          1997,  5190,  1997,  2111,  2444,  2091, 24352,  2013,  1037,  5477,\n",
       "          1999,  2662,  2008,  3728,  2018,  2049,  3891, 23191,  2904,  1000,\n",
       "          2013,  2659,  2000,  2152, 19353,  1997,  2895,  1000,  2011,  1996,\n",
       "          2149,  2390,  3650,  1997,  6145,  1012,  2739,  2739,  2271,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0]),\n",
       " tensor([1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
       "         1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0,\n",
       "         1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0]))"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "t.convert_ids_to_tokens(record['his_encoded_index'][0,3])"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['[CLS]',\n",
       " 'hundreds',\n",
       " 'of',\n",
       " 'thousands',\n",
       " 'of',\n",
       " 'people',\n",
       " 'in',\n",
       " 'california',\n",
       " 'are',\n",
       " 'down',\n",
       " '##river',\n",
       " 'of',\n",
       " 'a',\n",
       " 'dam',\n",
       " 'that',\n",
       " \"'\",\n",
       " 'could',\n",
       " 'fail',\n",
       " \"'\",\n",
       " 'hundreds',\n",
       " 'of',\n",
       " 'thousands',\n",
       " 'of',\n",
       " 'people',\n",
       " 'live',\n",
       " 'down',\n",
       " '##river',\n",
       " 'from',\n",
       " 'a',\n",
       " 'dam',\n",
       " 'in',\n",
       " 'california',\n",
       " 'that',\n",
       " 'recently',\n",
       " 'had',\n",
       " 'its',\n",
       " 'risk',\n",
       " 'characterization',\n",
       " 'changed',\n",
       " '\"',\n",
       " 'from',\n",
       " 'low',\n",
       " 'to',\n",
       " 'high',\n",
       " 'urgency',\n",
       " 'of',\n",
       " 'action',\n",
       " '\"',\n",
       " 'by',\n",
       " 'the',\n",
       " 'us',\n",
       " 'army',\n",
       " 'corps',\n",
       " 'of',\n",
       " 'engineers',\n",
       " '.',\n",
       " 'news',\n",
       " 'news',\n",
       " '##us',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]']"
      ]
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "tokens = t.decode(record['his_encoded_index'][0,3])\n",
    "tokens"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'[CLS] hundreds of thousands of people in california are downriver of a dam that\\'could fail\\'hundreds of thousands of people live downriver from a dam in california that recently had its risk characterization changed \" from low to high urgency of action \" by the us army corps of engineers. news newsus [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]'"
      ]
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "record['his_subword_index'][0,3]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[ 0,  0],\n",
       "        [ 1,  1],\n",
       "        [ 2,  2],\n",
       "        [ 3,  3],\n",
       "        [ 4,  4],\n",
       "        [ 5,  5],\n",
       "        [ 6,  6],\n",
       "        [ 6,  7],\n",
       "        [ 6,  8],\n",
       "        [ 6,  9],\n",
       "        [ 6, 10],\n",
       "        [ 7, 11],\n",
       "        [ 8, 12],\n",
       "        [ 9, 13],\n",
       "        [10, 14],\n",
       "        [11, 15],\n",
       "        [12, 16],\n",
       "        [13, 17],\n",
       "        [14, 18],\n",
       "        [15, 19],\n",
       "        [16, 20],\n",
       "        [17, 21],\n",
       "        [18, 22],\n",
       "        [19, 23],\n",
       "        [20, 24],\n",
       "        [21, 25],\n",
       "        [22, 26],\n",
       "        [23, 27],\n",
       "        [24, 28],\n",
       "        [25, 29],\n",
       "        [26, 30],\n",
       "        [27, 31],\n",
       "        [28, 32],\n",
       "        [29, 33],\n",
       "        [30, 34],\n",
       "        [31, 35],\n",
       "        [32, 36],\n",
       "        [33, 37],\n",
       "        [34, 38],\n",
       "        [35, 39],\n",
       "        [36, 40],\n",
       "        [37, 41],\n",
       "        [38, 42],\n",
       "        [39, 43],\n",
       "        [39, 44],\n",
       "        [40, 45],\n",
       "        [40, 46],\n",
       "        [41, 47],\n",
       "        [42, 48],\n",
       "        [43, 49],\n",
       "        [44, 50],\n",
       "        [45, 51],\n",
       "        [46, 52],\n",
       "        [47, 53],\n",
       "        [48, 54],\n",
       "        [49, 55],\n",
       "        [50, 56],\n",
       "        [51, 57],\n",
       "        [52, 58],\n",
       "        [53, 59],\n",
       "        [54, 60],\n",
       "        [55, 61],\n",
       "        [56, 62],\n",
       "        [57, 63],\n",
       "        [58, 64],\n",
       "        [59, 65],\n",
       "        [60, 66],\n",
       "        [61, 67],\n",
       "        [62, 68],\n",
       "        [63, 69],\n",
       "        [64, 70],\n",
       "        [65, 71],\n",
       "        [66, 72],\n",
       "        [67, 73],\n",
       "        [68, 74],\n",
       "        [69, 75],\n",
       "        [70, 76],\n",
       "        [71, 77],\n",
       "        [72, 78],\n",
       "        [73, 79],\n",
       "        [74, 80],\n",
       "        [75, 81],\n",
       "        [76, 82],\n",
       "        [76, 83],\n",
       "        [77, 84],\n",
       "        [78, 85],\n",
       "        [79, 86],\n",
       "        [80, 87],\n",
       "        [81, 88],\n",
       "        [82, 89],\n",
       "        [83, 90],\n",
       "        [84, 91],\n",
       "        [85, 92],\n",
       "        [86, 93],\n",
       "        [87, 94],\n",
       "        [88, 95],\n",
       "        [89, 96],\n",
       "        [90, 97],\n",
       "        [91, 98],\n",
       "        [91, 99]])"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "tokens"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'[CLS] hundreds of thousands of people in california are downriver of a dam that\\'could fail\\'hundreds of thousands of people live downriver from a dam in california that recently had its risk characterization changed \" from low to high urgency of action \" by the us army corps of engineers. news newsus [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]'"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "model.eval()\n",
    "x = model(record)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 0.0000, 1.0000, 1.0000, 0.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        0.0000, 1.0000, 1.0000, 1.0000, 0.5000, 0.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 0.0000, 1.0000, 1.0000, 1.0000, 0.0000, 1.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000])\n",
      "tensor([[[[ 0.0915,  0.3206,  0.0029,  ...,  0.0651, -0.1172, -0.1191],\n",
      "          [ 0.1801,  0.0201, -0.0948,  ...,  0.0021,  0.0313,  0.1342],\n",
      "          [ 0.1105, -0.0637, -0.0301,  ...,  0.0504,  0.2367,  0.1692],\n",
      "          [-0.1183,  0.2131,  0.1917,  ...,  0.1390, -0.1331,  0.0259],\n",
      "          [ 0.1433,  0.0538,  0.0491,  ..., -0.0048, -0.0241,  0.0674]],\n",
      "\n",
      "         [[-0.0740,  0.2585,  0.2338,  ..., -0.0613, -0.1304,  0.1197],\n",
      "          [-0.0491, -0.0353, -0.0078,  ..., -0.0439, -0.0746, -0.1430],\n",
      "          [-0.1815,  0.3161,  0.3581,  ...,  0.0954, -0.1615,  0.0269],\n",
      "          [-0.1472, -0.2682,  0.0646,  ..., -0.2076,  0.0291,  0.2123],\n",
      "          [-0.1013, -0.1341,  0.1206,  ...,  0.0074, -0.0982,  0.1020]],\n",
      "\n",
      "         [[ 0.0191, -0.0269,  0.0473,  ...,  0.0952,  0.0222, -0.0104],\n",
      "          [ 0.0832,  0.0166,  0.1525,  ..., -0.1337,  0.2452, -0.2838],\n",
      "          [ 0.0060, -0.0207, -0.0530,  ...,  0.2111, -0.0280, -0.1681],\n",
      "          [-0.1841, -0.0467,  0.1289,  ...,  0.0456, -0.0230,  0.1242],\n",
      "          [ 0.0197,  0.0723,  0.1025,  ...,  0.0393,  0.0202,  0.1186]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0052, -0.0039,  0.0048,  ..., -0.0060,  0.0043,  0.0061],\n",
      "          [-0.0052, -0.0039,  0.0048,  ..., -0.0060,  0.0043,  0.0061],\n",
      "          [-0.0052, -0.0039,  0.0048,  ..., -0.0060,  0.0043,  0.0061],\n",
      "          [-0.0052, -0.0039,  0.0048,  ..., -0.0060,  0.0043,  0.0061],\n",
      "          [-0.0052, -0.0039,  0.0048,  ..., -0.0060,  0.0043,  0.0061]],\n",
      "\n",
      "         [[-0.0052, -0.0039,  0.0048,  ..., -0.0060,  0.0043,  0.0061],\n",
      "          [-0.0052, -0.0039,  0.0048,  ..., -0.0060,  0.0043,  0.0061],\n",
      "          [-0.0052, -0.0039,  0.0048,  ..., -0.0060,  0.0043,  0.0061],\n",
      "          [-0.0052, -0.0039,  0.0048,  ..., -0.0060,  0.0043,  0.0061],\n",
      "          [-0.0052, -0.0039,  0.0048,  ..., -0.0060,  0.0043,  0.0061]],\n",
      "\n",
      "         [[-0.0052, -0.0039,  0.0048,  ..., -0.0060,  0.0043,  0.0061],\n",
      "          [-0.0052, -0.0039,  0.0048,  ..., -0.0060,  0.0043,  0.0061],\n",
      "          [-0.0052, -0.0039,  0.0048,  ..., -0.0060,  0.0043,  0.0061],\n",
      "          [-0.0052, -0.0039,  0.0048,  ..., -0.0060,  0.0043,  0.0061],\n",
      "          [-0.0052, -0.0039,  0.0048,  ..., -0.0060,  0.0043,  0.0061]]]],\n",
      "       grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "x"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "record['cdd_mask']"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "c[5][0]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "c[6][0].sum()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "record['his_mask'][0].sum()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "words = convert_tokens_to_words(t.convert_ids_to_tokens(record['cdd_encoded_index'][1,0]))\n",
    "words = [i for i in words if i!='[PAD]']\n",
    "\n",
    "for i,j in enumerate(c[0][1].matmul(record['cdd_reduced_mask'][1].float().unsqueeze(-1)).squeeze(-1)[0]):\n",
    "\n",
    "    if j == 0 and i < 40:\n",
    "        print(i)\n",
    "        print(words[i])\n",
    "\n",
    "len(words), words"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "c[0][1].matmul(record['cdd_reduced_mask'][1].float().unsqueeze(-1)).squeeze(-1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "a = torch.zeros(3,1)\n",
    "a[-3:] = 1\n",
    "a"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "record['cdd_mask'], record['cdd_id']"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "c[0][1]#, record['cdd_subword_index'][1]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "c[0].matmul(record['cdd_attn_mask'].float().unsqueeze(-1)).squeeze(-1)[1]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "record['cdd_attn_mask']"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "t = BertTokenizer.from_pretrained('bert-base-uncased')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "tokens = t.convert_ids_to_tokens(record['his_encoded_index'][0][0])\n",
    "tokens"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "d = c.matmul(record['cdd_attn_mask'].to(config.device).float().unsqueeze(-1)).squeeze(-1)[0][1]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "for i,tok in enumerate(tokens):\n",
    "    if tok.startswith('##'):\n",
    "        print(i)\n",
    "[i for i in tokens if i!='[PAD]']"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "record['his_subword_index'][0][0]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "c[1][0][0][29]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "for i,j in enumerate(c[3][0,0]):\n",
    "    if j == 0 and i < 30:\n",
    "        print(i)\n",
    "        print(words[i])\n",
    "c[2][0][0], c[3][0,0]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.11",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.11 64-bit (conda)"
  },
  "interpreter": {
   "hash": "decb58d8582e8bebc2c9af4e5243ce054f2f8013c5b7e79ffbf7b8b9f3c0761b"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}