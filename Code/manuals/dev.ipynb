{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import os\n",
    "import sys\n",
    "os.chdir(\"../\")\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "import re\n",
    "import logging\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "import time\n",
    "import pickle\n",
    "from thop import profile\n",
    "from collections import defaultdict\n",
    "from data.configs.demo import config\n",
    "from collections import defaultdict\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModel, BertModel, BertConfig, AutoModelForSequenceClassification\n",
    "from utils.Manager import Manager\n",
    "\n",
    "from models.Embeddings.BERT import BERT_Embedding\n",
    "from models.Encoders.CNN import CNN_Encoder,CNN_User_Encoder\n",
    "from models.Encoders.RNN import RNN_Encoder,RNN_User_Encoder\n",
    "from models.Encoders.MHA import MHA_Encoder, MHA_User_Encoder\n",
    "from models.Modules.DRM import Matching_Reducer, Identical_Reducer\n",
    "from models.Rankers.BERT import BERT_Onepass_Ranker, BERT_Original_Ranker\n",
    "from models.Rankers.CNN import CNN_Ranker\n",
    "from models.Encoders.Pooling import Attention_Pooling, Average_Pooling\n",
    "from models.UniLM.modeling import TuringNLRv3Model, TuringNLRv3ForSequenceClassification, relative_position_bucket\n",
    "from models.UniLM.configuration_tnlrv3 import TuringNLRv3Config\n",
    "\n",
    "from models.TwoTowerBaseModel import TwoTowerBaseModel\n",
    "\n",
    "from models.Encoders.BERT import BERT_Encoder\n",
    "from models.Encoders.Pooling import *\n",
    "\n",
    "from models.TESRec import TESRec\n",
    "from models.XFormer import XFormer\n",
    "from models.PLM import PLM\n",
    " \n",
    "from models.Modules.Attention import MultiheadAttention, get_attn_mask, XSoftmax\n",
    "torch.set_printoptions(threshold=100000)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# m = AutoModel.from_pretrained('bert-base-uncased',cache_dir=config.path + 'bert_cache/')\n",
    "# m2 = AutoModel.from_pretrained('microsoft/deberta-base',cache_dir=config.path + 'bert_cache/')\n",
    "# m3 = TuringNLRv3ForSequenceClassification.from_pretrained(config.unilm_path, config=TuringNLRv3Config.from_pretrained(config.unilm_config_path))\n",
    "# m4 = AutoModel.from_pretrained('google/reformer-crime-and-punishment', cache_dir=config.path + \"bert_cache/\")\n",
    "# m5 = AutoModel.from_pretrained('funnel-transformer/small-base', cache_dir=config.path + \"bert_cache/\")\n",
    "# m6 = AutoModel.from_pretrained('distilbert-base-uncased',cache_dir=config.path + 'bert_cache/')\n",
    "# m7 = AutoModel.from_pretrained(\"google/bigbird-roberta-base\", cache_dir=config.path + \"bert_cache/\")\n",
    "m8 = AutoModel.from_pretrained(\"allenai/longformer-base-4096\", cache_dir=config.path + \"bert_cache/\")\n",
    "\n",
    "# t = AutoTokenizer.from_pretrained('bert-base-uncased', cache_dir=config.path + \"bert_cache/\")\n",
    "# t2 = AutoTokenizer.from_pretrained('microsoft/deberta-base', cache_dir=config.path + \"bert_cache/\")\n",
    "# t3 = AutoTokenizer.from_pretrained('allenai/longformer-base-4096', cache_dir=config.path + \"bert_cache/\")\n",
    "# t4 = AutoTokenizer.from_pretrained('google/reformer-crime-and-punishment', cache_dir=config.path + \"bert_cache/\")\n",
    "# t5 = AutoTokenizer.from_pretrained('funnel-transformer/small-base', cache_dir=config.path + \"bert_cache/\")\n",
    "# t6 = AutoTokenizer.from_pretrained('distilbert-base-uncased', cache_dir=config.path + \"bert_cache/\")\n",
    "# t7 = AutoTokenizer.from_pretrained(\"google/bigbird-roberta-base\", cache_dir=config.path + \"bert_cache/\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "m8.config"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "m8"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "config.bert = 'bert'\n",
    "config.mode = \"encode\"\n",
    "config.scale = \"large\"\n",
    "\n",
    "manager = Manager(config)\n",
    "\n",
    "loaders = manager.prepare()\n",
    "X1 = list(loaders[0])\n",
    "# X2 = list(loaders[1])\n",
    "x1 = X1[0]\n",
    "# x2 = X2[0]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# embedding = BERT_Embedding(manager)\n",
    "manager.hidden_dim = 768\n",
    "manager.reducer = \"none\"\n",
    "# encoderN = CNN_Encoder(manager)\n",
    "# encoderN = RNN_Encoder(manager)\n",
    "# encoderN = MHA_Encoder(manager)\n",
    "\n",
    "# encoderU = CNN_User_Encoder(manager)\n",
    "encoderU = RNN_User_Encoder(manager)\n",
    "# encoderU = MHA_User_Encoder(manager)\n",
    "# encoderU = Attention_Pooling(manager)\n",
    "# encoderU = Average_Pooling(manager)\n",
    "\n",
    "# reducer = Matching_Reducer(manager)\n",
    "# reducer = Identical_Reducer(manager)\n",
    "\n",
    "# ranker = CNN_Ranker(manager)\n",
    "# ranker = BERT_Onepass_Ranker(manager)\n",
    "# ranker = BERT_Original_Ranker(manager)\n",
    "\n",
    "# model = TESRec(manager, embedding, encoderN, encoderU, reducer).to(manager.device)\n",
    "# model = ESM(manager, embedding, encoderN, encoderU, reducer, ranker).to(manager.device)\n",
    "model = PLM(manager, encoderU).to(manager.device)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# GateFormer\n",
    "embedding = 50 * 2 * 100 * 768 * 2\n",
    "\n",
    "ext_encoding = 50*(2*3*150*100 + 4*100*150) + 8*2*150*150*50\n",
    "reduction = (2*100*150 + 100*math.log2(100))*50 + 50*3\n",
    "\n",
    "bert_embed = 150 * 2 * 768 * 2\n",
    "bert_project = 150*12*64*2\n",
    "bert_attn = 150*12*64*150*2 + 12*150*150*64*2\n",
    "bert_intm = 150*768*768*2 + 150*768*2 + 150*768*3072*4\n",
    "bert_pool = 150*768*4\n",
    "\n",
    "sum = embedding + ext_encoding + reduction + bert_embed + (bert_project + bert_attn + bert_intm) * 12 + bert_pool\n",
    "sum"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "# GateFormer\n",
    "embedding = 50 * 2 * 100 * 768 * 2\n",
    "\n",
    "bert_embed = 150 * 2 * 768 * 2\n",
    "bert_project = 150*12*64*2\n",
    "bert_attn = 150*12*64*150*2 + 12*150*150*64*2\n",
    "bert_intm = 150*768*768*2 + 150*768*2 + 150*768*3072*4\n",
    "bert_pool = 150*768*4\n",
    "\n",
    "sum = embedding + bert_embed + (bert_project + bert_attn + bert_intm) * 12 + bert_pool\n",
    "sum"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "19961548800"
      ]
     },
     "metadata": {},
     "execution_count": 1
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "# NRMS\n",
    "embedding = 50 * 2 * 100 * 768 * 2\n",
    "\n",
    "project = 50 * 100 * 768 * 384 * 2 *3\n",
    "attn = 50*100*384*100*4\n",
    "attnA = 50*100*384*2\n",
    "\n",
    "project2 = 50*384*384*2*3\n",
    "attn2 = 50*384*50*4\n",
    "attnA2 = 50*384*2\n",
    "\n",
    "sum = embedding + project + project2 + attn + attn2 + attnA + attnA2\n",
    "sum"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "5258995200"
      ]
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# BigBird\n",
    "embedding = 50 * 2 * 100 * 768 * 2 * 3\n",
    "\n",
    "bert_project = 1024*12*64*2\n",
    "bert_attn = 1024*12*64*2 + 12*1024*64*2\n",
    "bert_intm = 1024*768*768*2 + 1024*768*2 + 1024*768*3072*4\n",
    "bert_pool = 1024*768*4\n",
    "\n",
    "sum = embedding + (bert_project + bert_attn + bert_intm) * 12 + bert_pool\n",
    "sum"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# longformer\n",
    "embedding = 50 * 2 * 100 * 768 * 2 * 3\n",
    "\n",
    "bert_project = 1024*12*64*2\n",
    "bert_attn = 1024*512*12*64*2 + 12*1024*512*64*2\n",
    "bert_intm = 1024*768*768*2 + 1024*768*2 + 1024*768*3072*4\n",
    "bert_pool = 1024*768*4\n",
    "\n",
    "sum = embedding + (bert_project + bert_attn + bert_intm) * 12 + bert_pool\n",
    "sum"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# EBNR\n",
    "embedding = 50 * 2 * 100 * 768 * 2 * 3\n",
    "\n",
    "bert_project = 50*12*100*64*2*3\n",
    "bert_attn = 50*12*100*64*100*2 + 50*12*100*100*64*2\n",
    "bert_intm = 50*100*768*768*2 + 50*100*768*2 + 50*100*768*3072*4\n",
    "bert_pool = 50*1*768*768*2\n",
    "\n",
    "bert = (bert_project + bert_attn + bert_intm) * 12 + bert_pool\n",
    "\n",
    "rnn = 8*2*768*768*50\n",
    "\n",
    "sum = embedding + bert + rnn\n",
    "sum"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Synthesizer\n",
    "embedding = 50 * 2 * 100 * 768 * 2 * 3\n",
    "\n",
    "bert_project = 50*12*100*64*2*3\n",
    "bert_attn = 50*12*100*64*100*2 + 50*12*100*100*64*2\n",
    "bert_intm = 50*100*768*768*2 + 50*100*768*2 + 50*100*768*3072*4\n",
    "bert_pool = 50*1*768*768*2\n",
    "\n",
    "bert = (bert_project + bert_attn + bert_intm) * 12 + bert_pool\n",
    "\n",
    "rnn = 8*2*768*768*50\n",
    "\n",
    "sum = embedding + bert + rnn\n",
    "sum"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# funnel\n",
    "embedding = 50 * 2 * 100 * 768 * 2 * 3\n",
    "\n",
    "bert_project = 50*12*100*64*2*3\n",
    "bert_attn = 50*12*100*64*100*2 + 50*12*100*100*64*2\n",
    "bert_intm = 50*100*768*768*2 + 50*100*768*2 + 50*100*768*3072*4\n",
    "bert_pool = 50*1*768*768*2\n",
    "\n",
    "bert = (bert_project + bert_attn + bert_intm) * 10 + bert_pool\n",
    "\n",
    "rnn = 8*2*768*768*50\n",
    "\n",
    "sum = embedding + bert + rnn\n",
    "sum"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# newbert\n",
    "embedding = 50 * 2 * 100 * 768 * 2 * 3\n",
    "\n",
    "bert_project = 50*12*100*64*2*3\n",
    "bert_attn = 50*12*100*64*100*2 + 50*12*100*100*64*2\n",
    "bert_intm = 50*100*768*768*2 + 50*100*768*2 + 50*100*768*3072*4\n",
    "bert_pool = 50*1*768*768*2\n",
    "\n",
    "bert = (bert_project + bert_attn + bert_intm) * 4 + bert_pool\n",
    "\n",
    "rnn = 8*2*768*768*50\n",
    "\n",
    "sum = embedding + bert + rnn\n",
    "sum"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# distilbert\n",
    "embedding = 50 * 2 * 100 * 768 * 2 * 2\n",
    "\n",
    "bert_project = 50*12*100*64*2*3\n",
    "bert_attn = 50*12*100*64*100*2 + 50*12*100*100*64*2\n",
    "bert_intm = 50*100*768*768*2 + 50*100*768*2 + 50*100*768*3072*4\n",
    "bert_pool = 50*1*768*768*2\n",
    "\n",
    "bert = (bert_project + bert_attn + bert_intm) * 5 + bert_pool\n",
    "\n",
    "rnn = 8*2*768*768*50\n",
    "\n",
    "sum = embedding + bert + rnn\n",
    "sum"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.11",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.11 64-bit (conda)"
  },
  "interpreter": {
   "hash": "0f43efc2da5f33d61ae1bd929e6c7df9dd2aa7f250aadb5586d31de3e27bb6a5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}